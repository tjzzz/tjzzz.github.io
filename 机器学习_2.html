
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>
    
  机器学习 - 镇镇的笔记
  

  </title>
  <meta name="author" content="">
  <meta name="description" content="">

  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link href="asset/css/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="atom.xml" rel="alternate" title="镇镇的笔记" type="application/atom+xml">
  <script src="asset/js/modernizr-2.0.js"></script>
  <script src="asset/js/jquery.min.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/solarized_light.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>

  <style type="text/css">
  .cat-children-p{ padding: 6px 0px;}
  .hljs{background: none;}
  </style>
  <script type="text/javascript">
  var isAddSildbar = true;
  </script>
  <script src="asset/js/octopress.js" type="text/javascript"></script>
</head>
<script type="text/javascript">
//链接新开窗口
function addBlankTargetForLinks () {
  $('a[href^="http"]').each(function(){
      $(this).attr('target', '_blank');
  });
}
$(document).ready(function(event) {
  addBlankTargetForLinks();
});
</script>
<body   >
  <header role="banner"><hgroup>
  <h1><a href="index.html">镇镇的笔记</a></h1>
  
    <h2></h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">

  <li id=""><a target="self" href="index.html">Home</a></li>

  <li id=""><a target="_self" href="archives.html">Archives</a></li>

</ul>

</nav>
  <div id="main">
    <div id="content"> 
<div class="blog-index">

	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15350244372147.html">4.1 回归模型</a></h1>
			<p class="meta"><time datetime="2018-08-23T19:40:37+08:00" 
			pubdate data-updated="true">2018/8/23</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>进入统计机器学习大门，最基础的从回归分析说起。</p>

<h2 id="toc_0">1.回归分析</h2>

<p>机器学习从最简单的回归分析说起，这次从最小二乘的几何意义角度去看回归分析。</p>

<p>\[Y = X’B\]<br/>
我们知道最终估计的满足 \((y-X\hat\beta)^TX=0\)。即最优估计是在空间上的正交投影</p>

<p><img src="media/15350244372147/15350246581231.jpg" alt=""/><br/>
统计中的一些基本概念：</p>

<ul>
<li>t 检验</li>
<li>F 检验</li>
<li>p value</li>
<li>多重共线性</li>
<li></li>
</ul>

<h2 id="toc_1">2.正则化处理</h2>

<p>训练数据是有限的时候，总可以通过增加参数的方法提高模型复杂度，降低训练误差，但是其泛化能力不好。正则化即通过调整参数的取值，来平衡<strong>偏差</strong>和<strong>方差</strong>的关系。</p>

<p>线性回归中，最直接的方法就行在loss function中添加正则化项。一般形式如下：</p>

<p>\[E(w) = \sum [f(x_i, w) - y_i]^2 + \lambda g(||w||_p)\]</p>

<ul>
<li>当取一范数时，即为lasso；</li>
<li>二范数：岭回归</li>
<li>一范数和二范数组合：弹性网络。  \(a||w||^2_2 + (1-a)||w||_1\)</li>
</ul>

<p>一范数和二范数的几何意义区别如下(这里就不解释了)：</p>

<ul>
<li>lasso会将特征衰减到0</li>
<li>岭回归大量特征系数都比较小</li>
<li>弹性网络结合了两种方法的优点</li>
</ul>

<p><img src="media/15350244372147/15350256600383.jpg" alt=""/></p>

<blockquote>
<p>从概率不同学派的角度来看上面的问题。<br/>
正则化的方式，是从频率学派角度来看；而贝叶斯学派视角来看，正则化其实就是引入了关于参数的先验信息。</p>
</blockquote>

<p>贝叶斯学派是假定参数服从某种分布，然后根据其分布利用积分的方法将其消除掉。这一过程叫<strong>边际化</strong>。边际化的过程其实恰好是正则化/泛化的过程。</p>

<p>可以证明，岭回归是w满足正态分布，lasso是当w满足拉普拉斯分布时候通过最大后验概率得到的估计结果。</p>

<blockquote>
<p>code</p>
</blockquote>

<pre><code>import numpy as np # 快速操作结构数组的工具
import matplotlib.pyplot as plt  # 可视化绘制
from sklearn.linear_model import Lasso,LassoCV,LassoLarsCV   # Lasso回归,LassoCV交叉验证实现alpha的选取，LassoLarsCV基于最小角回归交叉验证实现alpha的选取

# ========Lasso回归========
model = Lasso(alpha=0.01)  # 调节alpha可以实现对拟合的程度
# model = LassoCV()  # LassoCV自动调节alpha可以实现选择最佳的alpha。
# model = LassoLarsCV()  # LassoLarsCV自动调节alpha可以实现选择最佳的alpha
model.fit(X, y)   # 线性回归建模
print(&#39;系数矩阵:\n&#39;,model.coef_)
print(&#39;线性回归模型:\n&#39;,model)
# print(&#39;最佳的alpha：&#39;,model.alpha_)  # 只有在使用LassoCV、LassoLarsCV时才有效
# 使用模型预测
predicted = model.predict(X)

</code></pre>

<h2 id="toc_2">3.广义线性模型</h2>

<p>广义线性模型可以看做一般线性模型的推广，既然说他是推广，说明有一些问题是传统的线性模型没法解决的。</p>

<p>广义线性模型中y的密度函数形式是基于指数分布族的\[p(y;\theta)=b(y)exp[\theta&#39;T(y)+a(\theta)]\]<br/>
其中\(T(y)\)是一个充分统计量，通常可以等于\(y\)。 常见的正态分布、指数分布、二项分布、泊松分布都属于指数分布族，都可以转为这种形式。</p>

<p>介绍一个常用的广义线性模型：</p>

<p>xxx</p>

<h2 id="toc_3">4.基函数扩展：属性的非线性化</h2>

<p>线性模型的表达能力有限，前面广义线性模型的思路是将因变量y做了一个非线性映射。而从另一个角度，可以将解释变量变为非线性的，即<br/>
\[y=\beta_0+\beta_1x_1 + ...+\beta_nx_n\]<br/>
可以扩展为<strong>基函数扩展模型</strong><br/>
\[y=\beta_0+\beta_1f(x_1) + ...+\beta_nf(x_n)\]</p>

<p>比如常见的多项式回归\[y=\beta_0+\beta_1 x + ...+\beta_n x^n\]</p>

<p>多项式回归会存在一些问题：</p>

<ul>
<li>\(x\)和\(x^k\)之间是相关的，不太好解释清楚每个变量的贡献程度</li>
<li>会出现过拟合的情况</li>
</ul>

<p><strong>多元自适应回归样条MARS</strong></p>

<ul>
<li>多项式整体是线性，局部非非线性</li>
<li>MARS: 整体是非线性，局部是线性(分段函数)</li>
</ul>

<p>样条函数，需要满足一些最基本的一些条件</p>

<ul>
<li>在knot节点处满足函数的连续性</li>
<li>一阶导数连续，二阶导数连续，则称为三次样条</li>
</ul>

<p>平滑样条</p>

<p>\[E=\sum_{i=1}^n [y_i-g(x_i)]^2 +\lambda\int g&#39;&#39;(t)^2 \]</p>

<p>code: <code>patsy</code></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15343431925455.html">二、起步篇—— 数据预处理[python]</a></h1>
			<p class="meta"><time datetime="2018-08-15T22:26:32+08:00" 
			pubdate data-updated="true">2018/8/15</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<blockquote>
<p>一方面可以多查些官方说明<br/>
多去看些kaggle，tianchi等的比赛案例，他们数据预处理做的很全面到位<br/>
实践一些工作中的项目，将代码规范化</p>
</blockquote>

<h2 id="toc_0">1.缺失表示</h2>

<p>python中缺失是nan，如果本身数据中缺失是用其他方式表示的，可以先转换一下<br/>
<code>df.replace(&#39;-&#39;,np.nan)</code></p>

<pre><code class="language-python">
import numpy as np
import pandas as pd
from io import StringIO
import sys

df = pd.read_table(&#39;zz&#39;)
df = df.replace(&#39;-&#39;,np.nan).head()
df.head()
</code></pre>

<h2 id="toc_1">2.缺失的简单处理办法</h2>

<h3 id="toc_2">暴力删除</h3>

<p><code>isnull()</code>   判断是否缺失</p>

<p><code>dropna( axis = 0 /1 )</code> 参数axis表示轴选择，axis=0 代表行，axis=1 代表列</p>

<p><code>dropna(subset=[&#39;&#39;])</code>   删除指定列中有空值的一行数据</p>

<h3 id="toc_3">默认值填充</h3>

<p><code>df.fillna(value)</code><br/>
或者对不同列填不同的值</p>

<h3 id="toc_4">统计/算法填充</h3>

<pre><code class="language-python">from sklearn.preprocessing import Imputer
# strategy 有mean,median, most_frequent 方式
# axis 默认是0，列向， axis=1行向
dff = df.loc[:, [&#39;comment_time&#39;]]
imr = Imputer(missing_values = &#39;NaN&#39;, strategy = &#39;mean&#39;, axis = 0 )
imr = imr.fit(dff.values)
imputed_data = imr.transform(dff.values)
</code></pre>

<pre><code class="language-python">## 3.分类数据处理
from sklearn.preprocessing import LabelEncoder
class_le = LabelEncoder()
y = class_le.fit_transform(df[&#39;nid&#39;].values)

</code></pre>

<pre><code class="language-python">## 数据标准化
from sklearn.preprocessing import MinMaxScaler
mms = MinMaxScaler()
X_train_norm = mms.fit_transform(imputed_data)
X_test_norm = mms.transform(imputed_data)
</code></pre>

<h2 id="toc_5">参考资料</h2>

<p><a href="https://blog.csdn.net/Amy_mm/article/details/79799629">https://blog.csdn.net/Amy_mm/article/details/79799629</a><br/>
<a href="https://www.cnblogs.com/charlotte77/p/5622325.html">https://www.cnblogs.com/charlotte77/p/5622325.html</a></p>

<p><a href="https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python">https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15334844213158.html">二、起步篇——数据预处理[方法论]</a></h1>
			<p class="meta"><time datetime="2018-08-05T23:53:41+08:00" 
			pubdate data-updated="true">2018/8/5</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p><img src="media/15334844213158/15335717779664.jpg" alt=""/></p>

<h2 id="toc_0">1.数据偏度</h2>

<p>数据的处理，从数据特征本身的统计维度看，有尺度、偏度、</p>

<p>1.数据尺度</p>

<ul>
<li>标准化 =&gt; 均值0，方差1</li>
<li>归一化 =&gt; [0,1]</li>
</ul>

<p>2.数据偏度<br/>
可以通过偏度来度量，数据中如果存在较大的偏度，可能是因为有异常点的存在。</p>

<p>有偏数据处理，一般可以取log，或者开根号让他能近似正态</p>

<h2 id="toc_1">2.异常点</h2>

<p>首先什么是异常点<br/>
异常点<br/>
（1） 首先确认是不是错误导致，比如计算错误。取值错误<br/>
（2）确认异常点的生成机制</p>

<p>（1）异常点检测</p>

<p>@@@<br/>
sklearn中常用的包</p>

<p>（2）异常点处理</p>

<ul>
<li>如果是少量可以直接删除</li>
<li>当数据量较少，删除后造成可用信息较少时候，可以使用“空间标识”的数值处理方法</li>
</ul>

<h2 id="toc_2">3.缺失值</h2>

<p>缺失机制：随机缺失，还是非随机缺失</p>

<p>补充原则：</p>

<ul>
<li>如果缺失占比太大，删除</li>
</ul>

<p>补充方法：</p>

<ul>
<li>统计方法：均值</li>
<li>机器学习方法：回归、K近邻</li>
</ul>

<h2 id="toc_3">4.特征冗余</h2>

<p>一般是说特征自相关性太高，即“共线性”。另外是指一些没有区分度的变量，比如一是特征取值的总数与样本数目的比例在 10% 以下，二是出现频率最高的特征取值的出现频率应该在出现频率次高的特征的20倍以上。</p>

<p>检测办法：<br/>
解决办法：PCA</p>

<h2 id="toc_4">参考文章</h2>

<p>离群点</p>

<p><a href="https://blog.chih.me/Outlier-mining-review.html">https://blog.chih.me/Outlier-mining-review.html</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15318267888584.html">目录结构</a></h1>
			<p class="meta"><time datetime="2018-07-17T19:26:28+08:00" 
			pubdate data-updated="true">2018/7/17</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<ol>
<li><p>统计学习理论</p></li>
</ol>

<ul>
<li>可学习</li>
<li>模型设计</li>
<li><p>基础知识偏——统计</p></li>
</ul>

<ol>
<li><p>数据&amp;特征</p></li>
</ol>

<ul>
<li>数据清洗</li>
<li>特征提取</li>
<li>降维</li>
</ul>

<p>3 模型部分</p>

<ul>
<li>无监督</li>
<li>有监督

<ul>
<li>回归</li>
<li>分类</li>
</ul></li>
</ul>

<h3 id="toc_0">补充</h3>

<p>LR 在多分类情况下 -李航</p>

<p>关于凸优化的</p>

<p>SVM 优化SMO算法 + sklearn的区别</p>

<h2 id="toc_1">可参照资料</h2>

<p>coursera<br/>
<a href="https://www.coursera.org/learn/competitive-data-science/home/welcome">https://www.coursera.org/learn/competitive-data-science/home/welcome</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15316431193074.html">一、基础篇</a></h1>
			<p class="meta"><time datetime="2018-07-15T16:25:19+08:00" 
			pubdate data-updated="true">2018/7/15</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<h1 id="toc_0">1.计算学习理论——是否可学习</h1>

<p>一直在说机器学习，主要是在说怎么去学。在怎么学之前，首先需要了解下能不能学，学习的机制是什么</p>

<h2 id="toc_1">PAC（概率近似正确）</h2>

<p><a href="https://blog.csdn.net/wangjianguobj/article/details/57413819">https://blog.csdn.net/wangjianguobj/article/details/57413819</a></p>

<h2 id="toc_2">VC维度</h2>

<p>这个介绍的挺详细<br/>
<a href="http://www.flickering.cn/machine_learning/2015/04/vc%E7%BB%B4%E7%9A%84%E6%9D%A5%E9%BE%99%E5%8E%BB%E8%84%89/?from=singlemessage">http://www.flickering.cn/machine_learning/2015/04/vc%E7%BB%B4%E7%9A%84%E6%9D%A5%E9%BE%99%E5%8E%BB%E8%84%89/?from=singlemessage</a></p>

<h2 id="toc_3">参考</h2>

<p>台大-机器学习基石</p>

<h1 id="toc_4">6.模型设计准则</h1>

<ol>
<li>模型拟合</li>
</ol>

<p>(1) 无免费午餐定理 NFL</p>

<p>就是任何一个算法，针对所有问题，在平均意义上效果是一样的。</p>

<p>=&gt; 所以要具体问题具体分析，针对不同问题，选择适合该问题的方法</p>

<p>(2)奥卡姆剃刀原则</p>

<p>即在预测效果差不多的情况下，模型越简单余越好</p>

<p>误差 = bias + varaince + noise</p>

<ul>
<li>过拟合</li>
<li>欠拟合</li>
</ul>

<h1 id="toc_5">7.模型验证</h1>

<p>1.估计泛化误差</p>

<p>训练集，验证集</p>

<p>2.对数据的重采样</p>

<ul>
<li>留出法</li>
<li>k折交叉验证</li>
<li>自助法(有放回)</li>
</ul>

<h1 id="toc_6">8.模型的评估指标</h1>

<h1 id="toc_7">9.实验设计</h1>

<p>设计实验是要要成的任务是对整个机器学习过程的优化。实验中因子的设计可能会包含很多，比如：算法的类别、算法的参数、数据集等。</p>

<p>当因子较多的时候，如何确定单一因子的影响就需要一些技巧<br/>
<strong>控制变量法</strong></p>

<p>它暗含着一个较强的假设，就是不同因子之间相互独立，互不影响。然而这个并不总是成立的。</p>

<p><strong>因子设计</strong><br/>
他关注的是不同因子之间系统化的变化对学习效果的影响，他的一个特例就是<strong>全因子实验</strong>，也叫<strong>完全交叉设计</strong>。</p>

<p>在具体操作的时候，当分析的因子的离散取值较多时候，可以通过粗调+微调的方法。</p>

<p>在对因子进行精调时候，可以使用<strong>响应面方法</strong>（zzz:根据百科资料解释,就是做了一个二次函数的拟合）</p>

<h2 id="toc_8">正交抽样设计</h2>

<p>@@@补充下：</p>


		</div>

		

	</article>
  
	<div class="pagination">
	 <a class="prev" href="机器学习_3.html">&larr; Older</a> 
<a href="archives.html">Blog Archives</a>
	 <a class="next" href="机器学习_1.html">Newer &rarr;</a>  
	    
	</div>
</div>
 <aside class="sidebar"> 

	<section>
	  <h1>Categories</h1>
	  <ul id="recent_posts">
	  
	      <li class="post">
	        <a href="%E4%BD%A0%E4%B8%8D%E5%BE%97%E4%B8%8D%E7%9F%A5%E7%9A%84%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95.html"><strong>你不得不知的统计方法&nbsp;(3)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3%E7%BA%B3%E7%B1%B3%E5%AD%A6%E4%BD%8D.html"><strong>Udacity.DL&nbsp;(3)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="DL.html"><strong>Ng.DL&nbsp;(3)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="book.DL.html"><strong>book.DL&nbsp;(8)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html"><strong>机器学习&nbsp;(23)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F.html"><strong>推荐系统&nbsp;(3)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="NLP&%E5%9B%BE%E5%83%8F.html"><strong>NLP&图像&nbsp;(4)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96.html"><strong>数据可视化&nbsp;(7)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="0.%20%E8%B5%84%E6%BA%90%E5%AF%BC%E8%88%AA.html"><strong>0. 资源导航&nbsp;(3)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="data.html"><strong>data&nbsp;(1)</strong></a>
	        
	        
	        
	      </li>
	   
	  </ul>
	</section>
	<section>
	  <h1>Recent Posts</h1>
	  <ul id="recent_posts">
	  
	      
		      <li class="post">
		        <a href="15516671779096.html">list</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15479712192030.html">R 数据透视表</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15456330400571.html">统计阈值</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15394437873112.html">4.9 深度学习综述</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15394428762655.html">4.8 自适应的基函数——神经网络</a>
		      </li>
	     
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	   
	  </ul>
	</section>
	
</aside> </div></div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 -  -
  <span class="credit">Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a> &nbsp;&nbsp; Theme by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>

  
    


<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>

</body>
</html>