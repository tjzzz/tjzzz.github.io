<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  8 深度学习 - zhenzhen数据科学笔记
  
  </title>
  
  
  <link href="atom.xml" rel="alternate" title="zhenzhen数据科学笔记" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />
    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript">
  function before_search(){
    var searchVal = 'site: ' + document.getElementById('search_input').value;
    document.getElementById('search_q').value = searchVal;
    return true;
  }
</script>
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>


  <section class="top-bar-section">
  <div class="row">
      <div style="position: relative;width:100%;"><div style="position: absolute; width:100%;">
        <ul id="main-menu" class="left">
        
        <li id=""><a target="_self" href="index.html">Home</a></li>
        
        <li id=""><a target="_self" href="archives.html">Archives</a></li>
        
        <li id=""><a target="_self" href="about_me.html">aboutme</a></li>
        
        </ul>

        <ul class="right" id="search-wrap">
          <li>
<form target="_blank" onsubmit="return before_search();" action="https://google.com/search" method="get">
    <input type="hidden" id="search_q" name="q" value="" />
    <input tabindex="1" type="search" id="search_input"  placeholder="Search"/>
</form>
</li>
          </ul>
      </div></div>
  </div>
  </section>

</nav>

        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; zhenzhen数据科学笔记</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
        
        <li><a target="_self" href="index.html">Home</a></li>
        
        <li><a target="_self" href="archives.html">Archives</a></li>
        
        <li><a target="_self" href="about_me.html">aboutme</a></li>
        

    <li><label>Categories</label></li>

        
            <li><a href="kdd&%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html">kdd&异常检测</a></li>
        
            <li><a href="%E8%BD%A8%E8%BF%B9%E5%88%86%E6%9E%90.html">轨迹分析</a></li>
        
            <li><a href="1%20Tools.html">1 Tools</a></li>
        
            <li><a href="2%20Get%20Data.html">2 Get Data</a></li>
        
            <li><a href="3%20%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96.html">3 数据可视化</a></li>
        
            <li><a href="4%20%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95.html">4 统计方法</a></li>
        
            <li><a href="5%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html">5 机器学习</a></li>
        
            <li><a href="6%20NLP.html">6 NLP</a></li>
        
            <li><a href="7%20CV.html">7 CV</a></li>
        
            <li><a href="8%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html">8 深度学习</a></li>
        
            <li><a href="9%20%E6%AF%94%E8%B5%9B%E5%AD%A6%E4%B9%A0.html">9 比赛学习</a></li>
        
            <li><a href="%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6-%E6%B8%85%E5%8D%95.html">数据科学-清单</a></li>
        
            <li><a href="%E5%85%B6%E4%BB%96.html">其他</a></li>
         

      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>


        <section id="main-content" role="main" class="scroll-container">
        
       

 <script type="text/javascript">
	$(function(){
		$('#menu_item_index').addClass('is_active');
	});
</script>
<div class="row">
	<div class="large-8 medium-8 columns">
		<div class="markdown-body home-categories">
		
			<div class="article">
                <a class="clearlink" href="15637037677008.html">
                
                  <h1>3.【解释性】LIME</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>机器学习得到的模型有时候是一个black box不具有解释性，作者提出了一个问题，我们究竟是相信一个predict result，还是相信一个model。</p>

<p>本文作者主要是利用局部近似的方法，来对any classifier进行解释<br/>
一个大概的示意图<br/>
<img src="media/15227606288131/15227612016423.jpg" alt=""/></p>

<h2 id="toc_0">2.可解释性</h2>

<ul>
<li>可解释：首先必须是可解释的易懂的，在特征很多的时候，线性模型、梯度向量、可加模型等都不太适合。</li>
<li>local faithfull：局部忠诚</li>
<li>与模型无关的，可解释any classifier</li>
</ul>

<h2 id="toc_1">3 Local Interpretable Model-agnostic Explanations</h2>

<p>LIME，首先区分两个东西</p>

<ul>
<li>features</li>
<li>interpretable data representations</li>
</ul>

<p>比如文本文类时具体的features是一个vector，而可解释的representation可能是是否出现某个关键词</p>

<p>基本原理示意图：<br/>
<img src="media/15227606288131/15227631412258.jpg" alt=""/></p>

<p>说明：</p>

<p>抽象的数学描述<br/>
<img src="media/15227606288131/15227633252420.jpg" alt=""/></p>

<p>作者在后面主要是讲了候选集是稀疏线性模型的方法</p>

<h3 id="toc_2">稀疏线性解释</h3>

<p>即G为线性模型，一致性的度量\(\pi_x=exp(-D(x,z)^2/\sigma^2)\), 在x局部用一个线性函数去近似</p>

<p><img src="media/15227606288131/15227718128055.jpg" alt=""/><br/>
具体操作，先用lasso选择k个特征，然后用最小二乘学习特征的权重，K-LASSO<br/>
<img src="media/15227606288131/15227724362604.jpg" alt=""/></p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2019/7/21</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='8%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html'>8 深度学习</a></span>
          				   
                    

                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15637025344767.html">
                
                  <h1>【NG-DL】course2_week1 优化网络参数</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<h2 id="toc_0">1.基本概念</h2>

<p>很多优化参数：<br/>
网络层数，隐层数，学习率，激活函数。。。</p>

<ul>
<li><p>训练集/验证集/测试集</p></li>
<li><p>偏差， 训练集误差</p></li>
<li><p>方差</p></li>
</ul>

<p>若有高bias： 尝试新的网络，更大网络</p>

<p>高方差： 获取更多数据，或者正则化，更合适的网络机构</p>

<p>bias和varaince的平衡<br/>
一般来说更大的网络能减小偏差，更多的数据能减小方差。</p>

<h2 id="toc_1">2.正则化-L2</h2>

<p>以逻辑回归为例</p>

<p>\(J(w,b)=\frac{1}{m}\sum L(\hat y_i, y_i)+\frac{\lambda}{2m}|w|^2_2\)L2惩罚，避免过拟合，导致高方差</p>

<p>类似的神经网络在优化函数上加上</p>

<p>\(J(w^{[1]},b^{[1]},...w^{[l]},b^{[l]})=\frac{1}{m}\sum L(\hat y_i, y_i)+\frac{\lambda}{2m}\sum||w^{[l]}||^2_2\)</p>

<p>其中\(|w^{[l]}|^2\)F范数</p>

<ul>
<li>Ng.当\(\lambda\)较大时候,w会较小，sigmoid接近线性，降低方差。
<img src="media/15055593941505/15103891828021.jpg" alt=""/></li>
</ul>

<h3 id="toc_2">正则化-dropout(随机失活)</h3>

<p>每次对网络中的节点设置一个随机消失的概率p，即每个节点可能在也可能不在网络中，不在的时候即相当于该节点的数值置为0.</p>

<p>dropout与l2类似都会shrink权重。</p>

<h3 id="toc_3">early stoping</h3>

<h2 id="toc_4">3.优化</h2>

<h3 id="toc_5">归一化</h3>

<p>归一化输入=&gt; 均值0，方差1</p>

<ul>
<li>零均值化</li>
<li>归一化方差</li>
</ul>

<p><img src="media/15055593941505/15103915636569.jpg" alt=""/></p>

<h3 id="toc_6">梯度消失与梯度爆炸</h3>

<p>当梯度增长很大或者很微弱时，会导致优化出问题或者很慢。</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2019/7/21</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='8%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html'>8 深度学习</a></span>
          				   
                    

                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15637037679634.html">
                
                  <h1>神经网络解释性问题</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p><a href="https://ask.hellobi.com/blog/zlx19930503/10578">https://ask.hellobi.com/blog/zlx19930503/10578</a></p>

<p>但是深度学习是一个黑箱。我第一次听说它时，就对其工作原理非常费解。几年过去了，我仍然在探索合理的答案。尝试解释现代神经网络很难，但是至关重要。如果我们打算依赖深度学习制造新的 AI、处理敏感的用户数据，或者开药，那么我们必须理解这些模型的工作原理。</p>

<p>很幸运，学界人士也提出了很多对深度学习的理解。以下是几个近期论文示例：</p>

<h2 id="toc_0">Grad-Cam（Selvaraju et. al. 2017）</h2>

<p>使用最后卷积层的梯度生成热力图，突出显示输入图像中的重要像素用于分类。</p>

<h2 id="toc_1">LIME（Ribeiro et. al. 2016）</h2>

<p>使用稀疏线性模型（可轻松识别重要特征）逼近 DNN 的预测。</p>

<p>论文地址：<a href="https://arxiv.org/abs/1602.04938">https://arxiv.org/abs/1602.04938</a></p>

<p>一些中文解读：<a href="https://www.oreilly.com.cn/ideas/?p=563%EF%BC%9B">https://www.oreilly.com.cn/ideas/?p=563；</a><br/>
<a href="http://geek.csdn.net/news/detail/66259">http://geek.csdn.net/news/detail/66259</a></p>

<p>一个例子<br/>
<a href="http://marcotcr.github.io/lime/tutorials/Lime%20-%20basic%20usage%2C%20two%20class%20case.html">http://marcotcr.github.io/lime/tutorials/Lime%20-%20basic%20usage%2C%20two%20class%20case.html</a></p>

<p><a href="https://www.jiqizhixin.com/articles/2017-12-20-2">https://www.jiqizhixin.com/articles/2017-12-20-2</a></p>

<h2 id="toc_2">特征可视化（Olah 2017）</h2>

<p>对于带有随机噪声的图像，优化像素来激活训练的 DNN 中的特定神经元，进而可视化神经元学到的内容。</p>

<h2 id="toc_3">Loss Landscape（Li et. al. 2017）</h2>

<p>可视化 DNN 尝试最小化的非凸损失函数，查看架构／参数如何影响损失情况。</p>

<h2 id="toc_4">关于xgboost</h2>

<p>R: <a href="https://github.com/AppliedDataSciencePartners/xgboostExplainer">https://github.com/AppliedDataSciencePartners/xgboostExplainer</a><br/>
python <a href="https://github.com/gameofdimension/xgboost_explainer">https://github.com/gameofdimension/xgboost_explainer</a></p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2019/7/21</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='8%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html'>8 深度学习</a></span>
          				   
                    

                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15637025345079.html">
                
                  <h1>第一章 引言</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>别人的读后总结，可参考「Deep Learning」读书系列分享（一） | 分享总结</p>

<p><a href="https://www.leiphone.com/news/201708/LEBNjZzvm0Q3Ipp0.html">https://www.leiphone.com/news/201708/LEBNjZzvm0Q3Ipp0.html</a></p>

<h3 id="toc_0">需要明确的几个概念范围</h3>

<p><img src="media/15075611675547/15075613801366.jpg" alt=""/></p>

<p><img src="media/15075611675547/15075614908544.jpg" alt=""/></p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2019/7/21</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='8%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html'>8 深度学习</a></span>
          				   
                    

                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15637025346077.html">
                
                  <h1>第七章 正则化</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>机器学习不止要求在训练数据上有良好的表现，还希望有较好的泛化能力，即在测试数据上也能减少测试误差。这些策略被统称为<strong>正则化</strong></p>

<p>常见的一些正则化方法：</p>

<h2 id="toc_0">1.参数范数惩罚</h2>

<p>即在原有的优化函数中，添加一个对参数的惩罚，来限制模型的学习能力<br/>
<img src="media/15120469131645/15206725126887.jpg" alt=""/></p>

<p>(1) L2参数正则化<br/>
L2正则化/岭回归，又叫权重衰减； 可以参照岭回归<br/>
<img src="media/15120469131645/15206732558707.jpg" alt=""/></p>

<p>(X⊤X + αI)−1 这个新矩阵与原来的是一样的，不同的仅仅是在对 角加了 α。这个矩阵的对角项对应每个输入特征的方差。我们可以看到，L2正则化能 让学习算法 ‘‘感知’’ 到具有较高方差的输入 x，因此与输出目标的协方差较小(相对 增加方差)的特征的权重将会收缩。</p>

<p>（2）L1正则化： 具有稀疏性，很多会衰减成0，所以有时候会用来做变量选择lasso</p>

<h2 id="toc_1">2.作为约束的范数惩罚</h2>

<p>从另一个角度来看这个问题，可以被看做是构造一个广义拉格朗日函数来最小化带约束的函数</p>

<p><img src="media/15120469131645/15206742273357.jpg" alt=""/></p>

<p><img src="media/15120469131645/15206742365336.jpg" alt=""/></p>

<p>最小化约束 + 重投影的角度</p>

<h2 id="toc_2">3.正则化和欠约束问题</h2>

<p>正则化还有个好处可以保证X&#39;X+aI 是可逆的</p>

<h2 id="toc_3">4.数据集增强</h2>

<p>可以通过一些方法在不改变label的情况下自己构造一批数据集，比如图像识别时候对图像的旋转；有些时候也可以通过输入噪声的方式来进行数据集增强。</p>

<h2 id="toc_4">5.噪声鲁棒性</h2>

<ul>
<li>向模型的输入或者是权重中加入噪音。</li>
<li>向输出目标中加入噪音，即标注数据有一定的错误，不是百分百准确的时候。<strong>标签平滑</strong>方法是将0，1分类，变为e/(k-1)和1-e的k个输出的softmax函数。（e是标注的错误率）</li>
</ul>

<h2 id="toc_5">6.半监督学习</h2>

<p>大概意思是说：P(x) 产生的未标记样本和P(x,y)中的标记样本都用 于估计 P(y|x)或者根据x预测y。</p>

<h2 id="toc_6">7.多任务学习</h2>

<p>就是通过合并几个任务中的样例（可以视为对参数施加的软约束），我感觉就是类似于group_lasso这样的，对参数加了一个别的约束，部分样本需要共享同一个参数</p>

<h2 id="toc_7">8.提前终止</h2>

<p><img src="media/15120469131645/15206764319925.jpg" alt=""/><br/>
当训练的能力较强时候会发现，随着训练次数的增加，训练误差在逐步减小，但是测试误差会呈现一个U型状态。即先减小后增加。</p>

<p>不是从模型的优化函数入手，相当于是一个实践的经验技巧。</p>

<p>提前终止具有正则化的效果</p>

<h2 id="toc_8">9.参数绑定和参数共享</h2>

<h2 id="toc_9">10.稀疏表示</h2>

<p>前文所述的权重衰减直接惩罚模型参数。另一种策略是惩罚神经网络中的激活 单元，稀疏化激活单元。这种策略间接地对模型参数施加了复杂惩罚。<br/>
<img src="media/15120469131645/15207643423743.jpg" alt=""/></p>

<h2 id="toc_10">11.Bagging 和其他集成方法</h2>

<p>结合多个模型，进行模型平均</p>

<h2 id="toc_11">12.dropout</h2>

<p>@@@@</p>

<h2 id="toc_12">13.对抗训练</h2>

<h1 id="toc_13">14 切面距离、正切传播和流形正切分类器</h1>

<p>略</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2019/7/21</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='8%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html'>8 深度学习</a></span>
          				   
                    

                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
              


			<div class="row">
			  <div class="large-6 columns">
			  <p class="text-left" style="padding-top:25px;">
			   
			  </p>
			  </div>
			  <div class="large-6 columns">
			<p class="text-right" style="padding-top:25px;">
			 <a href="8 深度学习_1.html">&raquo; Next Page</a> 
			</p>
			  </div>
			</div>
		</div>
	</div><!-- large 8 -->

 <div class="large-4 medium-4 columns">
  <div class="hide-for-small">
    <div id="sidebar" class="sidebar">
          <div id="site-info" class="site-info">
            
                <h1>zhenzhen数据科学笔记</h1>
                <div class="site-des"></div>
                <div class="social">









<a target="_blank" class="github" target="_blank" href="tjzzz.github.io" title="GitHub">GitHub</a>

  <a target="_blank" class="rss" href="atom.xml" title="RSS">RSS</a>
                
              	 </div>
          	</div>

             

              <div id="site-categories" class="side-item ">
                <div class="side-header">
                  <h2>Categories</h2>
                </div>
                <div class="side-content">

      	<p class="cat-list">
        
            <a href="kdd&%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html"><strong>kdd&异常检测</strong></a>
        
            <a href="%E8%BD%A8%E8%BF%B9%E5%88%86%E6%9E%90.html"><strong>轨迹分析</strong></a>
        
            <a href="1%20Tools.html"><strong>1 Tools</strong></a>
        
            <a href="2%20Get%20Data.html"><strong>2 Get Data</strong></a>
        
            <a href="3%20%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96.html"><strong>3 数据可视化</strong></a>
        
            <a href="4%20%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95.html"><strong>4 统计方法</strong></a>
        
            <a href="5%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html"><strong>5 机器学习</strong></a>
        
            <a href="6%20NLP.html"><strong>6 NLP</strong></a>
        
            <a href="7%20CV.html"><strong>7 CV</strong></a>
        
            <a href="8%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html"><strong>8 深度学习</strong></a>
        
            <a href="9%20%E6%AF%94%E8%B5%9B%E5%AD%A6%E4%B9%A0.html"><strong>9 比赛学习</strong></a>
        
            <a href="%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6-%E6%B8%85%E5%8D%95.html"><strong>数据科学-清单</strong></a>
        
            <a href="%E5%85%B6%E4%BB%96.html"><strong>其他</strong></a>
         
        </p>


                </div>
              </div>

              <div id="site-categories" class="side-item">
                <div class="side-header">
                  <h2>Recent Posts</h2>
                </div>
                <div class="side-content">
                <ul class="posts-list">
	      
		      
			      <li class="post">
			        <a href="15687050894061.html">0.综述</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15637036455584.html">1 估计的置信度</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15637037681646.html">1 基础工具包安装pip</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15637025346412.html">1. conda 环境管理</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15637037713554.html">1. 数据可视化概述</a>
			      </li>
		     
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		   
		  		</ul>
                </div>
              </div>
        </div><!-- sidebar -->
      </div><!-- hide for small -->
</div><!-- large 4 -->

</div><!-- row -->

 <div class="page-bottom clearfix">
  <div class="row">
   <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
</div>

        </section>
      </div>
    </div>

  
    

    <script src="asset/js/foundation.min.js"></script>
    <script>
      $(document).foundation();
      function fixSidebarHeight(){
        var w1 = $('.markdown-body').height();
          var w2 = $('#sidebar').height();
          if (w1 > w2) { $('#sidebar').height(w1); };
      }
      $(function(){
        fixSidebarHeight();
      })
      $(window).load(function(){
          fixSidebarHeight();
      });
     
    </script>

    
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>


  </body>
</html>
