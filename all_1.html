<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  zhenzhen学习笔记
  
  </title>
 <meta name="description" content="">
 <link href="atom.xml" rel="alternate" title="zhenzhen学习笔记" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />

    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
    <script src="asset/highlightjs/highlight.pack.js"></script>
    <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
    <script>hljs.initHighlightingOnLoad();</script>
    
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>

<div id="header">
    <h1><a href="index.html">zhenzhen学习笔记</a></h1>
</div>

</nav>
        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; zhenzhen学习笔记</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
      <li><a href="index.html">Home</a></li>
      
        <li class="divider"></li>
        <li><label>1 Tools</label></li>

          
            <li><a title="1 安装-mac" href="15637025344954.html">1 安装-mac</a></li>
          
            <li><a title="git" href="15637037678160.html">git</a></li>
          
            <li><a title="jupyterLab" href="15637037680349.html">jupyterLab</a></li>
          
            <li><a title="markdown" href="15637037679256.html">markdown</a></li>
          
            <li><a title="sublime" href="15637037680741.html">sublime</a></li>
          
            <li><a title="工欲善其事必先利其器——Jupyter notebook" href="15637037683461.html">工欲善其事必先利其器——Jupyter notebook</a></li>
          
            <li><a title="工欲善其事必先利其器——conda" href="15637025346412.html">工欲善其事必先利其器——conda</a></li>
          

      
        <li class="divider"></li>
        <li><label>2 Get Data</label></li>

          
            <li><a title="公开微观数据库 1.0" href="15637025347227.html">公开微观数据库 1.0</a></li>
          

      
        <li class="divider"></li>
        <li><label>3 数据可视化</label></li>

          
            <li><a title="Data product" href="15637037683065.html">Data product</a></li>
          
            <li><a title="rCharts" href="15637037678380.html">rCharts</a></li>
          
            <li><a title="数据可视化(seaborn)" href="15637037713554.html">数据可视化(seaborn)</a></li>
          

      
        <li class="divider"></li>
        <li><label>4 统计方法</label></li>

          
            <li><a title="1 估计的置信度" href="15637036455584.html">1 估计的置信度</a></li>
          
            <li><a title="2 不同设计之间有统计学差异吗" href="15637025346225.html">2 不同设计之间有统计学差异吗</a></li>
          
            <li><a title="3 样本量的确定" href="15637036605080.html">3 样本量的确定</a></li>
          
            <li><a title="关于长点击阈值划分方法" href="15637037730522.html">关于长点击阈值划分方法</a></li>
          
            <li><a title="卡方检验" href="15637025346262.html">卡方检验</a></li>
          
            <li><a title="统计阈值" href="15637037730576.html">统计阈值</a></li>
          

      
        <li class="divider"></li>
        <li><label>5 机器学习</label></li>

          
            <li><a title="3.1 特征处理—— 特征选择" href="15637037691936.html">3.1 特征处理—— 特征选择</a></li>
          
            <li><a title="3.2 特征处理——降维" href="15637037731313.html">3.2 特征处理——降维</a></li>
          
            <li><a title="4.1 回归模型" href="15637037691075.html">4.1 回归模型</a></li>
          
            <li><a title="4.2 回归与分类" href="15637037677393.html">4.2 回归与分类</a></li>
          
            <li><a title="4.3 支持向量机" href="15637037728199.html">4.3 支持向量机</a></li>
          
            <li><a title="4.4 k近邻 —— 非参模型" href="15637037731266.html">4.4 k近邻 —— 非参模型</a></li>
          
            <li><a title="4.5 树模型" href="15637037678245.html">4.5 树模型</a></li>
          
            <li><a title="4.6 集成" href="15637037692016.html">4.6 集成</a></li>
          
            <li><a title="4.7 聚类1" href="15636947700701.html">4.7 聚类1</a></li>
          
            <li><a title="4.7 聚类2——-效果评价" href="15637037683688.html">4.7 聚类2——-效果评价</a></li>
          
            <li><a title="4.8 自适应的基函数——神经网络" href="15637025348085.html">4.8 自适应的基函数——神经网络</a></li>
          
            <li><a title="4.9 深度学习综述" href="15637037686386.html">4.9 深度学习综述</a></li>
          
            <li><a title="FM" href="15637037720747.html">FM</a></li>
          
            <li><a title="FM 模型" href="15637037680228.html">FM 模型</a></li>
          
            <li><a title="query文本聚类" href="15637025345613.html">query文本聚类</a></li>
          
            <li><a title="t-sne" href="15637037679781.html">t-sne</a></li>
          
            <li><a title="xgboost" href="15637025344879.html">xgboost</a></li>
          
            <li><a title="【聚类】-效果评价" href="15637037699016.html">【聚类】-效果评价</a></li>
          
            <li><a title="一、基础篇" href="15637037677178.html">一、基础篇</a></li>
          
            <li><a title="二、起步篇—— 数据预处理[python]" href="15637025346988.html">二、起步篇—— 数据预处理[python]</a></li>
          
            <li><a title="二、起步篇——数据预处理[方法论]" href="15636947700356.html">二、起步篇——数据预处理[方法论]</a></li>
          
            <li><a title="二、起步篇——数据预处理[方法论]" href="15637025346040.html">二、起步篇——数据预处理[方法论]</a></li>
          
            <li><a title="聚类Tools篇" href="15637025345910.html">聚类Tools篇</a></li>
          
            <li><a title="聚类Tools篇" href="15637037682671.html">聚类Tools篇</a></li>
          
            <li><a title="聚类方法-spark的bisecting和streaming" href="15637037731727.html">聚类方法-spark的bisecting和streaming</a></li>
          
            <li><a title="聚类方法Mini Batch KMeans" href="15637025344831.html">聚类方法Mini Batch KMeans</a></li>
          
            <li><a title="视频广告" href="15637025347693.html">视频广告</a></li>
          

      
        <li class="divider"></li>
        <li><label>6 推荐系统</label></li>

          
            <li><a title="章1 基本介绍" href="15637025348511.html">章1 基本介绍</a></li>
          
            <li><a title="章2 利用用户行为数据" href="15637025347286.html">章2 利用用户行为数据</a></li>
          

      
        <li class="divider"></li>
        <li><label>6 文本&视频</label></li>

          
            <li><a title="Face综述" href="15637037688620.html">Face综述</a></li>
          
            <li><a title="face_recgnization" href="15637037690385.html">face_recgnization</a></li>
          
            <li><a title="图像识别模型—— 1.利用已有的进行微调" href="15637037708871.html">图像识别模型—— 1.利用已有的进行微调</a></li>
          

      
        <li class="divider"></li>
        <li><label>7 深度学习</label></li>

          
            <li><a title="3.【解释性】LIME" href="15637037677008.html">3.【解释性】LIME</a></li>
          
            <li><a title="TensorFlow" href="15637037730028.html">TensorFlow</a></li>
          
            <li><a title="[2018-06-25]学习1" href="15637037693934.html">[2018-06-25]学习1</a></li>
          
            <li><a title="【NG-DL】course2_week1 优化网络参数" href="15637025344767.html">【NG-DL】course2_week1 优化网络参数</a></li>
          
            <li><a title="【Tensorflow】week2 Introduction to Computer Vision" href="15637025345757.html">【Tensorflow】week2 Introduction to Computer Vision</a></li>
          
            <li><a title="神经网络解释性问题" href="15637037679634.html">神经网络解释性问题</a></li>
          
            <li><a title="第一章 引言" href="15637025345079.html">第一章 引言</a></li>
          
            <li><a title="第七章 正则化" href="15637025346077.html">第七章 正则化</a></li>
          
            <li><a title="第三章 概率与信息论" href="15637025345792.html">第三章 概率与信息论</a></li>
          
            <li><a title="第二章 线性代数" href="15637025345723.html">第二章 线性代数</a></li>
          
            <li><a title="第五章 机器学习" href="15637025346737.html">第五章 机器学习</a></li>
          
            <li><a title="第八章 深度模型中的优化" href="15637037731128.html">第八章 深度模型中的优化</a></li>
          
            <li><a title="第六章 深度前馈网络" href="15637025345687.html">第六章 深度前馈网络</a></li>
          
            <li><a title="第四章 数值计算" href="15637037679680.html">第四章 数值计算</a></li>
          

      
        <li class="divider"></li>
        <li><label>10 比赛学习</label></li>

          
            <li><a title="比赛学习" href="15637037730631.html">比赛学习</a></li>
          

      
        <li class="divider"></li>
        <li><label>数据科学-清单</label></li>

          
            <li><a title="推荐资源" href="15637037694950.html">推荐资源</a></li>
          
            <li><a title="目录" href="15637025347820.html">目录</a></li>
          
            <li><a title="资源List" href="15637025346338.html">资源List</a></li>
          

      
      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>

        <section id="main-content" role="main" class="scroll-container">

          <div class="row">
            <div class="large-3 medium-3 columns">
              <div class="hide-for-small">
                <div class="sidebar">
                <nav>
                  <ul id="side-nav" class="side-nav">

                    
                      <li class="side-title"><span>1 Tools</span></li>
                        
                          <li><a title="1 安装-mac" href="15637025344954.html">1 安装-mac</a></li>
                        
                          <li><a title="git" href="15637037678160.html">git</a></li>
                        
                          <li><a title="jupyterLab" href="15637037680349.html">jupyterLab</a></li>
                        
                          <li><a title="markdown" href="15637037679256.html">markdown</a></li>
                        
                          <li><a title="sublime" href="15637037680741.html">sublime</a></li>
                        
                          <li><a title="工欲善其事必先利其器——Jupyter notebook" href="15637037683461.html">工欲善其事必先利其器——Jupyter notebook</a></li>
                        
                          <li><a title="工欲善其事必先利其器——conda" href="15637025346412.html">工欲善其事必先利其器——conda</a></li>
                        

                    
                      <li class="side-title"><span>2 Get Data</span></li>
                        
                          <li><a title="公开微观数据库 1.0" href="15637025347227.html">公开微观数据库 1.0</a></li>
                        

                    
                      <li class="side-title"><span>3 数据可视化</span></li>
                        
                          <li><a title="Data product" href="15637037683065.html">Data product</a></li>
                        
                          <li><a title="rCharts" href="15637037678380.html">rCharts</a></li>
                        
                          <li><a title="数据可视化(seaborn)" href="15637037713554.html">数据可视化(seaborn)</a></li>
                        

                    
                      <li class="side-title"><span>4 统计方法</span></li>
                        
                          <li><a title="1 估计的置信度" href="15637036455584.html">1 估计的置信度</a></li>
                        
                          <li><a title="2 不同设计之间有统计学差异吗" href="15637025346225.html">2 不同设计之间有统计学差异吗</a></li>
                        
                          <li><a title="3 样本量的确定" href="15637036605080.html">3 样本量的确定</a></li>
                        
                          <li><a title="关于长点击阈值划分方法" href="15637037730522.html">关于长点击阈值划分方法</a></li>
                        
                          <li><a title="卡方检验" href="15637025346262.html">卡方检验</a></li>
                        
                          <li><a title="统计阈值" href="15637037730576.html">统计阈值</a></li>
                        

                    
                      <li class="side-title"><span>5 机器学习</span></li>
                        
                          <li><a title="3.1 特征处理—— 特征选择" href="15637037691936.html">3.1 特征处理—— 特征选择</a></li>
                        
                          <li><a title="3.2 特征处理——降维" href="15637037731313.html">3.2 特征处理——降维</a></li>
                        
                          <li><a title="4.1 回归模型" href="15637037691075.html">4.1 回归模型</a></li>
                        
                          <li><a title="4.2 回归与分类" href="15637037677393.html">4.2 回归与分类</a></li>
                        
                          <li><a title="4.3 支持向量机" href="15637037728199.html">4.3 支持向量机</a></li>
                        
                          <li><a title="4.4 k近邻 —— 非参模型" href="15637037731266.html">4.4 k近邻 —— 非参模型</a></li>
                        
                          <li><a title="4.5 树模型" href="15637037678245.html">4.5 树模型</a></li>
                        
                          <li><a title="4.6 集成" href="15637037692016.html">4.6 集成</a></li>
                        
                          <li><a title="4.7 聚类1" href="15636947700701.html">4.7 聚类1</a></li>
                        
                          <li><a title="4.7 聚类2——-效果评价" href="15637037683688.html">4.7 聚类2——-效果评价</a></li>
                        
                          <li><a title="4.8 自适应的基函数——神经网络" href="15637025348085.html">4.8 自适应的基函数——神经网络</a></li>
                        
                          <li><a title="4.9 深度学习综述" href="15637037686386.html">4.9 深度学习综述</a></li>
                        
                          <li><a title="FM" href="15637037720747.html">FM</a></li>
                        
                          <li><a title="FM 模型" href="15637037680228.html">FM 模型</a></li>
                        
                          <li><a title="query文本聚类" href="15637025345613.html">query文本聚类</a></li>
                        
                          <li><a title="t-sne" href="15637037679781.html">t-sne</a></li>
                        
                          <li><a title="xgboost" href="15637025344879.html">xgboost</a></li>
                        
                          <li><a title="【聚类】-效果评价" href="15637037699016.html">【聚类】-效果评价</a></li>
                        
                          <li><a title="一、基础篇" href="15637037677178.html">一、基础篇</a></li>
                        
                          <li><a title="二、起步篇—— 数据预处理[python]" href="15637025346988.html">二、起步篇—— 数据预处理[python]</a></li>
                        
                          <li><a title="二、起步篇——数据预处理[方法论]" href="15636947700356.html">二、起步篇——数据预处理[方法论]</a></li>
                        
                          <li><a title="二、起步篇——数据预处理[方法论]" href="15637025346040.html">二、起步篇——数据预处理[方法论]</a></li>
                        
                          <li><a title="聚类Tools篇" href="15637025345910.html">聚类Tools篇</a></li>
                        
                          <li><a title="聚类Tools篇" href="15637037682671.html">聚类Tools篇</a></li>
                        
                          <li><a title="聚类方法-spark的bisecting和streaming" href="15637037731727.html">聚类方法-spark的bisecting和streaming</a></li>
                        
                          <li><a title="聚类方法Mini Batch KMeans" href="15637025344831.html">聚类方法Mini Batch KMeans</a></li>
                        
                          <li><a title="视频广告" href="15637025347693.html">视频广告</a></li>
                        

                    
                      <li class="side-title"><span>6 推荐系统</span></li>
                        
                          <li><a title="章1 基本介绍" href="15637025348511.html">章1 基本介绍</a></li>
                        
                          <li><a title="章2 利用用户行为数据" href="15637025347286.html">章2 利用用户行为数据</a></li>
                        

                    
                      <li class="side-title"><span>6 文本&视频</span></li>
                        
                          <li><a title="Face综述" href="15637037688620.html">Face综述</a></li>
                        
                          <li><a title="face_recgnization" href="15637037690385.html">face_recgnization</a></li>
                        
                          <li><a title="图像识别模型—— 1.利用已有的进行微调" href="15637037708871.html">图像识别模型—— 1.利用已有的进行微调</a></li>
                        

                    
                      <li class="side-title"><span>7 深度学习</span></li>
                        
                          <li><a title="3.【解释性】LIME" href="15637037677008.html">3.【解释性】LIME</a></li>
                        
                          <li><a title="TensorFlow" href="15637037730028.html">TensorFlow</a></li>
                        
                          <li><a title="[2018-06-25]学习1" href="15637037693934.html">[2018-06-25]学习1</a></li>
                        
                          <li><a title="【NG-DL】course2_week1 优化网络参数" href="15637025344767.html">【NG-DL】course2_week1 优化网络参数</a></li>
                        
                          <li><a title="【Tensorflow】week2 Introduction to Computer Vision" href="15637025345757.html">【Tensorflow】week2 Introduction to Computer Vision</a></li>
                        
                          <li><a title="神经网络解释性问题" href="15637037679634.html">神经网络解释性问题</a></li>
                        
                          <li><a title="第一章 引言" href="15637025345079.html">第一章 引言</a></li>
                        
                          <li><a title="第七章 正则化" href="15637025346077.html">第七章 正则化</a></li>
                        
                          <li><a title="第三章 概率与信息论" href="15637025345792.html">第三章 概率与信息论</a></li>
                        
                          <li><a title="第二章 线性代数" href="15637025345723.html">第二章 线性代数</a></li>
                        
                          <li><a title="第五章 机器学习" href="15637025346737.html">第五章 机器学习</a></li>
                        
                          <li><a title="第八章 深度模型中的优化" href="15637037731128.html">第八章 深度模型中的优化</a></li>
                        
                          <li><a title="第六章 深度前馈网络" href="15637025345687.html">第六章 深度前馈网络</a></li>
                        
                          <li><a title="第四章 数值计算" href="15637037679680.html">第四章 数值计算</a></li>
                        

                    
                      <li class="side-title"><span>10 比赛学习</span></li>
                        
                          <li><a title="比赛学习" href="15637037730631.html">比赛学习</a></li>
                        

                    
                      <li class="side-title"><span>数据科学-清单</span></li>
                        
                          <li><a title="推荐资源" href="15637037694950.html">推荐资源</a></li>
                        
                          <li><a title="目录" href="15637025347820.html">目录</a></li>
                        
                          <li><a title="资源List" href="15637025346338.html">资源List</a></li>
                        

                    
                  </ul>
                </nav>
                </div>
              </div>
            </div>
            <div class="large-9 medium-9 columns">

 


	
		<div class="markdown-body">
		<h1>3.2 特征处理——降维</h1>

		<p>关于降维的讨论主要是来源于“维度灾难”, 这个是数学家理查德-贝尔曼提出的。</p>

<blockquote>
<p>当所有参数是已知的时候，维度的增加可以让分类问题的错误率渐近为0.<br/>
当未知参数只能根据有限样本来估计时，维度的增加使错误率先降低后增加，最终收敛到0.5</p>
</blockquote>

<p>维数灾难的本质原因在于<code>数据样本的有限性</code>。而在数据有限的条件下，去解决维度问题，自然的方法就是去降维。降维的方法有很多</p>

<h2 id="toc_0">1. 常用的线性降维方法：</h2>

<ul>
<li>PCA 主成分分析</li>
<li>IDA</li>
<li>LDA</li>
</ul>

<h2 id="toc_1">2.非线性的方法——流形</h2>

<p><strong>流形</strong><br/>
是指嵌入在高维空间中的低维子空间，它的维度是低维数据变化的自由度。（比如地球仪的球面，虽然它是在一个三维空间中，但其实是一个二维的地图卷曲而成，\(x^2+y^2+z^2=1\)，维度是2）</p>

<p><strong>流形学习</strong><br/>
就是通过挖掘数据的内在结构实现向故由维度的转化，找到对应的低维嵌入流形。其大部分是非线性的、非参的。所以相比线性方法有更强的表达能力，但是同时对噪声更加敏感。</p>

<p><strong>流形学习方法</strong></p>

<p>流形学习，首先需要确定低维流形的结构，然后是高维到低维的映射关系。实际中因为都未知，所以需要做一些假设。</p>

<blockquote>
<ul>
<li>多维缩放MDS (multi dimensional scaling)</li>
</ul>
</blockquote>

<p>原则:让高维空间上样本之间的距离在低维空间中尽量保持一致以距离重建的误差最小为优化目标。</p>

<p>具体来说：</p>

<p>(1) 对于原始的数据\(X_{np}\),首先可以计算出任何两个样本之间的距离，从而构造出一个距离矩阵\(D\)，MDS算法的目的就是根据距离矩阵，寻找向量\(Z_1,Z_2...Z_k\),使得\(||Z_i-Z_j||≈\sigma_{ij}\)</p>

<p>假设\(Z\)是经过中心化处理过的，即\(\sum z_i = 0\) , 则有</p>

<p>\[XX^T = D≈ZZ^T\]</p>

<p>看到这个形式，应该就能明白怎么取解了。对D做特征分解\(D=VAV^T\)， V是对应的特征向量，我们选择前k个特征值比较大的作为最终的降维维度即可。</p>

<p><code>问题：高维空间的距离与低维空间距离保持一致这个假设是否合理？</code></p>

<p>以地球仪的球面为例，三维空间中两个点的距离和平面中两个点的距离显然是不一样的。三维空间中如果用欧式距离去度量那么北京与纽约的距离是连接两点的直线，而在平面上他是一条曲线。</p>

<pre><code># MDS
mds = manifold.MDS(n_components, max_iter=100, n_init=1)
Y = mds.fit_transform(X)
</code></pre>

<p>下面再说一些以几何性质作为同构基础的降维方法</p>

<blockquote>
<ul>
<li>等度量映射Isomap</li>
</ul>
</blockquote>

<p>等度量映射，以数据所在的低维流形与欧式空间子集的等距性为基础。描述距离的是<strong>测地距离</strong>，即流形上两点的真实距离。测地距离的近似计算方法：近邻点之间的欧式距离近似为近邻点之间的测地距离。</p>

<p>通过对每一个近邻点建立连接，就可以让所有数据点共同构成一张带权重的近邻连接图。这样在这张图上任意两个点的测地距离就相当于是两点之间的最短路径。可以用图论中的Dijkstra算法求解。</p>

<p>当计算出距离后，剩下的处理方法和MDS一致。所以总的来说包括三步：<br/>
(1) 最近邻搜索<br/>
(2) 最短路径搜索<br/>
(3) 部分特征值分解</p>

<pre><code>model = manifold.Isomap(n_neighbors, n_components)
Y = model.fit_transform(X)
</code></pre>

<blockquote>
<ul>
<li>局部线性嵌入LLE(local linear embedding)</li>
</ul>
</blockquote>

<p>想法：待求解的低维流形在局部上是线性的，每个点可以表示成近邻点的线性组合。而局部线性嵌入就是在求解流形的过程中保持每个领域中的线性系数不变的基础上重构原数据点。</p>

<p>详细的推导过程<a href="https://blog.csdn.net/yukgwy60648/article/details/54578141">https://blog.csdn.net/yukgwy60648/article/details/54578141</a></p>

<pre><code># 其中method可选 [&#39;standard&#39;, &#39;ltsa&#39;, &#39;hessian&#39;, &#39;modified&#39;]
model = manifold.LocallyLinearEmbedding(n_neighbors, n_components, eigen_solver=&#39;auto&#39;, method=method)
Y = model.fit_transform(X)
</code></pre>

<p>从概率角度</p>

<blockquote>
<ul>
<li>随机近邻嵌入 SNE</li>
</ul>
</blockquote>

<p>随机近邻嵌入的特点：保持数据降维前后的概率分布不变,他将高维空间中的距离首先映射到了一个服从正态分布的条件概率上。这个概率描述了不同数据点之间的相似性。</p>

<p>\[p_{j|i}=\frac{exp(-||x_j-x_i||^2/2\sigma^2_i)}{\sum_{k\ne i}exp(-||x_k-x_i||^2/2\sigma^2_i)}\]</p>

<p>映射到低维空间后，按照同样方式计算条件概率，希望连个概率分布尽量一致。这里是KL散度最小化<br/>
\[KL(P||Q) = -\sum P_i ln(\frac{P_i}{Q_i})=-\sum P_i(ln(P_i)- ln(Q_i))\]</p>

<p><code>问题</code>：<br/>
KL距离是不对称的，会导致相聚较远的点出现较大的散度差。为了是KL距离最小化，数据就会被压缩到极小的范围，产生拥挤问题。</p>

<p><code>改进</code><br/>
* 将KL散度改为对称形式 \(p_{ij}=p_{ji}=(p_{i|j}+p_{j|i})/2\)<br/>
* 令低维空间中的条件概率服从t分布，t分布有长尾效应，从而使高维中分布较远的点降维后也能区分开</p>

<pre><code>tsne = manifold.TSNE(n_components=n_components, init=&#39;pca&#39;, random_state=0)
Y = tsne.fit_transform(X)
</code></pre>

<p><img src="media/15382821564829/15383222417494.jpg" alt=""/></p>

<h2 id="toc_2">小结</h2>

<ul>
<li><p>本章主要知识结构<br/>
<img src="https://upload-images.jianshu.io/upload_images/127231-bf906252693ca552.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"/></p></li>
<li><p>sklearn中关于流形学习内容都在<code>sklearn.manifold</code>模块。<br/>
官网示例 <a href="http://sklearn.apachecn.org/cn/0.19.0/auto_examples/manifold/plot_compare_methods.html#sphx-glr-auto-examples-manifold-plot-compare-methods-py">http://sklearn.apachecn.org/cn/0.19.0/auto_examples/manifold/plot_compare_methods.html#sphx-glr-auto-examples-manifold-plot-compare-methods-py</a></p></li>
<li><p>参考文档<br/>
<a href="https://blog.csdn.net/yukgwy60648/article/details/54578141">https://blog.csdn.net/yukgwy60648/article/details/54578141</a><br/>
sklearn—文档 <a href="http://scikit-learn.org/stable/modules/manifold.html">http://scikit-learn.org/stable/modules/manifold.html</a><br/>
<a href="http://sklearn.apachecn.org/cn/0.19.0/modules/manifold.html">http://sklearn.apachecn.org/cn/0.19.0/modules/manifold.html</a></p></li>
</ul>


		</div>
	

 
	

 
	

 
	

 
	

  
  
</div></div>


<div class="page-bottom">
  <div class="row">
  <hr />
  <div class="small-9 columns">
  <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
  <div class="small-3 columns">
  <p class="copyright text-right"><a href="#header">TOP</a></p>
  </div>
   
  </div>
</div>

        </section>
      </div>
    </div>
    
    
    <script src="asset/js/foundation.min.js"></script>
    <script src="asset/js/foundation/foundation.offcanvas.js"></script>
    <script>
      $(document).foundation();

     
    </script>
    
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>

  </body>
</html>
