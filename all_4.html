
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>
  
  
  

  </title>
  <meta name="author" content="">
  <meta name="description" content="">

  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link href="asset/css/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="atom.xml" rel="alternate" title="" type="application/atom+xml">
  <script src="asset/js/modernizr-2.0.js"></script>
  <script src="asset/js/jquery.min.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/solarized_light.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>

  <style type="text/css">
  .cat-children-p{ padding: 6px 0px;}
  .hljs{background: none;}
  </style>
  <script type="text/javascript">
  var isAddSildbar = true;
  </script>
  <script src="asset/js/octopress.js" type="text/javascript"></script>
</head>
<script type="text/javascript">
//链接新开窗口
function addBlankTargetForLinks () {
  $('a[href^="http"]').each(function(){
      $(this).attr('target', '_blank');
  });
}
$(document).ready(function(event) {
  addBlankTargetForLinks();
});
</script>
<body   >
  <header role="banner"><hgroup>
  <h1><a href="index.html"></a></h1>
  
    <h2></h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">

  <li id=""><a target="self" href="index.html">Home</a></li>

  <li id=""><a target="_self" href="archives.html">Archives</a></li>

</ul>

</nav>
  <div id="main">
    <div id="content"> 
<div class="blog-index">

	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15343431925455.html">二、起步篇—— 数据预处理[python]</a></h1>
			<p class="meta"><time datetime="2018-08-15T22:26:32+08:00" 
			pubdate data-updated="true">2018/8/15</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<blockquote>
<p>一方面可以多查些官方说明<br/>
多去看些kaggle，tianchi等的比赛案例，他们数据预处理做的很全面到位<br/>
实践一些工作中的项目，将代码规范化</p>
</blockquote>

<h2 id="toc_0">1.缺失表示</h2>

<p>python中缺失是nan，如果本身数据中缺失是用其他方式表示的，可以先转换一下<br/>
<code>df.replace(&#39;-&#39;,np.nan)</code></p>

<pre><code class="language-python">
import numpy as np
import pandas as pd
from io import StringIO
import sys

df = pd.read_table(&#39;zz&#39;)
df = df.replace(&#39;-&#39;,np.nan).head()
df.head()
</code></pre>

<h2 id="toc_1">2.缺失的简单处理办法</h2>

<h3 id="toc_2">暴力删除</h3>

<p><code>isnull()</code>   判断是否缺失</p>

<p><code>dropna( axis = 0 /1 )</code> 参数axis表示轴选择，axis=0 代表行，axis=1 代表列</p>

<p><code>dropna(subset=[&#39;&#39;])</code>   删除指定列中有空值的一行数据</p>

<h3 id="toc_3">默认值填充</h3>

<p><code>df.fillna(value)</code><br/>
或者对不同列填不同的值</p>

<h3 id="toc_4">统计/算法填充</h3>

<pre><code class="language-python">from sklearn.preprocessing import Imputer
# strategy 有mean,median, most_frequent 方式
# axis 默认是0，列向， axis=1行向
dff = df.loc[:, [&#39;comment_time&#39;]]
imr = Imputer(missing_values = &#39;NaN&#39;, strategy = &#39;mean&#39;, axis = 0 )
imr = imr.fit(dff.values)
imputed_data = imr.transform(dff.values)
</code></pre>

<pre><code class="language-python">## 3.分类数据处理
from sklearn.preprocessing import LabelEncoder
class_le = LabelEncoder()
y = class_le.fit_transform(df[&#39;nid&#39;].values)

</code></pre>

<pre><code class="language-python">## 数据标准化
from sklearn.preprocessing import MinMaxScaler
mms = MinMaxScaler()
X_train_norm = mms.fit_transform(imputed_data)
X_test_norm = mms.transform(imputed_data)
</code></pre>

<h2 id="toc_5">参考资料</h2>

<p><a href="https://blog.csdn.net/Amy_mm/article/details/79799629">https://blog.csdn.net/Amy_mm/article/details/79799629</a><br/>
<a href="https://www.cnblogs.com/charlotte77/p/5622325.html">https://www.cnblogs.com/charlotte77/p/5622325.html</a></p>

<p><a href="https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python">https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15340577552786.html">face_recgnization</a></h1>
			<p class="meta"><time datetime="2018-08-12T15:09:15+08:00" 
			pubdate data-updated="true">2018/8/12</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>github<br/>
<a href="https://github.com/ageitgey/face_recognition">https://github.com/ageitgey/face_recognition</a></p>

<h2 id="toc_0">1. 安装</h2>

<p>文档： <a href="https://zhuanlan.zhihu.com/p/28271869">https://zhuanlan.zhihu.com/p/28271869</a></p>

<pre><code>pip install face_recognition
</code></pre>

<p>直接安装会报错，安装face_recognition这个之前需要先安装编译dlib</p>

<pre><code>brew install boost
brew install boost-python --with-python3

# install dlib
git clone https://github.com/davisking/dlib.git
cd dlib
mkdir build; cd build; cmake .. -DDLIB_USE_CUDA=0 -DUSE_AVX_INSTRUCTIONS=1; cmake --build 

cd ..
python setup.py install --yes USE_AVX_INSTRUCTIONS --no DLIB_USE_CUDA
</code></pre>

<p>If there is no cmake on your mac, you can use  <code>brew install cmake</code>. After all these have been done, run</p>

<pre><code>pip install face_recognition
</code></pre>

<h2 id="toc_1">2.usage</h2>

<p>face_recognition有两种使用方式，命令行方式和python包方式</p>

<p>(1) 命令行方式</p>

<p>(2) python 包<br/>
<a href="https://face-recognition.readthedocs.io/en/latest/face_recognition.html#module-face_recognition.api">https://face-recognition.readthedocs.io/en/latest/face_recognition.html#module-face_recognition.api</a></p>

<p></p>

<h2 id="toc_2">参考资料</h2>

<p><a href="https://zhuanlan.zhihu.com/p/28271869">https://zhuanlan.zhihu.com/p/28271869</a></p>

<p><a href="https://medium.com/@ageitgey">https://medium.com/@ageitgey</a></p>

<hr/>

<p><a href="https://www.jianshu.com/p/281aa6a3823a">https://www.jianshu.com/p/281aa6a3823a</a></p>

<p>一个案例<br/>
<a href="https://www.jianshu.com/p/38ca6daf6b40">https://www.jianshu.com/p/38ca6daf6b40</a><br/>
<a href="http://www.opencv.org.cn/opencvdoc/2.3.2/html/doc/tutorials/tutorials.html">http://www.opencv.org.cn/opencvdoc/2.3.2/html/doc/tutorials/tutorials.html</a></p>

<p>tf案例<br/>
<a href="https://blog.csdn.net/u010016927/article/details/75722416">https://blog.csdn.net/u010016927/article/details/75722416</a></p>

<p>knn<br/>
<a href="https://www.leiphone.com/news/201707/gIbNsPtWk460m5vj.html">https://www.leiphone.com/news/201707/gIbNsPtWk460m5vj.html</a></p>

<p><a href="https://blog.csdn.net/Mbx8X9u/article/details/79124840">https://blog.csdn.net/Mbx8X9u/article/details/79124840</a></p>

<p><a href="https://www.ctolib.com/topics-101544.html">https://www.ctolib.com/topics-101544.html</a></p>

<p><a href="https://www.oschina.net/code/snippet_2558914_54339">https://www.oschina.net/code/snippet_2558914_54339</a></p>

<h2 id="toc_3">new</h2>

<p><a href="https://www.leiphone.com/news/201704/rYdpAvh4SvgVPpRQ.html">https://www.leiphone.com/news/201704/rYdpAvh4SvgVPpRQ.html</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15334844213158.html">二、起步篇——数据预处理[方法论]</a></h1>
			<p class="meta"><time datetime="2018-08-05T23:53:41+08:00" 
			pubdate data-updated="true">2018/8/5</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p><img src="media/15334844213158/15335717779664.jpg" alt=""/></p>

<h2 id="toc_0">1.数据偏度</h2>

<p>数据的处理，从数据特征本身的统计维度看，有尺度、偏度、</p>

<p>1.数据尺度</p>

<ul>
<li>标准化 =&gt; 均值0，方差1</li>
<li>归一化 =&gt; [0,1]</li>
</ul>

<p>2.数据偏度<br/>
可以通过偏度来度量，数据中如果存在较大的偏度，可能是因为有异常点的存在。</p>

<p>有偏数据处理，一般可以取log，或者开根号让他能近似正态</p>

<h2 id="toc_1">2.异常点</h2>

<p>首先什么是异常点<br/>
异常点<br/>
（1） 首先确认是不是错误导致，比如计算错误。取值错误<br/>
（2）确认异常点的生成机制</p>

<p>（1）异常点检测</p>

<p>@@@<br/>
sklearn中常用的包</p>

<p>（2）异常点处理</p>

<ul>
<li>如果是少量可以直接删除</li>
<li>当数据量较少，删除后造成可用信息较少时候，可以使用“空间标识”的数值处理方法</li>
</ul>

<h2 id="toc_2">3.缺失值</h2>

<p>缺失机制：随机缺失，还是非随机缺失</p>

<p>补充原则：</p>

<ul>
<li>如果缺失占比太大，删除</li>
</ul>

<p>补充方法：</p>

<ul>
<li>统计方法：均值</li>
<li>机器学习方法：回归、K近邻</li>
</ul>

<h2 id="toc_3">4.特征冗余</h2>

<p>一般是说特征自相关性太高，即“共线性”。另外是指一些没有区分度的变量，比如一是特征取值的总数与样本数目的比例在 10% 以下，二是出现频率最高的特征取值的出现频率应该在出现频率次高的特征的20倍以上。</p>

<p>检测办法：<br/>
解决办法：PCA</p>

<h2 id="toc_4">参考文章</h2>

<p>离群点</p>

<p><a href="https://blog.chih.me/Outlier-mining-review.html">https://blog.chih.me/Outlier-mining-review.html</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15318267888584.html">目录结构</a></h1>
			<p class="meta"><time datetime="2018-07-17T19:26:28+08:00" 
			pubdate data-updated="true">2018/7/17</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<ol>
<li><p>统计学习理论</p></li>
</ol>

<ul>
<li>可学习</li>
<li>模型设计</li>
<li><p>基础知识偏——统计</p></li>
</ul>

<ol>
<li><p>数据&amp;特征</p></li>
</ol>

<ul>
<li>数据清洗</li>
<li>特征提取</li>
<li>降维</li>
</ul>

<p>3 模型部分</p>

<ul>
<li>无监督</li>
<li>有监督

<ul>
<li>回归</li>
<li>分类</li>
</ul></li>
</ul>

<h3 id="toc_0">补充</h3>

<p>LR 在多分类情况下 -李航</p>

<p>关于凸优化的</p>

<p>SVM 优化SMO算法 + sklearn的区别</p>

<h2 id="toc_1">可参照资料</h2>

<p>coursera<br/>
<a href="https://www.coursera.org/learn/competitive-data-science/home/welcome">https://www.coursera.org/learn/competitive-data-science/home/welcome</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15316431193074.html">一、基础篇</a></h1>
			<p class="meta"><time datetime="2018-07-15T16:25:19+08:00" 
			pubdate data-updated="true">2018/7/15</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<h1 id="toc_0">1.计算学习理论——是否可学习</h1>

<p>一直在说机器学习，主要是在说怎么去学。在怎么学之前，首先需要了解下能不能学，学习的机制是什么</p>

<h2 id="toc_1">PAC（概率近似正确）</h2>

<p><a href="https://blog.csdn.net/wangjianguobj/article/details/57413819">https://blog.csdn.net/wangjianguobj/article/details/57413819</a></p>

<h2 id="toc_2">VC维度</h2>

<p>这个介绍的挺详细<br/>
<a href="http://www.flickering.cn/machine_learning/2015/04/vc%E7%BB%B4%E7%9A%84%E6%9D%A5%E9%BE%99%E5%8E%BB%E8%84%89/?from=singlemessage">http://www.flickering.cn/machine_learning/2015/04/vc%E7%BB%B4%E7%9A%84%E6%9D%A5%E9%BE%99%E5%8E%BB%E8%84%89/?from=singlemessage</a></p>

<h2 id="toc_3">参考</h2>

<p>台大-机器学习基石</p>

<h1 id="toc_4">6.模型设计准则</h1>

<ol>
<li>模型拟合</li>
</ol>

<p>(1) 无免费午餐定理 NFL</p>

<p>就是任何一个算法，针对所有问题，在平均意义上效果是一样的。</p>

<p>=&gt; 所以要具体问题具体分析，针对不同问题，选择适合该问题的方法</p>

<p>(2)奥卡姆剃刀原则</p>

<p>即在预测效果差不多的情况下，模型越简单余越好</p>

<p>误差 = bias + varaince + noise</p>

<ul>
<li>过拟合</li>
<li>欠拟合</li>
</ul>

<h1 id="toc_5">7.模型验证</h1>

<p>1.估计泛化误差</p>

<p>训练集，验证集</p>

<p>2.对数据的重采样</p>

<ul>
<li>留出法</li>
<li>k折交叉验证</li>
<li>自助法(有放回)</li>
</ul>

<h1 id="toc_6">8.模型的评估指标</h1>

<h1 id="toc_7">9.实验设计</h1>

<p>设计实验是要要成的任务是对整个机器学习过程的优化。实验中因子的设计可能会包含很多，比如：算法的类别、算法的参数、数据集等。</p>

<p>当因子较多的时候，如何确定单一因子的影响就需要一些技巧<br/>
<strong>控制变量法</strong></p>

<p>它暗含着一个较强的假设，就是不同因子之间相互独立，互不影响。然而这个并不总是成立的。</p>

<p><strong>因子设计</strong><br/>
他关注的是不同因子之间系统化的变化对学习效果的影响，他的一个特例就是<strong>全因子实验</strong>，也叫<strong>完全交叉设计</strong>。</p>

<p>在具体操作的时候，当分析的因子的离散取值较多时候，可以通过粗调+微调的方法。</p>

<p>在对因子进行精调时候，可以使用<strong>响应面方法</strong>（zzz:根据百科资料解释,就是做了一个二次函数的拟合）</p>

<h2 id="toc_8">正交抽样设计</h2>

<p>@@@补充下：</p>


		</div>

		

	</article>
  
	<div class="pagination">
	 <a class="prev" href="all_5.html">&larr; Older</a> 
<a href="archives.html">Blog Archives</a>
	 <a class="next" href="all_3.html">Newer &rarr;</a>  
	    
	</div>
</div>
 <aside class="sidebar"> 

	<section>
	  <h1>Categories</h1>
	  <ul id="recent_posts">
	  
	      <li class="post">
	        <a href="%E4%BD%A0%E4%B8%8D%E5%BE%97%E4%B8%8D%E7%9F%A5%E7%9A%84%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95.html"><strong>你不得不知的统计方法&nbsp;(3)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3%E7%BA%B3%E7%B1%B3%E5%AD%A6%E4%BD%8D.html"><strong>Udacity.DL&nbsp;(3)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="DL.html"><strong>Ng.DL&nbsp;(3)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="book.DL.html"><strong>book.DL&nbsp;(8)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html"><strong>机器学习&nbsp;(23)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F.html"><strong>推荐系统&nbsp;(3)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="NLP&%E5%9B%BE%E5%83%8F.html"><strong>NLP&图像&nbsp;(4)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96.html"><strong>数据可视化&nbsp;(7)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="0.%20%E8%B5%84%E6%BA%90%E5%AF%BC%E8%88%AA.html"><strong>0. 资源导航&nbsp;(3)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="data.html"><strong>data&nbsp;(1)</strong></a>
	        
	        
	        
	      </li>
	   
	  </ul>
	</section>
	<section>
	  <h1>Recent Posts</h1>
	  <ul id="recent_posts">
	  
	      
		      <li class="post">
		        <a href="15516671779096.html">list</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15479712192030.html">R 数据透视表</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15456330400571.html">统计阈值</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15394437873112.html">4.9 深度学习综述</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15394428762655.html">4.8 自适应的基函数——神经网络</a>
		      </li>
	     
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	   
	  </ul>
	</section>
	
</aside> </div></div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 -  -
  <span class="credit">Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a> &nbsp;&nbsp; Theme by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>

  
    


<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>

</body>
</html>