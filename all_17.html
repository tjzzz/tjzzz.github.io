
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>
    
  学习笔记
  

  </title>
  <meta name="author" content="">
  <meta name="description" content="">

  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link href="asset/css/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="atom.xml" rel="alternate" title="学习笔记" type="application/atom+xml">
  <script src="asset/js/modernizr-2.0.js"></script>
  <script src="asset/js/jquery.min.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/solarized_light.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>

  <style type="text/css">
  .cat-children-p{ padding: 6px 0px;}
  .hljs{background: none;}
  </style>
  <script type="text/javascript">
  var isAddSildbar = true;
  </script>
  <script src="asset/js/octopress.js" type="text/javascript"></script>
</head>
<script type="text/javascript">
//链接新开窗口
function addBlankTargetForLinks () {
  $('a[href^="http"]').each(function(){
      $(this).attr('target', '_blank');
  });
}
$(document).ready(function(event) {
  addBlankTargetForLinks();
});
</script>
<body   >
  <header role="banner"><hgroup>
  <h1><a href="index.html">学习笔记</a></h1>
  
    <h2></h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">

  <li id=""><a target="self" href="index.html">Home</a></li>

  <li id=""><a target="_self" href="archives.html">Archives</a></li>

</ul>

</nav>
  <div id="main">
    <div id="content"> 
<div class="blog-index">

	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15082571023160.html">第五章 机器学习</a></h1>
			<p class="meta"><time datetime="2017-10-18T00:18:22+08:00" 
			pubdate data-updated="true">2017/10/18</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>这部分主要是补充了机器学习的一席基础知识点，这里先略过。后期再进行相应的补充。具体包括</p>

<ul>
<li><p>容量/过拟合/欠拟合</p></li>
<li><p>估计/偏差/方差</p></li>
<li><p>最大似然估计</p></li>
<li><p>贝叶斯统计</p></li>
<li><p>监督学习算法</p></li>
<li><p>无监督学习算法</p>

<ul>
<li>PCA</li>
<li>聚类</li>
</ul></li>
<li><p>梯度下降</p></li>
</ul>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15080580137304.html">第四章 数值计算</a></h1>
			<p class="meta"><time datetime="2017-10-15T17:00:13+08:00" 
			pubdate data-updated="true">2017/10/15</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<h2 id="toc_0">1.数值精度</h2>

<p>这部分对于了解具体的算法并没影响，但是在进行底层库开发时候经常会遇到，可能会出现<strong>上溢</strong>或者<strong>下溢</strong></p>

<p>（1）病态条件</p>

<p>条件数：表示函数相对于输入的微小变化而变化的快慢程度。<br/>
比如矩阵求逆运算的条件数=最大和最小特征值的模的比</p>

<h2 id="toc_1">2.优化算法</h2>

<ul>
<li>梯度下降</li>
<li>牛顿法</li>
</ul>

<p>一般把需要最优化的函数称为<strong>目标函数</strong></p>

<p><strong>梯度下降</strong></p>

<p>对于一个多维输入函数f，梯度\(\triangledown_x f(x)\),其在u方向上的<strong>方向导数</strong>，相当于f在u方向上的斜率<br/>
\(f(x+\alpha u)\)关于\(\alpha\)的导数(在\(\alpha =0\)时取得)</p>

<p>\[\frac{\partial}{\partial \alpha}f(x+\alpha u)=u^T\triangledown_x f(x)\]</p>

<p>为了是f最小，希望找到f下降最快的方向，因此有<br/>
\[min u^T\triangledown_x f(x)\]<br/>
u取为单位向量，很明显是在u和f夹角180时候，也就是两个完全相反的时候，下降最快。<br/>
梯度下降： \(x&#39;=x-\epsilon \triangledown_x f(x)\)</p>

<p><strong>牛顿法</strong></p>

<p>Hessian矩阵，二阶导数<br/>
<img src="media/15080580137304/15082408605128.jpg" alt=""/></p>

<h2 id="toc_2">3.有限制的约束</h2>

<p>对于有限制的优化，有时候可以将约束条件转化到原始的优化函数中，这里主要介绍一下通用的方法：<strong>KKT方法</strong>(拉格朗日方法的推广，可以非等式约束)</p>

<pre><code>@@@
http://blog.csdn.net/mr_kktian/article/details/53750424
</code></pre>

<h2 id="toc_3">参考资料</h2>

<p>梯度下降法 扩展阅读： <a href="https://www.jiqizhixin.com/articles/2016-11-21-4">https://www.jiqizhixin.com/articles/2016-11-21-4</a><br/>
<a href="http://www.cnblogs.com/maybe2030/p/4751804.html">http://www.cnblogs.com/maybe2030/p/4751804.html</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15080561019055.html">第三章 概率与信息论</a></h1>
			<p class="meta"><time datetime="2017-10-15T16:28:21+08:00" 
			pubdate data-updated="true">2017/10/15</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>本章主要是介绍了一些概率论的基础以及常见的分布</p>

<h2 id="toc_0">1.常用函数的有用性质</h2>

<ul>
<li>sigmoid 函数</li>
</ul>

<p>\[\delta(x) = \frac{1}{1+exp(-x)}\]</p>

<ul>
<li>softplus函数
\[log(1+exp(x))\]
<img src="media/15080561019055/15080571562017.jpg" alt=""/></li>
</ul>

<p>是\(y=max(0,x)\)的平滑版本</p>

<h2 id="toc_1">2.信息论</h2>

<p>信息论是应用数学的一个分支，主要研究的是对一个信号包含信息的多少进行量化。<br/>
<img src="media/15080561019055/15080594230903.jpg" alt=""/></p>

<p>自信息：定义一个时间X=x的自信息<br/>
\[I(x) = -log P(x)\]</p>

<p>熵：<br/>
\[-\sum P(x_i) logP(x_i)\]</p>

<h3 id="toc_2">KL散度/相对熵</h3>

<p>\[KL(P||Q) = -\sum P_i ln(\frac{P_i}{Q_i})=-\sum P_i(ln(P_i)- ln(Q_i))\]</p>

<p>注意：</p>

<ul>
<li>KL距离其实并不是严格的距离，不满足对称性以及三角不等式。</li>
</ul>

<p>JS距离：<br/>
\[JS(P1||P2) = \frac{1}{2}KL(P1||(P1+P2)/2)+ \frac{1}{2}KL(P2||(P1+P2)/2)\]</p>

<h3 id="toc_3">交叉熵</h3>

<p>相对熵的第一部分<br/>
\[KL(P||Q) = -\sum P_i ln(Q_i)\]</p>

<h2 id="toc_4">3.结构化概率模型——图模型(graphical model)</h2>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15080506207071.html">第二章 线性代数</a></h1>
			<p class="meta"><time datetime="2017-10-15T14:57:00+08:00" 
			pubdate data-updated="true">2017/10/15</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>第二章主要是介绍了线性代数的一些基础知识</p>

<p>这里补充几点吧</p>

<h2 id="toc_0">特征分解</h2>

<p>每个矩阵可以视为多个列向量组成的一个向量空间/或者是一个线性变化(一个矩阵乘以一个向量后相当于是对向量做了一个线性变换)。而矩阵的分解，相当于去提取这个向量空间最重要的特征。</p>

<p>(1)首先是特征值和特征向量<br/>
若<strong>方阵</strong>A满足 \(Av=\lambda v\),则\(v\)称为矩阵A的特征向量，\(\lambda\)称为对应的特征值。</p>

<p><strong>特征分解</strong><br/>
\[A=V \Lambda V^{-1}\]<br/>
V是其特征向量构成的矩阵，\(\Lambda\)是特征值构成的对角矩阵</p>

<p>性质：</p>

<p>(1) 实对称矩阵A都可以分解为\(A=Q\Lambda Q^{-1}\)，Q为正交矩阵</p>

<p>(2)用来计算矩阵的逆。若\(A=Q \Lambda Q^{-1}\)，则\(A^{-1}=Q \Lambda^{-1}Q^{-1}\)</p>

<h2 id="toc_1">奇异值分解</h2>

<p>特征分解对于提取矩阵的特征根是很好的方法，但是他只能针对<strong>方阵</strong>操作。当A不是方阵时候，就需要用到SVD<br/>
\[A_{n*m}=U_{n*n}\Sigma_{n*m} V^{T}_{m*m}\]</p>

<p>其中，U称为左奇异向量，V称为右奇异向量</p>

<p>\(AA^T=UDV^TVDU^T=UD^2U^T\)<br/>
\(A^TA=VDU^T UDV^T=VD^2V^T\)<br/>
即：<br/>
A的左奇异向量是\(AA^T\)的特征向量，A的右奇异向量是\(A^TA\)的特征向量，A的奇异值是\(AA^T\)也是\(A^TA\)的特征之爱的平方根。</p>

<blockquote>
<p>对比：<br/>
特征分解是有限制的，比如矩阵必须是方阵</p>
</blockquote>

<h3 id="toc_2">SVD与PCA的关系</h3>

<ul>
<li class="task-list-item"><input disabled="disabled" type="checkbox" /> 查一下之前多元的变换原理
</li>
</ul>

<p>PCA的全部工作简单点说，就是对原始的空间中顺序地找一组相互正交的坐标轴，第一个轴是使得方差最大的，第二个轴是在与第一个轴正交的平面中使得方差最大的，第三个轴是在与第1、2个轴正交的平面中方差最大的，这样假设在N维空间中，我们可以找到N个这样的坐标轴，我们取前r个去近似这个空间，这样就从一个N维的空间压缩到r维的空间了，但是我们选择的r个坐标轴能够使得空间的压缩使得数据的损失最小。</p>

<h3 id="toc_3">SVD与潜在语义检索LSI</h3>

<h2 id="toc_4">参考资料</h2>

<p><a href="http://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html">http://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15078740756158.html">paddlepaddle安装</a></h1>
			<p class="meta"><time datetime="2017-10-13T13:54:35+08:00" 
			pubdate data-updated="true">2017/10/13</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p><a href="http://learn.baidu.com/pages/index.html#/video/?courseId=13655&amp;elementId=ec41cf99-5d69-4f17-807b-3b9668d64f75&amp;userId=5879362&amp;groupId=477326&amp;_k=imsxjl">http://learn.baidu.com/pages/index.html#/video/?courseId=13655&amp;elementId=ec41cf99-5d69-4f17-807b-3b9668d64f75&amp;userId=5879362&amp;groupId=477326&amp;_k=imsxjl</a><br/>
mac安装</p>

<p>方法一：pip install paddlepaddle</p>

<p>方法二： docker安装</p>

<h3 id="toc_0">1.安装docker for mac</h3>

<p>下载链接<br/>
<a href="https://download.docker.com/mac/stable/Docker.dmg">https://download.docker.com/mac/stable/Docker.dmg</a></p>

<pre><code>docker --version
docker-compose --version
docker-machine --version
</code></pre>

<h3 id="toc_1">2.安装paddlepaddle的镜像版本</h3>

<p><a href="https://livc.io/173">https://livc.io/173</a></p>

<p>(1)根据自己的机器选择合适的版本<br/>
<a href="http://doc.paddlepaddle.org/release_doc/0.9.0/doc_cn/build_and_install/install/docker_install.html">http://doc.paddlepaddle.org/release_doc/0.9.0/doc_cn/build_and_install/install/docker_install.html</a></p>

<p>我这个地方选择的是cpu-noavx-latest</p>

<p>(2)下载镜像<br/>
<img src="media/15078740756158/15078763330578.jpg" alt=""/></p>

<p>docker pull paddledev/paddle:cpu-noavx-latest</p>

<p>(3)运行</p>

<pre><code>docker run -it paddledev/paddle:cpu-noavx-latest
root@a60119636542:/# paddle version
PaddlePaddle 0.9.0a0, compiled with
    with_avx: OFF
    with_gpu: OFF
    with_double: OFF
    with_python: ON
    with_rdma: OFF
    with_glog: ON
    with_gflags: ON
    with_metric_learning: 
    with_timer: OFF
    with_predict_sdk: 
root@a60119636542:/# 
</code></pre>

<p>退出： ctrl+d</p>

<h3 id="toc_2">3.试玩环境</h3>

<p>华东在机器上装了一个环境。</p>

<pre><code>http://wiki.baidu.com/pages/viewpage.action?pageId=329462880

/home/work/duhuadong/python27-gcc482/bin/python train.py

/home/work/duhuadong/models-develop/text_classification

work@yq01-ps-feed201705-m120007.yq01.baidu.com
</code></pre>


		</div>

		

	</article>
  
	<div class="pagination">
	 <a class="prev" href="all_18.html">&larr; Older</a> 
<a href="archives.html">Blog Archives</a>
	 <a class="next" href="all_16.html">Newer &rarr;</a>  
	    
	</div>
</div>
 <aside class="sidebar"> 

	<section>
	  <h1>Categories</h1>
	  <ul id="recent_posts">
	  
	      <li class="post">
	        <a href="%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6-%E6%B8%85%E5%8D%95.html"><strong>数据科学-清单&nbsp;(4)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="1%20Tools.html"><strong>1 Tools&nbsp;(33)</strong></a>
	         <p class="cat-children-p"> 
	        
	        	<a href="%E9%85%B7%E7%82%AB%E7%A5%9E%E5%99%A8.html">酷炫神器&nbsp;(12)</a>&nbsp;&nbsp;
	        
	        	<a href="PaddlePaddle.html">PaddlePaddle&nbsp;(3)</a>&nbsp;&nbsp;
	        
	        	<a href="spark.html">spark&nbsp;(12)</a>&nbsp;&nbsp;
	        
	        	<a href="tensorflow.html">tensorflow&nbsp;(2)</a>&nbsp;&nbsp;
	        
	        	<a href="SQL.html">SQL&nbsp;(1)</a>&nbsp;&nbsp;
	        
	         </p> 
	      </li>
	  
	      <li class="post">
	        <a href="2%20Get%20Data.html"><strong>2 Get Data&nbsp;(1)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="3%20%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96.html"><strong>3 数据可视化&nbsp;(8)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="4%20%E4%BD%A0%E4%B8%8D%E5%BE%97%E4%B8%8D%E7%9F%A5%E7%9A%84%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95.html"><strong>4 你不得不知的统计方法&nbsp;(9)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="5%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html"><strong>5 机器学习&nbsp;(23)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F.html"><strong>6 推荐系统&nbsp;(3)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="6%20%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86.html"><strong>6 图像处理&nbsp;(4)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="6%20%E6%90%9C%E7%B4%A2.html"><strong>6 搜索&nbsp;(1)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="6%20nlp.html"><strong>6 nlp&nbsp;(1)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="7%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html"><strong>7 深度学习&nbsp;(12)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="8%20Ai%E5%BA%94%E7%94%A8.html"><strong>8 Ai应用&nbsp;(1)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E8%AE%B8%E5%BC%8F%E4%BC%9F-%E6%9E%B6%E6%9E%84%E8%AF%BE.html"><strong>许式伟-架构课&nbsp;(1)</strong></a>
	        
	        
	        
	      </li>
	   
	  </ul>
	</section>
	<section>
	  <h1>Recent Posts</h1>
	  <ul id="recent_posts">
	  
	      
		      <li class="post">
		        <a href="15633781017095.html"></a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15633691538884.html">3. 样本量的确定？</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15633655285542.html">卡方检验</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15632757602829.html">3. 假设检验的power</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15630063899159.html">python自然语言处理学习笔记——1</a>
		      </li>
	     
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	   
	  </ul>
	</section>
	
</aside> </div></div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 -  -
  <span class="credit">Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a> &nbsp;&nbsp; Theme by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>

  
    


<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>

</body>
</html>