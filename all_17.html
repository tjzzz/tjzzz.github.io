<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  zhenzhen数据科学笔记
  
  </title>
  
  
  <link href="atom.xml" rel="alternate" title="zhenzhen数据科学笔记" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />
    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript">
  function before_search(){
    var searchVal = 'site: ' + document.getElementById('search_input').value;
    document.getElementById('search_q').value = searchVal;
    return true;
  }
</script>
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>


  <section class="top-bar-section">
  <div class="row">
      <div style="position: relative;width:100%;"><div style="position: absolute; width:100%;">
        <ul id="main-menu" class="left">
        
        <li id=""><a target="_self" href="index.html">Home</a></li>
        
        <li id=""><a target="_self" href="archives.html">Archives</a></li>
        
        <li id=""><a target="_self" href="about_me.html">aboutme</a></li>
        
        </ul>

        <ul class="right" id="search-wrap">
          <li>
<form target="_blank" onsubmit="return before_search();" action="https://google.com/search" method="get">
    <input type="hidden" id="search_q" name="q" value="" />
    <input tabindex="1" type="search" id="search_input"  placeholder="Search"/>
</form>
</li>
          </ul>
      </div></div>
  </div>
  </section>

</nav>

        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; zhenzhen数据科学笔记</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
        
        <li><a target="_self" href="index.html">Home</a></li>
        
        <li><a target="_self" href="archives.html">Archives</a></li>
        
        <li><a target="_self" href="about_me.html">aboutme</a></li>
        

    <li><label>Categories</label></li>

        
            <li><a href="%E8%BD%A8%E8%BF%B9%E5%88%86%E6%9E%90.html">轨迹分析</a></li>
        
            <li><a href="1%20Tools.html">1 Tools</a></li>
        
            <li><a href="2%20Get%20Data.html">2 Get Data</a></li>
        
            <li><a href="3%20%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96.html">3 数据可视化</a></li>
        
            <li><a href="4%20%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95.html">4 统计方法</a></li>
        
            <li><a href="5%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html">5 机器学习</a></li>
        
            <li><a href="6%20%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F.html">6 推荐系统</a></li>
        
            <li><a href="6.CV.html">6.CV</a></li>
        
            <li><a href="6%20NLP.html">6 NLP</a></li>
        
            <li><a href="7%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html">7 深度学习</a></li>
        
            <li><a href="8%20%E6%AF%94%E8%B5%9B%E5%AD%A6%E4%B9%A0.html">8 比赛学习</a></li>
        
            <li><a href="%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6-%E6%B8%85%E5%8D%95.html">数据科学-清单</a></li>
         

      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>


        <section id="main-content" role="main" class="scroll-container">
        
       

 <script type="text/javascript">
	$(function(){
		$('#menu_item_index').addClass('is_active');
	});
</script>
<div class="row">
	<div class="large-8 medium-8 columns">
		<div class="markdown-body home-categories">
		
			<div class="article">
                <a class="clearlink" href="15637025347286.html">
                
                  <h1>章2 利用用户行为数据</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<h1 id="toc_0">1.用户行为数据</h1>

<p>用户行为数据在网页上的主要存在形式就是日志，可能包含的字段有</p>

<ul>
<li>uid</li>
<li>itemid</li>
<li>行为类型（点击、浏览、购买）</li>
<li>context（产生行为的时间、地点等）</li>
<li>行为权重（比如看视频行为的时长、打分行为的分数）</li>
<li>行为内容（比如评论行为的评论内容）<br/>
另外，这些数据大致上可以分为显性反馈行为和隐性反馈行为。显性行为就是可以明确用户是喜好的，比如购买。而多数的数据都是隐性的，比如浏览了某个网页、听了某个歌，这些行为无法判断出用户的喜好。</li>
</ul>

<p>物品流行度的幂率分布</p>

<h1 id="toc_1">算法</h1>

<p>一般把仅仅基于用户行为数据设计的推荐算法叫做协同过滤算法。主要包括：</p>

<ul>
<li>基于邻域的方法
<ul>
<li>基于用户的</li>
<li>基于物品的</li>
</ul></li>
<li>隐语义模型LFM</li>
<li>基于图的随机游走算法</li>
</ul>

<h2 id="toc_2">1.userCF</h2>

<p>基本想法：对于一个用户A的推荐，可以先找到与这个人相似的那些人，然后看那些人中喜欢的，而用户A没有听过的物品推荐给A。<br/>
step1: 找到相似用户，即需要定义相似度。</p>

<h2 id="toc_3">标题</h2>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2019/7/21</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='6%20%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F.html'>6 推荐系统</a></span>
          				   
                    

                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15637025345079.html">
                
                  <h1>第一章 引言</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>别人的读后总结，可参考「Deep Learning」读书系列分享（一） | 分享总结</p>

<p><a href="https://www.leiphone.com/news/201708/LEBNjZzvm0Q3Ipp0.html">https://www.leiphone.com/news/201708/LEBNjZzvm0Q3Ipp0.html</a></p>

<h3 id="toc_0">需要明确的几个概念范围</h3>

<p><img src="media/15075611675547/15075613801366.jpg" alt=""/></p>

<p><img src="media/15075611675547/15075614908544.jpg" alt=""/></p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2019/7/21</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='7%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html'>7 深度学习</a></span>
          				   
                    

                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15637025346077.html">
                
                  <h1>第七章 正则化</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>机器学习不止要求在训练数据上有良好的表现，还希望有较好的泛化能力，即在测试数据上也能减少测试误差。这些策略被统称为<strong>正则化</strong></p>

<p>常见的一些正则化方法：</p>

<h2 id="toc_0">1.参数范数惩罚</h2>

<p>即在原有的优化函数中，添加一个对参数的惩罚，来限制模型的学习能力<br/>
<img src="media/15120469131645/15206725126887.jpg" alt=""/></p>

<p>(1) L2参数正则化<br/>
L2正则化/岭回归，又叫权重衰减； 可以参照岭回归<br/>
<img src="media/15120469131645/15206732558707.jpg" alt=""/></p>

<p>(X⊤X + αI)−1 这个新矩阵与原来的是一样的，不同的仅仅是在对 角加了 α。这个矩阵的对角项对应每个输入特征的方差。我们可以看到，L2正则化能 让学习算法 ‘‘感知’’ 到具有较高方差的输入 x，因此与输出目标的协方差较小(相对 增加方差)的特征的权重将会收缩。</p>

<p>（2）L1正则化： 具有稀疏性，很多会衰减成0，所以有时候会用来做变量选择lasso</p>

<h2 id="toc_1">2.作为约束的范数惩罚</h2>

<p>从另一个角度来看这个问题，可以被看做是构造一个广义拉格朗日函数来最小化带约束的函数</p>

<p><img src="media/15120469131645/15206742273357.jpg" alt=""/></p>

<p><img src="media/15120469131645/15206742365336.jpg" alt=""/></p>

<p>最小化约束 + 重投影的角度</p>

<h2 id="toc_2">3.正则化和欠约束问题</h2>

<p>正则化还有个好处可以保证X&#39;X+aI 是可逆的</p>

<h2 id="toc_3">4.数据集增强</h2>

<p>可以通过一些方法在不改变label的情况下自己构造一批数据集，比如图像识别时候对图像的旋转；有些时候也可以通过输入噪声的方式来进行数据集增强。</p>

<h2 id="toc_4">5.噪声鲁棒性</h2>

<ul>
<li>向模型的输入或者是权重中加入噪音。</li>
<li>向输出目标中加入噪音，即标注数据有一定的错误，不是百分百准确的时候。<strong>标签平滑</strong>方法是将0，1分类，变为e/(k-1)和1-e的k个输出的softmax函数。（e是标注的错误率）</li>
</ul>

<h2 id="toc_5">6.半监督学习</h2>

<p>大概意思是说：P(x) 产生的未标记样本和P(x,y)中的标记样本都用 于估计 P(y|x)或者根据x预测y。</p>

<h2 id="toc_6">7.多任务学习</h2>

<p>就是通过合并几个任务中的样例（可以视为对参数施加的软约束），我感觉就是类似于group_lasso这样的，对参数加了一个别的约束，部分样本需要共享同一个参数</p>

<h2 id="toc_7">8.提前终止</h2>

<p><img src="media/15120469131645/15206764319925.jpg" alt=""/><br/>
当训练的能力较强时候会发现，随着训练次数的增加，训练误差在逐步减小，但是测试误差会呈现一个U型状态。即先减小后增加。</p>

<p>不是从模型的优化函数入手，相当于是一个实践的经验技巧。</p>

<p>提前终止具有正则化的效果</p>

<h2 id="toc_8">9.参数绑定和参数共享</h2>

<h2 id="toc_9">10.稀疏表示</h2>

<p>前文所述的权重衰减直接惩罚模型参数。另一种策略是惩罚神经网络中的激活 单元，稀疏化激活单元。这种策略间接地对模型参数施加了复杂惩罚。<br/>
<img src="media/15120469131645/15207643423743.jpg" alt=""/></p>

<h2 id="toc_10">11.Bagging 和其他集成方法</h2>

<p>结合多个模型，进行模型平均</p>

<h2 id="toc_11">12.dropout</h2>

<p>@@@@</p>

<h2 id="toc_12">13.对抗训练</h2>

<h1 id="toc_13">14 切面距离、正切传播和流形正切分类器</h1>

<p>略</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2019/7/21</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='7%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html'>7 深度学习</a></span>
          				   
                    

                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15637025345792.html">
                
                  <h1>第三章 概率与信息论</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>本章主要是介绍了一些概率论的基础以及常见的分布</p>

<h2 id="toc_0">1.常用函数的有用性质</h2>

<ul>
<li>sigmoid 函数</li>
</ul>

<p>\[\delta(x) = \frac{1}{1+exp(-x)}\]</p>

<ul>
<li>softplus函数<br/>
\[log(1+exp(x))\]
<img src="media/15080561019055/15080571562017.jpg" alt=""/></li>
</ul>

<p>是\(y=max(0,x)\)的平滑版本</p>

<h2 id="toc_1">2.信息论</h2>

<p>信息论是应用数学的一个分支，主要研究的是对一个信号包含信息的多少进行量化。<br/>
<img src="media/15080561019055/15080594230903.jpg" alt=""/></p>

<p>自信息：定义一个时间X=x的自信息<br/>
\[I(x) = -log P(x)\]</p>

<p>熵：<br/>
\[-\sum P(x_i) logP(x_i)\]</p>

<h3 id="toc_2">KL散度/相对熵</h3>

<p>\[KL(P||Q) = -\sum P_i ln(\frac{P_i}{Q_i})=-\sum P_i(ln(P_i)- ln(Q_i))\]</p>

<p>注意：</p>

<ul>
<li>KL距离其实并不是严格的距离，不满足对称性以及三角不等式。</li>
</ul>

<p>JS距离：<br/>
\[JS(P1||P2) = \frac{1}{2}KL(P1||(P1+P2)/2)+ \frac{1}{2}KL(P2||(P1+P2)/2)\]</p>

<h3 id="toc_3">交叉熵</h3>

<p>相对熵的第一部分<br/>
\[KL(P||Q) = -\sum P_i ln(Q_i)\]</p>

<h2 id="toc_4">3.结构化概率模型——图模型(graphical model)</h2>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2019/7/21</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='7%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html'>7 深度学习</a></span>
          				   
                    

                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15637025345723.html">
                
                  <h1>第二章 线性代数</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>第二章主要是介绍了线性代数的一些基础知识</p>

<p>这里补充几点吧</p>

<h2 id="toc_0">特征分解</h2>

<p>每个矩阵可以视为多个列向量组成的一个向量空间/或者是一个线性变化(一个矩阵乘以一个向量后相当于是对向量做了一个线性变换)。而矩阵的分解，相当于去提取这个向量空间最重要的特征。</p>

<p>(1)首先是特征值和特征向量<br/>
若<strong>方阵</strong>A满足 \(Av=\lambda v\),则\(v\)称为矩阵A的特征向量，\(\lambda\)称为对应的特征值。</p>

<p><strong>特征分解</strong><br/>
\[A=V \Lambda V^{-1}\]<br/>
V是其特征向量构成的矩阵，\(\Lambda\)是特征值构成的对角矩阵</p>

<p>性质：</p>

<p>(1) 实对称矩阵A都可以分解为\(A=Q\Lambda Q^{-1}\)，Q为正交矩阵</p>

<p>(2)用来计算矩阵的逆。若\(A=Q \Lambda Q^{-1}\)，则\(A^{-1}=Q \Lambda^{-1}Q^{-1}\)</p>

<h2 id="toc_1">奇异值分解</h2>

<p>特征分解对于提取矩阵的特征根是很好的方法，但是他只能针对<strong>方阵</strong>操作。当A不是方阵时候，就需要用到SVD<br/>
\[A_{n*m}=U_{n*n}\Sigma_{n*m} V^{T}_{m*m}\]</p>

<p>其中，U称为左奇异向量，V称为右奇异向量</p>

<p>\(AA^T=UDV^TVDU^T=UD^2U^T\)<br/>
\(A^TA=VDU^T UDV^T=VD^2V^T\)<br/>
即：<br/>
A的左奇异向量是\(AA^T\)的特征向量，A的右奇异向量是\(A^TA\)的特征向量，A的奇异值是\(AA^T\)也是\(A^TA\)的特征之爱的平方根。</p>

<blockquote>
<p>对比：<br/>
特征分解是有限制的，比如矩阵必须是方阵</p>
</blockquote>

<h3 id="toc_2">SVD与PCA的关系</h3>

<ul>
<li class="task-list-item"><input disabled="disabled" type="checkbox" /> 查一下之前多元的变换原理</li>
</ul>

<p>PCA的全部工作简单点说，就是对原始的空间中顺序地找一组相互正交的坐标轴，第一个轴是使得方差最大的，第二个轴是在与第一个轴正交的平面中使得方差最大的，第三个轴是在与第1、2个轴正交的平面中方差最大的，这样假设在N维空间中，我们可以找到N个这样的坐标轴，我们取前r个去近似这个空间，这样就从一个N维的空间压缩到r维的空间了，但是我们选择的r个坐标轴能够使得空间的压缩使得数据的损失最小。</p>

<h3 id="toc_3">SVD与潜在语义检索LSI</h3>

<h2 id="toc_4">参考资料</h2>

<p><a href="http://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html">http://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html</a></p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2019/7/21</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='7%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html'>7 深度学习</a></span>
          				   
                    

                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
              


			<div class="row">
			  <div class="large-6 columns">
			  <p class="text-left" style="padding-top:25px;">
			   <a href="all_16.html">&laquo; Prev Page</a>  
			  </p>
			  </div>
			  <div class="large-6 columns">
			<p class="text-right" style="padding-top:25px;">
			 <a href="all_18.html">&raquo; Next Page</a> 
			</p>
			  </div>
			</div>
		</div>
	</div><!-- large 8 -->

 <div class="large-4 medium-4 columns">
  <div class="hide-for-small">
    <div id="sidebar" class="sidebar">
          <div id="site-info" class="site-info">
            
                <h1>zhenzhen数据科学笔记</h1>
                <div class="site-des"></div>
                <div class="social">









<a target="_blank" class="github" target="_blank" href="tjzzz.github.io" title="GitHub">GitHub</a>

  <a target="_blank" class="rss" href="atom.xml" title="RSS">RSS</a>
                
              	 </div>
          	</div>

             

              <div id="site-categories" class="side-item ">
                <div class="side-header">
                  <h2>Categories</h2>
                </div>
                <div class="side-content">

      	<p class="cat-list">
        
            <a href="%E8%BD%A8%E8%BF%B9%E5%88%86%E6%9E%90.html"><strong>轨迹分析</strong></a>
        
            <a href="1%20Tools.html"><strong>1 Tools</strong></a>
        
            <a href="2%20Get%20Data.html"><strong>2 Get Data</strong></a>
        
            <a href="3%20%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96.html"><strong>3 数据可视化</strong></a>
        
            <a href="4%20%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95.html"><strong>4 统计方法</strong></a>
        
            <a href="5%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html"><strong>5 机器学习</strong></a>
        
            <a href="6%20%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F.html"><strong>6 推荐系统</strong></a>
        
            <a href="6.CV.html"><strong>6.CV</strong></a>
        
            <a href="6%20NLP.html"><strong>6 NLP</strong></a>
        
            <a href="7%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html"><strong>7 深度学习</strong></a>
        
            <a href="8%20%E6%AF%94%E8%B5%9B%E5%AD%A6%E4%B9%A0.html"><strong>8 比赛学习</strong></a>
        
            <a href="%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6-%E6%B8%85%E5%8D%95.html"><strong>数据科学-清单</strong></a>
         
        </p>


                </div>
              </div>

              <div id="site-categories" class="side-item">
                <div class="side-header">
                  <h2>Recent Posts</h2>
                </div>
                <div class="side-content">
                <ul class="posts-list">
	      
		      
			      <li class="post">
			        <a href="15687050894061.html">0.综述</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15637036455584.html">1 估计的置信度</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15637037681646.html">1 基础工具包安装pip</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15637025346412.html">1. conda 环境管理</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15637037713554.html">1. 数据可视化概述</a>
			      </li>
		     
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		   
		  		</ul>
                </div>
              </div>
        </div><!-- sidebar -->
      </div><!-- hide for small -->
</div><!-- large 4 -->

</div><!-- row -->

 <div class="page-bottom clearfix">
  <div class="row">
   <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
</div>

        </section>
      </div>
    </div>

  
    

    <script src="asset/js/foundation.min.js"></script>
    <script>
      $(document).foundation();
      function fixSidebarHeight(){
        var w1 = $('.markdown-body').height();
          var w2 = $('#sidebar').height();
          if (w1 > w2) { $('#sidebar').height(w1); };
      }
      $(function(){
        fixSidebarHeight();
      })
      $(window).load(function(){
          fixSidebarHeight();
      });
     
    </script>

    
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>


  </body>
</html>
