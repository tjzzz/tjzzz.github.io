# pyspark提交任务相关配置


相关配置

- spark.driver.memory  
- spark.executor.memory




##




上传包
https://www.jianshu.com/p/92be93cfbb97

https://blog.csdn.net/weixin_42649077/article/details/84976960



http://www.it1352.com/220302.html


http://ju.outofmemory.cn/entry/171843


## 端口
http://master:4040spark 默认端口是4040，如果被占用，就往下寻找4041，4042......可获得这些信息：（1）stages和tasks调度情况；（2）RDD大小及内存使用；（3）系统环境信息；（4）正在执行的executor信息。
