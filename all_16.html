
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>
    
  学习笔记
  

  </title>
  <meta name="author" content="">
  <meta name="description" content="">

  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link href="asset/css/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="atom.xml" rel="alternate" title="学习笔记" type="application/atom+xml">
  <script src="asset/js/modernizr-2.0.js"></script>
  <script src="asset/js/jquery.min.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/solarized_light.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>

  <style type="text/css">
  .cat-children-p{ padding: 6px 0px;}
  .hljs{background: none;}
  </style>
  <script type="text/javascript">
  var isAddSildbar = true;
  </script>
  <script src="asset/js/octopress.js" type="text/javascript"></script>
</head>
<script type="text/javascript">
//链接新开窗口
function addBlankTargetForLinks () {
  $('a[href^="http"]').each(function(){
      $(this).attr('target', '_blank');
  });
}
$(document).ready(function(event) {
  addBlankTargetForLinks();
});
</script>
<body   >
  <header role="banner"><hgroup>
  <h1><a href="index.html">学习笔记</a></h1>
  
    <h2></h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">

  <li id=""><a target="self" href="index.html">Home</a></li>

  <li id=""><a target="_self" href="archives.html">Archives</a></li>

</ul>

</nav>
  <div id="main">
    <div id="content"> 
<div class="blog-index">

	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15080561019055.html">第三章 概率与信息论</a></h1>
			<p class="meta"><time datetime="2017-10-15T16:28:21+08:00" 
			pubdate data-updated="true">2017/10/15</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>本章主要是介绍了一些概率论的基础以及常见的分布</p>

<h2 id="toc_0">1.常用函数的有用性质</h2>

<ul>
<li>sigmoid 函数</li>
</ul>

<p>\[\delta(x) = \frac{1}{1+exp(-x)}\]</p>

<ul>
<li>softplus函数
\[log(1+exp(x))\]
<img src="media/15080561019055/15080571562017.jpg" alt=""/></li>
</ul>

<p>是\(y=max(0,x)\)的平滑版本</p>

<h2 id="toc_1">2.信息论</h2>

<p>信息论是应用数学的一个分支，主要研究的是对一个信号包含信息的多少进行量化。<br/>
<img src="media/15080561019055/15080594230903.jpg" alt=""/></p>

<p>自信息：定义一个时间X=x的自信息<br/>
\[I(x) = -log P(x)\]</p>

<p>熵：<br/>
\[-\sum P(x_i) logP(x_i)\]</p>

<h3 id="toc_2">KL散度/相对熵</h3>

<p>\[KL(P||Q) = -\sum P_i ln(\frac{P_i}{Q_i})=-\sum P_i(ln(P_i)- ln(Q_i))\]</p>

<p>注意：</p>

<ul>
<li>KL距离其实并不是严格的距离，不满足对称性以及三角不等式。</li>
</ul>

<p>JS距离：<br/>
\[JS(P1||P2) = \frac{1}{2}KL(P1||(P1+P2)/2)+ \frac{1}{2}KL(P2||(P1+P2)/2)\]</p>

<h3 id="toc_3">交叉熵</h3>

<p>相对熵的第一部分<br/>
\[KL(P||Q) = -\sum P_i ln(Q_i)\]</p>

<h2 id="toc_4">3.结构化概率模型——图模型(graphical model)</h2>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15080506207071.html">第二章 线性代数</a></h1>
			<p class="meta"><time datetime="2017-10-15T14:57:00+08:00" 
			pubdate data-updated="true">2017/10/15</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>第二章主要是介绍了线性代数的一些基础知识</p>

<p>这里补充几点吧</p>

<h2 id="toc_0">特征分解</h2>

<p>每个矩阵可以视为多个列向量组成的一个向量空间/或者是一个线性变化(一个矩阵乘以一个向量后相当于是对向量做了一个线性变换)。而矩阵的分解，相当于去提取这个向量空间最重要的特征。</p>

<p>(1)首先是特征值和特征向量<br/>
若<strong>方阵</strong>A满足 \(Av=\lambda v\),则\(v\)称为矩阵A的特征向量，\(\lambda\)称为对应的特征值。</p>

<p><strong>特征分解</strong><br/>
\[A=V \Lambda V^{-1}\]<br/>
V是其特征向量构成的矩阵，\(\Lambda\)是特征值构成的对角矩阵</p>

<p>性质：</p>

<p>(1) 实对称矩阵A都可以分解为\(A=Q\Lambda Q^{-1}\)，Q为正交矩阵</p>

<p>(2)用来计算矩阵的逆。若\(A=Q \Lambda Q^{-1}\)，则\(A^{-1}=Q \Lambda^{-1}Q^{-1}\)</p>

<h2 id="toc_1">奇异值分解</h2>

<p>特征分解对于提取矩阵的特征根是很好的方法，但是他只能针对<strong>方阵</strong>操作。当A不是方阵时候，就需要用到SVD<br/>
\[A_{n*m}=U_{n*n}\Sigma_{n*m} V^{T}_{m*m}\]</p>

<p>其中，U称为左奇异向量，V称为右奇异向量</p>

<p>\(AA^T=UDV^TVDU^T=UD^2U^T\)<br/>
\(A^TA=VDU^T UDV^T=VD^2V^T\)<br/>
即：<br/>
A的左奇异向量是\(AA^T\)的特征向量，A的右奇异向量是\(A^TA\)的特征向量，A的奇异值是\(AA^T\)也是\(A^TA\)的特征之爱的平方根。</p>

<blockquote>
<p>对比：<br/>
特征分解是有限制的，比如矩阵必须是方阵</p>
</blockquote>

<h3 id="toc_2">SVD与PCA的关系</h3>

<ul>
<li class="task-list-item"><input disabled="disabled" type="checkbox" /> 查一下之前多元的变换原理
</li>
</ul>

<p>PCA的全部工作简单点说，就是对原始的空间中顺序地找一组相互正交的坐标轴，第一个轴是使得方差最大的，第二个轴是在与第一个轴正交的平面中使得方差最大的，第三个轴是在与第1、2个轴正交的平面中方差最大的，这样假设在N维空间中，我们可以找到N个这样的坐标轴，我们取前r个去近似这个空间，这样就从一个N维的空间压缩到r维的空间了，但是我们选择的r个坐标轴能够使得空间的压缩使得数据的损失最小。</p>

<h3 id="toc_3">SVD与潜在语义检索LSI</h3>

<h2 id="toc_4">参考资料</h2>

<p><a href="http://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html">http://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15078740756158.html">paddlepaddle安装</a></h1>
			<p class="meta"><time datetime="2017-10-13T13:54:35+08:00" 
			pubdate data-updated="true">2017/10/13</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p><a href="http://learn.baidu.com/pages/index.html#/video/?courseId=13655&amp;elementId=ec41cf99-5d69-4f17-807b-3b9668d64f75&amp;userId=5879362&amp;groupId=477326&amp;_k=imsxjl">http://learn.baidu.com/pages/index.html#/video/?courseId=13655&amp;elementId=ec41cf99-5d69-4f17-807b-3b9668d64f75&amp;userId=5879362&amp;groupId=477326&amp;_k=imsxjl</a><br/>
mac安装</p>

<p>方法一：pip install paddlepaddle</p>

<p>方法二： docker安装</p>

<h3 id="toc_0">1.安装docker for mac</h3>

<p>下载链接<br/>
<a href="https://download.docker.com/mac/stable/Docker.dmg">https://download.docker.com/mac/stable/Docker.dmg</a></p>

<pre><code>docker --version
docker-compose --version
docker-machine --version
</code></pre>

<h3 id="toc_1">2.安装paddlepaddle的镜像版本</h3>

<p><a href="https://livc.io/173">https://livc.io/173</a></p>

<p>(1)根据自己的机器选择合适的版本<br/>
<a href="http://doc.paddlepaddle.org/release_doc/0.9.0/doc_cn/build_and_install/install/docker_install.html">http://doc.paddlepaddle.org/release_doc/0.9.0/doc_cn/build_and_install/install/docker_install.html</a></p>

<p>我这个地方选择的是cpu-noavx-latest</p>

<p>(2)下载镜像<br/>
<img src="media/15078740756158/15078763330578.jpg" alt=""/></p>

<p>docker pull paddledev/paddle:cpu-noavx-latest</p>

<p>(3)运行</p>

<pre><code>docker run -it paddledev/paddle:cpu-noavx-latest
root@a60119636542:/# paddle version
PaddlePaddle 0.9.0a0, compiled with
    with_avx: OFF
    with_gpu: OFF
    with_double: OFF
    with_python: ON
    with_rdma: OFF
    with_glog: ON
    with_gflags: ON
    with_metric_learning: 
    with_timer: OFF
    with_predict_sdk: 
root@a60119636542:/# 
</code></pre>

<p>退出： ctrl+d</p>

<h3 id="toc_2">3.试玩环境</h3>

<p>华东在机器上装了一个环境。</p>

<pre><code>http://wiki.baidu.com/pages/viewpage.action?pageId=329462880

/home/work/duhuadong/python27-gcc482/bin/python train.py

/home/work/duhuadong/models-develop/text_classification

work@yq01-ps-feed201705-m120007.yq01.baidu.com
</code></pre>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15078603543147.html">【聚类】-效果评价</a></h1>
			<p class="meta"><time datetime="2017-10-13T10:05:54+08:00" 
			pubdate data-updated="true">2017/10/13</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>一般分为两类：</p>

<ul>
<li>外部标准：即基于人工的判断，需要有个标注集合</li>
<li>内部标准：基于类内和类间聚类的目标函数的判断</li>
</ul>

<h2 id="toc_0">内部标准clustering-performance-evaluation</h2>

<h2 id="toc_1">外部标准——人工判定</h2>

<p>假设：<br/>
机器判断的类别集合是：\(C=\{C_1,C_2,...C_m\}\)<br/>
人工判断的类别集合是：\(P=\{P_1,P_2,...P_s\}\)</p>

<h3 id="toc_2">1.1混淆矩阵</h3>

<p>基于数据样本点的角度：<br/>
对于任意两个数据pair，\((x_i,x_j)\)按照其在C和P中是否属于同一个簇，可以构造出混淆矩阵</p>

<table>
<thead>
<tr>
<th></th>
<th>P_1</th>
<th>p_0</th>
</tr>
</thead>

<tbody>
<tr>
<td>C_1</td>
<td>a</td>
<td>b</td>
</tr>
<tr>
<td>C_0</td>
<td>c</td>
<td>d</td>
</tr>
</tbody>
</table>

<p><img src="media/15078603543147/15078631739679.jpg" alt=""/></p>

<h3 id="toc_3">1.2簇的准确率/召回率</h3>

<p>基于簇pair的，考虑对任意一个人工与机器的.\(P_j,C_i\)。对于每一个人工标注的\(P_j\),在机器标注中应该都会对应一个&quot;最相关的&quot;。可以遍历C中所有的cluster，分别计算准确率，召回率，F_score。<br/>
<img src="media/15078603543147/15078720767171.jpg" alt=""/></p>

<p>然后对于所有簇的F值做加权平均<br/>
\[ClassF=\sum w_j F(p_j), w_i=n_j/n\]</p>

<p>classF指标，相当于是以人工标注的簇为基准，将聚类的簇尽量逼近这个标注的结果。</p>

<h2 id="toc_4">1.3</h2>

<p>1.2中的方法相当于要求的比较严格，即以人工标注的集合簇为准。</p>

<p>实际中其实只要保证我们聚的每一个类\(C_i\)是有意义的就可以，即以C为主</p>

<p>类似的定义 \(F(C_i)=\max_{1\lt j \lt s}F(P_j, C_i)\)<br/>
\[F=\sum w_i F(C_i), w_i=|C_i|/n\]</p>

<ul>
<li>问题： 这个指标可能变化不是非常明显</li>
</ul>

<h2 id="toc_5">1.4基于数据对象的准召F</h2>

<p><img src="media/15078603543147/15078731022919.jpg" alt=""/></p>

<h2 id="toc_6">思考</h2>

<ol>
<li>基于人工标注的方法中，认为人工标注的是准确的或者说结果是唯一的。实际上一堆sample可以有不同的分类方法，而且每种方法可能都是对的。
<code>
e.g 苹果维修， 冰箱维修，苹果价格，冰箱价格，中国人民大学
</code>
如何进行标注，或者标注结果是非固定时候怎么衡量聚类效果的好坏？？</li>
</ol>

<h2 id="toc_7">参考资料</h2>

<p><a href="http://blog.csdn.net/itplus/article/details/10322361">http://blog.csdn.net/itplus/article/details/10322361</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15075611675547.html">第一章 引言</a></h1>
			<p class="meta"><time datetime="2017-10-09T22:59:27+08:00" 
			pubdate data-updated="true">2017/10/9</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>别人的读后总结，可参考「Deep Learning」读书系列分享（一） | 分享总结</p>

<p><a href="https://www.leiphone.com/news/201708/LEBNjZzvm0Q3Ipp0.html">https://www.leiphone.com/news/201708/LEBNjZzvm0Q3Ipp0.html</a></p>

<h3 id="toc_0">需要明确的几个概念范围</h3>

<p><img src="media/15075611675547/15075613801366.jpg" alt=""/></p>

<p><img src="media/15075611675547/15075614908544.jpg" alt=""/></p>


		</div>

		

	</article>
  
	<div class="pagination">
	 <a class="prev" href="all_17.html">&larr; Older</a> 
<a href="archives.html">Blog Archives</a>
	 <a class="next" href="all_15.html">Newer &rarr;</a>  
	    
	</div>
</div>
 <aside class="sidebar"> 

	<section>
	  <h1>Categories</h1>
	  <ul id="recent_posts">
	  
	      <li class="post">
	        <a href="%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6-%E6%B8%85%E5%8D%95.html"><strong>数据科学-清单&nbsp;(4)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="1%20Tools.html"><strong>1 Tools&nbsp;(33)</strong></a>
	         <p class="cat-children-p"> 
	        
	        	<a href="%E9%85%B7%E7%82%AB%E7%A5%9E%E5%99%A8.html">酷炫神器&nbsp;(12)</a>&nbsp;&nbsp;
	        
	        	<a href="PaddlePaddle.html">PaddlePaddle&nbsp;(3)</a>&nbsp;&nbsp;
	        
	        	<a href="spark.html">spark&nbsp;(12)</a>&nbsp;&nbsp;
	        
	        	<a href="tensorflow.html">tensorflow&nbsp;(2)</a>&nbsp;&nbsp;
	        
	        	<a href="SQL.html">SQL&nbsp;(1)</a>&nbsp;&nbsp;
	        
	         </p> 
	      </li>
	  
	      <li class="post">
	        <a href="2%20Get%20Data.html"><strong>2 Get Data&nbsp;(1)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="3%20%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96.html"><strong>3 数据可视化&nbsp;(8)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="4%20%E4%BD%A0%E4%B8%8D%E5%BE%97%E4%B8%8D%E7%9F%A5%E7%9A%84%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95.html"><strong>4 你不得不知的统计方法&nbsp;(5)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="5%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html"><strong>5 机器学习&nbsp;(23)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F.html"><strong>6 推荐系统&nbsp;(3)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="6%20NLP&%E5%9B%BE%E5%83%8F.html"><strong>6 NLP&图像&nbsp;(4)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="7%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html"><strong>7 深度学习&nbsp;(11)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="8%20Ai%E5%BA%94%E7%94%A8.html"><strong>8 Ai应用&nbsp;(1)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E8%AE%B8%E5%BC%8F%E4%BC%9F-%E6%9E%B6%E6%9E%84%E8%AF%BE.html"><strong>许式伟-架构课&nbsp;(1)</strong></a>
	        
	        
	        
	      </li>
	   
	  </ul>
	</section>
	<section>
	  <h1>Recent Posts</h1>
	  <ul id="recent_posts">
	  
	      
		      <li class="post">
		        <a href="15623124260572.html">1 抽样方法</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15598839206919.html">SC-FEGAN</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15596648844646.html">【Tensorflow】week2 Introduction to Computer Vision</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15596470753558.html">TensorFlow</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15594599843014.html">估计的置信度</a>
		      </li>
	     
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	   
	  </ul>
	</section>
	
</aside> </div></div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 -  -
  <span class="credit">Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a> &nbsp;&nbsp; Theme by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>

  
    


<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>

</body>
</html>