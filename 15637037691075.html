<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  4.1 回归模型 - zhenzhen学习笔记
  
  </title>
 <meta name="description" content="">
 <link href="atom.xml" rel="alternate" title="zhenzhen学习笔记" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />

    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
    <script src="asset/highlightjs/highlight.pack.js"></script>
    <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
    <script>hljs.initHighlightingOnLoad();</script>
    
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>

<div id="header">
    <h1><a href="index.html">zhenzhen学习笔记</a></h1>
</div>

</nav>
        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; zhenzhen学习笔记</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
      <li><a href="index.html">Home</a></li>
      
        <li class="divider"></li>
        <li><label>1 Tools</label></li>

          
            <li><a title="1 安装-mac" href="15637025344954.html">1 安装-mac</a></li>
          
            <li><a title="git" href="15637037678160.html">git</a></li>
          
            <li><a title="jupyterLab" href="15637037680349.html">jupyterLab</a></li>
          
            <li><a title="markdown" href="15637037679256.html">markdown</a></li>
          
            <li><a title="sublime" href="15637037680741.html">sublime</a></li>
          
            <li><a title="工欲善其事必先利其器——Jupyter notebook" href="15637037683461.html">工欲善其事必先利其器——Jupyter notebook</a></li>
          
            <li><a title="工欲善其事必先利其器——conda" href="15637025346412.html">工欲善其事必先利其器——conda</a></li>
          

      
        <li class="divider"></li>
        <li><label>2 Get Data</label></li>

          
            <li><a title="公开微观数据库 1.0" href="15637025347227.html">公开微观数据库 1.0</a></li>
          

      
        <li class="divider"></li>
        <li><label>3 数据可视化</label></li>

          
            <li><a title="Data product" href="15637037683065.html">Data product</a></li>
          
            <li><a title="rCharts" href="15637037678380.html">rCharts</a></li>
          
            <li><a title="数据可视化(seaborn)" href="15637037713554.html">数据可视化(seaborn)</a></li>
          

      
        <li class="divider"></li>
        <li><label>4 统计方法</label></li>

          
            <li><a title="1 估计的置信度" href="15637036455584.html">1 估计的置信度</a></li>
          
            <li><a title="2 不同设计之间有统计学差异吗" href="15637025346225.html">2 不同设计之间有统计学差异吗</a></li>
          
            <li><a title="3 样本量的确定" href="15637036605080.html">3 样本量的确定</a></li>
          
            <li><a title="关于长点击阈值划分方法" href="15637037730522.html">关于长点击阈值划分方法</a></li>
          
            <li><a title="卡方检验" href="15637025346262.html">卡方检验</a></li>
          
            <li><a title="统计阈值" href="15637037730576.html">统计阈值</a></li>
          

      
        <li class="divider"></li>
        <li><label>5 机器学习</label></li>

          
            <li><a title="3.1 特征处理—— 特征选择" href="15637037691936.html">3.1 特征处理—— 特征选择</a></li>
          
            <li><a title="3.2 特征处理——降维" href="15637037731313.html">3.2 特征处理——降维</a></li>
          
            <li><a title="4.1 回归模型" href="15637037691075.html">4.1 回归模型</a></li>
          
            <li><a title="4.2 回归与分类" href="15637037677393.html">4.2 回归与分类</a></li>
          
            <li><a title="4.3 支持向量机" href="15637037728199.html">4.3 支持向量机</a></li>
          
            <li><a title="4.4 k近邻 —— 非参模型" href="15637037731266.html">4.4 k近邻 —— 非参模型</a></li>
          
            <li><a title="4.5 树模型" href="15637037678245.html">4.5 树模型</a></li>
          
            <li><a title="4.6 集成" href="15637037692016.html">4.6 集成</a></li>
          
            <li><a title="4.7 聚类1" href="15636947700701.html">4.7 聚类1</a></li>
          
            <li><a title="4.7 聚类2——-效果评价" href="15637037683688.html">4.7 聚类2——-效果评价</a></li>
          
            <li><a title="4.8 自适应的基函数——神经网络" href="15637025348085.html">4.8 自适应的基函数——神经网络</a></li>
          
            <li><a title="4.9 深度学习综述" href="15637037686386.html">4.9 深度学习综述</a></li>
          
            <li><a title="FM" href="15637037720747.html">FM</a></li>
          
            <li><a title="FM 模型" href="15637037680228.html">FM 模型</a></li>
          
            <li><a title="query文本聚类" href="15637025345613.html">query文本聚类</a></li>
          
            <li><a title="t-sne" href="15637037679781.html">t-sne</a></li>
          
            <li><a title="xgboost" href="15637025344879.html">xgboost</a></li>
          
            <li><a title="【聚类】-效果评价" href="15637037699016.html">【聚类】-效果评价</a></li>
          
            <li><a title="一、基础篇" href="15637037677178.html">一、基础篇</a></li>
          
            <li><a title="二、起步篇—— 数据预处理[python]" href="15637025346988.html">二、起步篇—— 数据预处理[python]</a></li>
          
            <li><a title="二、起步篇——数据预处理[方法论]" href="15636947700356.html">二、起步篇——数据预处理[方法论]</a></li>
          
            <li><a title="二、起步篇——数据预处理[方法论]" href="15637025346040.html">二、起步篇——数据预处理[方法论]</a></li>
          
            <li><a title="聚类Tools篇" href="15637025345910.html">聚类Tools篇</a></li>
          
            <li><a title="聚类Tools篇" href="15637037682671.html">聚类Tools篇</a></li>
          
            <li><a title="聚类方法-spark的bisecting和streaming" href="15637037731727.html">聚类方法-spark的bisecting和streaming</a></li>
          
            <li><a title="聚类方法Mini Batch KMeans" href="15637025344831.html">聚类方法Mini Batch KMeans</a></li>
          
            <li><a title="视频广告" href="15637025347693.html">视频广告</a></li>
          

      
        <li class="divider"></li>
        <li><label>6 推荐系统</label></li>

          
            <li><a title="章1 基本介绍" href="15637025348511.html">章1 基本介绍</a></li>
          
            <li><a title="章2 利用用户行为数据" href="15637025347286.html">章2 利用用户行为数据</a></li>
          

      
        <li class="divider"></li>
        <li><label>6 文本&视频</label></li>

          
            <li><a title="Face综述" href="15637037688620.html">Face综述</a></li>
          
            <li><a title="face_recgnization" href="15637037690385.html">face_recgnization</a></li>
          
            <li><a title="图像识别模型—— 1.利用已有的进行微调" href="15637037708871.html">图像识别模型—— 1.利用已有的进行微调</a></li>
          

      
        <li class="divider"></li>
        <li><label>7 深度学习</label></li>

          
            <li><a title="3.【解释性】LIME" href="15637037677008.html">3.【解释性】LIME</a></li>
          
            <li><a title="TensorFlow" href="15637037730028.html">TensorFlow</a></li>
          
            <li><a title="[2018-06-25]学习1" href="15637037693934.html">[2018-06-25]学习1</a></li>
          
            <li><a title="【NG-DL】course2_week1 优化网络参数" href="15637025344767.html">【NG-DL】course2_week1 优化网络参数</a></li>
          
            <li><a title="【Tensorflow】week2 Introduction to Computer Vision" href="15637025345757.html">【Tensorflow】week2 Introduction to Computer Vision</a></li>
          
            <li><a title="神经网络解释性问题" href="15637037679634.html">神经网络解释性问题</a></li>
          
            <li><a title="第一章 引言" href="15637025345079.html">第一章 引言</a></li>
          
            <li><a title="第七章 正则化" href="15637025346077.html">第七章 正则化</a></li>
          
            <li><a title="第三章 概率与信息论" href="15637025345792.html">第三章 概率与信息论</a></li>
          
            <li><a title="第二章 线性代数" href="15637025345723.html">第二章 线性代数</a></li>
          
            <li><a title="第五章 机器学习" href="15637025346737.html">第五章 机器学习</a></li>
          
            <li><a title="第八章 深度模型中的优化" href="15637037731128.html">第八章 深度模型中的优化</a></li>
          
            <li><a title="第六章 深度前馈网络" href="15637025345687.html">第六章 深度前馈网络</a></li>
          
            <li><a title="第四章 数值计算" href="15637037679680.html">第四章 数值计算</a></li>
          

      
        <li class="divider"></li>
        <li><label>10 比赛学习</label></li>

          
            <li><a title="比赛学习" href="15637037730631.html">比赛学习</a></li>
          

      
        <li class="divider"></li>
        <li><label>数据科学-清单</label></li>

          
            <li><a title="推荐资源" href="15637037694950.html">推荐资源</a></li>
          
            <li><a title="目录" href="15637025347820.html">目录</a></li>
          
            <li><a title="资源List" href="15637025346338.html">资源List</a></li>
          

      
      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>

        <section id="main-content" role="main" class="scroll-container">

          <div class="row">
            <div class="large-3 medium-3 columns">
              <div class="hide-for-small">
                <div class="sidebar">
                <nav>
                  <ul id="side-nav" class="side-nav">

                    
                      <li class="side-title"><span>1 Tools</span></li>
                        
                          <li><a title="1 安装-mac" href="15637025344954.html">1 安装-mac</a></li>
                        
                          <li><a title="git" href="15637037678160.html">git</a></li>
                        
                          <li><a title="jupyterLab" href="15637037680349.html">jupyterLab</a></li>
                        
                          <li><a title="markdown" href="15637037679256.html">markdown</a></li>
                        
                          <li><a title="sublime" href="15637037680741.html">sublime</a></li>
                        
                          <li><a title="工欲善其事必先利其器——Jupyter notebook" href="15637037683461.html">工欲善其事必先利其器——Jupyter notebook</a></li>
                        
                          <li><a title="工欲善其事必先利其器——conda" href="15637025346412.html">工欲善其事必先利其器——conda</a></li>
                        

                    
                      <li class="side-title"><span>2 Get Data</span></li>
                        
                          <li><a title="公开微观数据库 1.0" href="15637025347227.html">公开微观数据库 1.0</a></li>
                        

                    
                      <li class="side-title"><span>3 数据可视化</span></li>
                        
                          <li><a title="Data product" href="15637037683065.html">Data product</a></li>
                        
                          <li><a title="rCharts" href="15637037678380.html">rCharts</a></li>
                        
                          <li><a title="数据可视化(seaborn)" href="15637037713554.html">数据可视化(seaborn)</a></li>
                        

                    
                      <li class="side-title"><span>4 统计方法</span></li>
                        
                          <li><a title="1 估计的置信度" href="15637036455584.html">1 估计的置信度</a></li>
                        
                          <li><a title="2 不同设计之间有统计学差异吗" href="15637025346225.html">2 不同设计之间有统计学差异吗</a></li>
                        
                          <li><a title="3 样本量的确定" href="15637036605080.html">3 样本量的确定</a></li>
                        
                          <li><a title="关于长点击阈值划分方法" href="15637037730522.html">关于长点击阈值划分方法</a></li>
                        
                          <li><a title="卡方检验" href="15637025346262.html">卡方检验</a></li>
                        
                          <li><a title="统计阈值" href="15637037730576.html">统计阈值</a></li>
                        

                    
                      <li class="side-title"><span>5 机器学习</span></li>
                        
                          <li><a title="3.1 特征处理—— 特征选择" href="15637037691936.html">3.1 特征处理—— 特征选择</a></li>
                        
                          <li><a title="3.2 特征处理——降维" href="15637037731313.html">3.2 特征处理——降维</a></li>
                        
                          <li><a title="4.1 回归模型" href="15637037691075.html">4.1 回归模型</a></li>
                        
                          <li><a title="4.2 回归与分类" href="15637037677393.html">4.2 回归与分类</a></li>
                        
                          <li><a title="4.3 支持向量机" href="15637037728199.html">4.3 支持向量机</a></li>
                        
                          <li><a title="4.4 k近邻 —— 非参模型" href="15637037731266.html">4.4 k近邻 —— 非参模型</a></li>
                        
                          <li><a title="4.5 树模型" href="15637037678245.html">4.5 树模型</a></li>
                        
                          <li><a title="4.6 集成" href="15637037692016.html">4.6 集成</a></li>
                        
                          <li><a title="4.7 聚类1" href="15636947700701.html">4.7 聚类1</a></li>
                        
                          <li><a title="4.7 聚类2——-效果评价" href="15637037683688.html">4.7 聚类2——-效果评价</a></li>
                        
                          <li><a title="4.8 自适应的基函数——神经网络" href="15637025348085.html">4.8 自适应的基函数——神经网络</a></li>
                        
                          <li><a title="4.9 深度学习综述" href="15637037686386.html">4.9 深度学习综述</a></li>
                        
                          <li><a title="FM" href="15637037720747.html">FM</a></li>
                        
                          <li><a title="FM 模型" href="15637037680228.html">FM 模型</a></li>
                        
                          <li><a title="query文本聚类" href="15637025345613.html">query文本聚类</a></li>
                        
                          <li><a title="t-sne" href="15637037679781.html">t-sne</a></li>
                        
                          <li><a title="xgboost" href="15637025344879.html">xgboost</a></li>
                        
                          <li><a title="【聚类】-效果评价" href="15637037699016.html">【聚类】-效果评价</a></li>
                        
                          <li><a title="一、基础篇" href="15637037677178.html">一、基础篇</a></li>
                        
                          <li><a title="二、起步篇—— 数据预处理[python]" href="15637025346988.html">二、起步篇—— 数据预处理[python]</a></li>
                        
                          <li><a title="二、起步篇——数据预处理[方法论]" href="15636947700356.html">二、起步篇——数据预处理[方法论]</a></li>
                        
                          <li><a title="二、起步篇——数据预处理[方法论]" href="15637025346040.html">二、起步篇——数据预处理[方法论]</a></li>
                        
                          <li><a title="聚类Tools篇" href="15637025345910.html">聚类Tools篇</a></li>
                        
                          <li><a title="聚类Tools篇" href="15637037682671.html">聚类Tools篇</a></li>
                        
                          <li><a title="聚类方法-spark的bisecting和streaming" href="15637037731727.html">聚类方法-spark的bisecting和streaming</a></li>
                        
                          <li><a title="聚类方法Mini Batch KMeans" href="15637025344831.html">聚类方法Mini Batch KMeans</a></li>
                        
                          <li><a title="视频广告" href="15637025347693.html">视频广告</a></li>
                        

                    
                      <li class="side-title"><span>6 推荐系统</span></li>
                        
                          <li><a title="章1 基本介绍" href="15637025348511.html">章1 基本介绍</a></li>
                        
                          <li><a title="章2 利用用户行为数据" href="15637025347286.html">章2 利用用户行为数据</a></li>
                        

                    
                      <li class="side-title"><span>6 文本&视频</span></li>
                        
                          <li><a title="Face综述" href="15637037688620.html">Face综述</a></li>
                        
                          <li><a title="face_recgnization" href="15637037690385.html">face_recgnization</a></li>
                        
                          <li><a title="图像识别模型—— 1.利用已有的进行微调" href="15637037708871.html">图像识别模型—— 1.利用已有的进行微调</a></li>
                        

                    
                      <li class="side-title"><span>7 深度学习</span></li>
                        
                          <li><a title="3.【解释性】LIME" href="15637037677008.html">3.【解释性】LIME</a></li>
                        
                          <li><a title="TensorFlow" href="15637037730028.html">TensorFlow</a></li>
                        
                          <li><a title="[2018-06-25]学习1" href="15637037693934.html">[2018-06-25]学习1</a></li>
                        
                          <li><a title="【NG-DL】course2_week1 优化网络参数" href="15637025344767.html">【NG-DL】course2_week1 优化网络参数</a></li>
                        
                          <li><a title="【Tensorflow】week2 Introduction to Computer Vision" href="15637025345757.html">【Tensorflow】week2 Introduction to Computer Vision</a></li>
                        
                          <li><a title="神经网络解释性问题" href="15637037679634.html">神经网络解释性问题</a></li>
                        
                          <li><a title="第一章 引言" href="15637025345079.html">第一章 引言</a></li>
                        
                          <li><a title="第七章 正则化" href="15637025346077.html">第七章 正则化</a></li>
                        
                          <li><a title="第三章 概率与信息论" href="15637025345792.html">第三章 概率与信息论</a></li>
                        
                          <li><a title="第二章 线性代数" href="15637025345723.html">第二章 线性代数</a></li>
                        
                          <li><a title="第五章 机器学习" href="15637025346737.html">第五章 机器学习</a></li>
                        
                          <li><a title="第八章 深度模型中的优化" href="15637037731128.html">第八章 深度模型中的优化</a></li>
                        
                          <li><a title="第六章 深度前馈网络" href="15637025345687.html">第六章 深度前馈网络</a></li>
                        
                          <li><a title="第四章 数值计算" href="15637037679680.html">第四章 数值计算</a></li>
                        

                    
                      <li class="side-title"><span>10 比赛学习</span></li>
                        
                          <li><a title="比赛学习" href="15637037730631.html">比赛学习</a></li>
                        

                    
                      <li class="side-title"><span>数据科学-清单</span></li>
                        
                          <li><a title="推荐资源" href="15637037694950.html">推荐资源</a></li>
                        
                          <li><a title="目录" href="15637025347820.html">目录</a></li>
                        
                          <li><a title="资源List" href="15637025346338.html">资源List</a></li>
                        

                    
                  </ul>
                </nav>
                </div>
              </div>
            </div>
            <div class="large-9 medium-9 columns">

 <div class="markdown-body">
<h1>4.1 回归模型</h1>

<p>进入统计机器学习大门，最基础的从回归分析说起。</p>

<h2 id="toc_0">1.回归分析</h2>

<p>机器学习从最简单的回归分析说起，这次从最小二乘的几何意义角度去看回归分析。</p>

<p>\[Y = X’B\]<br/>
我们知道最终估计的满足 \((y-X\hat\beta)^TX=0\)。即最优估计是在空间上的正交投影</p>

<p><img src="media/15350244372147/15350246581231.jpg" alt=""/><br/>
统计中的一些基本概念：</p>

<ul>
<li>t 检验</li>
<li>F 检验</li>
<li>p value</li>
<li>多重共线性</li>
<li></li>
</ul>

<h2 id="toc_1">2.正则化处理</h2>

<p>训练数据是有限的时候，总可以通过增加参数的方法提高模型复杂度，降低训练误差，但是其泛化能力不好。正则化即通过调整参数的取值，来平衡<strong>偏差</strong>和<strong>方差</strong>的关系。</p>

<p>线性回归中，最直接的方法就行在loss function中添加正则化项。一般形式如下：</p>

<p>\[E(w) = \sum [f(x_i, w) - y_i]^2 + \lambda g(||w||_p)\]</p>

<ul>
<li>当取一范数时，即为lasso；</li>
<li>二范数：岭回归</li>
<li>一范数和二范数组合：弹性网络。  \(a||w||^2_2 + (1-a)||w||_1\)</li>
</ul>

<p>一范数和二范数的几何意义区别如下(这里就不解释了)：</p>

<ul>
<li>lasso会将特征衰减到0</li>
<li>岭回归大量特征系数都比较小</li>
<li>弹性网络结合了两种方法的优点</li>
</ul>

<p><img src="media/15350244372147/15350256600383.jpg" alt=""/></p>

<blockquote>
<p>从概率不同学派的角度来看上面的问题。<br/>
正则化的方式，是从频率学派角度来看；而贝叶斯学派视角来看，正则化其实就是引入了关于参数的先验信息。</p>
</blockquote>

<p>贝叶斯学派是假定参数服从某种分布，然后根据其分布利用积分的方法将其消除掉。这一过程叫<strong>边际化</strong>。边际化的过程其实恰好是正则化/泛化的过程。</p>

<p>可以证明，岭回归是w满足正态分布，lasso是当w满足拉普拉斯分布时候通过最大后验概率得到的估计结果。</p>

<blockquote>
<p>code</p>
</blockquote>

<pre><code>import numpy as np # 快速操作结构数组的工具
import matplotlib.pyplot as plt  # 可视化绘制
from sklearn.linear_model import Lasso,LassoCV,LassoLarsCV   # Lasso回归,LassoCV交叉验证实现alpha的选取，LassoLarsCV基于最小角回归交叉验证实现alpha的选取

# ========Lasso回归========
model = Lasso(alpha=0.01)  # 调节alpha可以实现对拟合的程度
# model = LassoCV()  # LassoCV自动调节alpha可以实现选择最佳的alpha。
# model = LassoLarsCV()  # LassoLarsCV自动调节alpha可以实现选择最佳的alpha
model.fit(X, y)   # 线性回归建模
print(&#39;系数矩阵:\n&#39;,model.coef_)
print(&#39;线性回归模型:\n&#39;,model)
# print(&#39;最佳的alpha：&#39;,model.alpha_)  # 只有在使用LassoCV、LassoLarsCV时才有效
# 使用模型预测
predicted = model.predict(X)

</code></pre>

<h2 id="toc_2">3.广义线性模型</h2>

<p>广义线性模型可以看做一般线性模型的推广，既然说他是推广，说明有一些问题是传统的线性模型没法解决的。</p>

<p>广义线性模型中y的密度函数形式是基于指数分布族的\[p(y;\theta)=b(y)exp[\theta&#39;T(y)+a(\theta)]\]<br/>
其中\(T(y)\)是一个充分统计量，通常可以等于\(y\)。 常见的正态分布、指数分布、二项分布、泊松分布都属于指数分布族，都可以转为这种形式。</p>

<p>介绍一个常用的广义线性模型：</p>

<p>xxx</p>

<h2 id="toc_3">4.基函数扩展：属性的非线性化</h2>

<p>线性模型的表达能力有限，前面广义线性模型的思路是将因变量y做了一个非线性映射。而从另一个角度，可以将解释变量变为非线性的，即<br/>
\[y=\beta_0+\beta_1x_1 + ...+\beta_nx_n\]<br/>
可以扩展为<strong>基函数扩展模型</strong><br/>
\[y=\beta_0+\beta_1f(x_1) + ...+\beta_nf(x_n)\]</p>

<p>比如常见的多项式回归\[y=\beta_0+\beta_1 x + ...+\beta_n x^n\]</p>

<p>多项式回归会存在一些问题：</p>

<ul>
<li>\(x\)和\(x^k\)之间是相关的，不太好解释清楚每个变量的贡献程度</li>
<li>会出现过拟合的情况</li>
</ul>

<p><strong>多元自适应回归样条MARS</strong></p>

<ul>
<li>多项式整体是线性，局部非非线性</li>
<li>MARS: 整体是非线性，局部是线性(分段函数)</li>
</ul>

<p>样条函数，需要满足一些最基本的一些条件</p>

<ul>
<li>在knot节点处满足函数的连续性</li>
<li>一阶导数连续，二阶导数连续，则称为三次样条</li>
</ul>

<p>平滑样条</p>

<p>\[E=\sum_{i=1}^n [y_i-g(x_i)]^2 +\lambda\int g&#39;&#39;(t)^2 \]</p>

<p>code: <code>patsy</code></p>


</div>

<br /><br />
<hr />

<div class="row clearfix">
  <div class="large-6 columns">
	<div class="text-left" style="padding:15px 0px;">
		
	        <a href="15637037677008.html"  title="Previous Post: 3.【解释性】LIME">&laquo; 3.【解释性】LIME</a>
	    
	</div>
  </div>
  <div class="large-6 columns">
	<div class="text-right" style="padding:15px 0px;">
		
	        <a href="15637037677393.html" 
	        title="Next Post: 4.2 回归与分类">4.2 回归与分类 &raquo;</a>
	    
	</div>
  </div>
</div>

<div class="row">
<div style="padding:0px 0.93em;" class="share-comments">

</div>
</div>
<script type="text/javascript">
	$(function(){
		var currentURL = '15637037691075.html';
		$('#side-nav a').each(function(){
			if($(this).attr('href') == currentURL){
				$(this).parent().addClass('active');
			}
		});
	});
</script>  
</div></div>


<div class="page-bottom">
  <div class="row">
  <hr />
  <div class="small-9 columns">
  <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
  <div class="small-3 columns">
  <p class="copyright text-right"><a href="#header">TOP</a></p>
  </div>
   
  </div>
</div>

        </section>
      </div>
    </div>
    
    
    <script src="asset/js/foundation.min.js"></script>
    <script src="asset/js/foundation/foundation.offcanvas.js"></script>
    <script>
      $(document).foundation();

     
    </script>
    
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>

  </body>
</html>
