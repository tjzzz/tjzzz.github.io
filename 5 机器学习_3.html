<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  5 机器学习 - zhenzhen学习笔记
  
  </title>
  
  
  <link href="atom.xml" rel="alternate" title="zhenzhen学习笔记" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />
    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript">
  function before_search(){
    var searchVal = 'site: ' + document.getElementById('search_input').value;
    document.getElementById('search_q').value = searchVal;
    return true;
  }
</script>
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>


  <section class="top-bar-section">
  <div class="row">
      <div style="position: relative;width:100%;"><div style="position: absolute; width:100%;">
        <ul id="main-menu" class="left">
        
        <li id=""><a target="_self" href="index.html">Home</a></li>
        
        <li id=""><a target="_self" href="archives.html">Archives</a></li>
        
        <li id=""><a target="_self" href="about_me.html">aboutme</a></li>
        
        </ul>

        <ul class="right" id="search-wrap">
          <li>
<form target="_blank" onsubmit="return before_search();" action="http://google.com/search" method="get">
    <input type="hidden" id="search_q" name="q" value="" />
    <input tabindex="1" type="search" id="search_input"  placeholder="Search"/>
</form>
</li>
          </ul>
      </div></div>
  </div>
  </section>

</nav>

        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; zhenzhen学习笔记</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
        
        <li><a target="_self" href="index.html">Home</a></li>
        
        <li><a target="_self" href="archives.html">Archives</a></li>
        
        <li><a target="_self" href="about_me.html">aboutme</a></li>
        

    <li><label>Categories</label></li>

        
            <li><a href="1%20Tools.html">1 Tools</a></li>
        
            <li><a href="2%20Get%20Data.html">2 Get Data</a></li>
        
            <li><a href="3%20%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96.html">3 数据可视化</a></li>
        
            <li><a href="4%20%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95.html">4 统计方法</a></li>
        
            <li><a href="5%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html">5 机器学习</a></li>
        
            <li><a href="6%20%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F.html">6 推荐系统</a></li>
        
            <li><a href="6%20%E6%96%87%E6%9C%AC&%E8%A7%86%E9%A2%91.html">6 文本&视频</a></li>
        
            <li><a href="7%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html">7 深度学习</a></li>
        
            <li><a href="8%20%E6%AF%94%E8%B5%9B%E5%AD%A6%E4%B9%A0.html">8 比赛学习</a></li>
        
            <li><a href="%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6-%E6%B8%85%E5%8D%95.html">数据科学-清单</a></li>
        
            <li><a href="%E8%BD%A8%E8%BF%B9%E6%95%B0%E6%8D%AE.html">轨迹数据</a></li>
         

      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>


        <section id="main-content" role="main" class="scroll-container">
        
       

 <script type="text/javascript">
	$(function(){
		$('#menu_item_index').addClass('is_active');
	});
</script>
<div class="row">
	<div class="large-8 medium-8 columns">
		<div class="markdown-body home-categories">
		
			<div class="article">
                <a class="clearlink" href="15637037683688.html">
                
                  <h1>4.7 聚类2——-效果评价</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>一般分为两类：</p>

<ul>
<li>外部标准：即基于人工的判断，需要有个标注集合</li>
<li>内部标准：基于类内和类间聚类的目标函数的判断</li>
</ul>

<h2 id="toc_0">内部标准clustering-performance-evaluation</h2>

<ul>
<li>CH 准则</li>
<li>轮廓系数</li>
</ul>

<h2 id="toc_1">外部标准——人工判定</h2>

<p>假设：<br/>
机器判断的类别集合是：\(C=\{C_1,C_2,...C_m\}\)<br/>
人工判断的类别集合是：\(P=\{P_1,P_2,...P_s\}\)</p>

<h3 id="toc_2">1.1混淆矩阵</h3>

<p>基于数据样本点的角度：<br/>
对于任意两个数据pair，\((x_i,x_j)\)按照其在C和P中是否属于同一个簇，可以构造出混淆矩阵</p>

<table>
<thead>
<tr>
<th></th>
<th>P_1</th>
<th>p_0</th>
</tr>
</thead>

<tbody>
<tr>
<td>C_1</td>
<td>a</td>
<td>b</td>
</tr>
<tr>
<td>C_0</td>
<td>c</td>
<td>d</td>
</tr>
</tbody>
</table>

<p><img src="media/15078603543147/15078631739679.jpg" alt=""/></p>

<h3 id="toc_3">1.2簇的准确率/召回率</h3>

<p>基于簇pair的，考虑对任意一个人工与机器的.\(P_j,C_i\)。对于每一个人工标注的\(P_j\),在机器标注中应该都会对应一个&quot;最相关的&quot;。可以遍历C中所有的cluster，分别计算准确率，召回率，F_score。<br/>
<img src="media/15078603543147/15078720767171.jpg" alt=""/></p>

<p>然后对于所有簇的F值做加权平均<br/>
\[ClassF=\sum w_j F(p_j), w_i=n_j/n\]</p>

<p>classF指标，相当于是以人工标注的簇为基准，将聚类的簇尽量逼近这个标注的结果。</p>

<h2 id="toc_4">1.3</h2>

<p>1.2中的方法相当于要求的比较严格，即以人工标注的集合簇为准。</p>

<p>实际中其实只要保证我们聚的每一个类\(C_i\)是有意义的就可以，即以C为主</p>

<p>类似的定义 \(F(C_i)=\max_{1\lt j \lt s}F(P_j, C_i)\)<br/>
\[F=\sum w_i F(C_i), w_i=|C_i|/n\]</p>

<ul>
<li>问题： 这个指标可能变化不是非常明显</li>
</ul>

<h2 id="toc_5">1.4基于数据对象的准召F</h2>

<p><img src="media/15078603543147/15078731022919.jpg" alt=""/></p>

<h2 id="toc_6">思考</h2>

<ol>
<li>基于人工标注的方法中，认为人工标注的是准确的或者说结果是唯一的。实际上一堆sample可以有不同的分类方法，而且每种方法可能都是对的。
<code>
e.g 苹果维修， 冰箱维修，苹果价格，冰箱价格，中国人民大学
</code>
如何进行标注，或者标注结果是非固定时候怎么衡量聚类效果的好坏？？</li>
</ol>

<h2 id="toc_7">参考资料</h2>

<p><a href="http://blog.csdn.net/itplus/article/details/10322361">http://blog.csdn.net/itplus/article/details/10322361</a></p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2019/7/21</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='5%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html'>5 机器学习</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15637037686386.html">
                
                  <h1>4.9 深度学习综述</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>这里只是简单介绍，后续会在深度学习章节中进行详细说明</p>

<p><strong>通用逼近定理</strong></p>

<p><img src="media/15394437873112/15394453932519.jpg" alt=""/></p>

<h2 id="toc_0">参考资料</h2>

<p><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650739143&amp;idx=1&amp;sn=f51551128021e7747205f87971f4762e&amp;chksm=871ad5b9b06d5caf0a5b4601863adc213eb42573bbdc2773e54ff1c585b3954a8644df024015&amp;mpshare=1&amp;scene=1&amp;srcid=0313P1tfCgE3zTBXJuNIHaBl%23rd">https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650739143&amp;idx=1&amp;sn=f51551128021e7747205f87971f4762e&amp;chksm=871ad5b9b06d5caf0a5b4601863adc213eb42573bbdc2773e54ff1c585b3954a8644df024015&amp;mpshare=1&amp;scene=1&amp;srcid=0313P1tfCgE3zTBXJuNIHaBl%23rd</a></p>

<p><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650739820&amp;idx=1&amp;sn=260173be8cecc3a10d7b455922c10e0c&amp;chksm=871ad012b06d5904e65e96d0cfa236d0b6c7ce5683dd8d29514e4cbe420dc5b1ccd2786eea2c&amp;mpshare=1&amp;scene=1&amp;srcid=0324xGIxttOochJWNMPaDibb%23rd">https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650739820&amp;idx=1&amp;sn=260173be8cecc3a10d7b455922c10e0c&amp;chksm=871ad012b06d5904e65e96d0cfa236d0b6c7ce5683dd8d29514e4cbe420dc5b1ccd2786eea2c&amp;mpshare=1&amp;scene=1&amp;srcid=0324xGIxttOochJWNMPaDibb%23rd</a></p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2019/7/21</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='5%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html'>5 机器学习</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15637037677393.html">
                
                  <h1>4.2 回归与分类</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<blockquote>
<p>统计模型一开始是从回归分析开始的，但是实际问题中更加普遍的是分类问题。那么很自然的一个问题是，如果利用回归分析的方法的话，如何去做分类问题呢？换句话说回归和分类之间的联系在哪里呢？</p>
</blockquote>

<p>一个很自然的想法是，根据回归分析y的结果，按照一定规则将其映射到不同的区间段，从而形成一个分类模型。即连续变量 =&gt; 分类变量</p>

<h3 id="toc_0">1. 硬输出——判别分析</h3>

<p>直接根据阈值划分分类结果， 而这个映射函数即为<strong>判别函数</strong>。比较典型的就是判别分析了。常用的判别分析的方法：</p>

<blockquote>
<p>距离判别法</p>
</blockquote>

<p>即按照样本距离各个总体距离的远近来判断所属的归类。比如基于欧式距离或马氏距离，欧式距离没有考虑到本身特征量纲的差异，所以用的不多。这里以马氏距离，两个类别为例。</p>

<p>例子：已知一个样本X可能来自两个总体\(G_1\)和\(G_2\)其中的一个，其中 \(G_1: \mu_1,V_1, G_2:\mu_2, V_2\), 现在给定X，判断其属于哪一类。<br/>
注意：对总体分布没有要求</p>

<p>解析：判别函数\(W(X)=D^2(X,G_2)-D^2(X,G_1)=(X-\mu_2)V_2^{-1}(X-\mu_2)-(X-\mu_1)V_1^{-1}(X-\mu_1)\).</p>

<p>在实际中因为总体均值和方差是位置的，需要用样本进行估计。当\(V_1=V_2=V\)时候，二次判别式可以变成线性的，有\(W(X) = (X-\bar\mu)V^{-1}(\mu_1-\mu_2)\)， 其中\(\bar\mu = (\mu_1+\mu_2)/2\)</p>

<p>误判概率：判别分析肯定也有出错的时候，下面来讨论下误判概率问题。</p>

<p><img src="media/15383213879430/15384587841040.jpg" alt=""/></p>

<p>从上图中可以比较清楚的看到，出错的概率即为图中阴影部分的面积。</p>

<p>假设X属于1，下面计算其被判断成2的概率即P(2|1)=P(W(X)&lt;0). </p>

<p>令\(\lambda=(\mu_1-\mu_2)&#39;V^{-1}(\mu_1-\mu_2)\). 因为\(W(X) = (X-\bar\mu)V^{-1}(\mu_1-\mu_2)\)， 所以可以计算出<br/>
\(E(W(X))=(\mu_1-\bar\mu)V^{-1}(\mu_1-\mu_2)=\lambda/2\)<br/>
\(D(X)=(\mu_1-\mu_2)&#39;V^{-1}(\mu_1-\mu_2)=\lambda\)<br/>
在X服从正态分布的假定下，有\(W(X)~N(\lambda/2, \lambda)\)，从而可以计算出\(P(2|1)\)与\(P(1|2)\)</p>

<blockquote>
<p>贝叶斯判别法</p>
</blockquote>

<p>前面说的距离判别法因为形式简单，计算简便应用比较广。但是没有考虑到各个总体出现的可能性/概率大小，以及误判之后造成的不同损失大小。而贝叶斯判别法就是考虑这两点的一种判别方法。</p>

<p>这里只对其建模过程做个简述。<br/>
建模：假设m个类别，每个的先验概率和密度函数是 \(q_i, f_i(x)\), 而将原本属于类别i的判给类别j时候造成的损失，记为\(C(j|i)=\)， 而误判的概率可以写成\(p(j|i,R)=\int_{R_j}f_i(x)dx\)。 因此划分规则R最终带来的损失是<br/>
\[g(R)=\sum^m_1 q_i r(i,R)=\sum_1^m q_i\sum_{j=1}^m C(j|i)p(j|i,R)\]</p>

<blockquote>
<p>Fisher判别法</p>
</blockquote>

<p>fisher 判别法出发点和前面两个略有不同，是从投影/降维角度(将多元转为一元)来进行的。以两类为例：假定训练数据分为两个类别C1和C2,每个类别的均值分别是\(u_1\)和\(u_2\),如前所述经过\(y=W^TX+b\)投影后，最终的目标是希望类内的距离尽量小，类间的距离尽量大</p>

<p>类内距离：\(s_k=\sum_{x_i\in C_k}(w^Tx_i-w^Tu_k)^2   k=1,2\)<br/>
类间聚类：\((w^Tu_1 - w^Tu_2)^2\)</p>

<p>因此最终是最大化这个目标函数\(J(W)=\frac{(w^Tu_1 - w^Tu_2)^2}{s_1^2+s_2^2}\)，为了保证\(W\)的唯一性，不妨设\(W&#39;S_WW=1\)</p>

<p>\[MAX J(W)=\frac{W^TS_BW}{W^TS_WW}\]<br/>
\[st. W&#39;S_WW=1 \]</p>

<p>这里简单推导一下求解过程，令<br/>
\[L(W;\lambda)=W&#39;S_BW-\lambda(W&#39;S_WW -1) \]<br/>
\[\frac{\partial J}{\partial w}=2S_BW-2\lambda S_ww=0\]<br/>
\[\frac{\partial J}{\partial \lambda}=W&#39;S_WW - 1=0\]<br/>
=&gt; \(W&#39;S_BW=\lambda\)，所以只需最大化\(\lambda\)<br/>
\(S_BW=\lambda S_ww\)  ==&gt; \(S_W^{-1}S_BW=\lambda W\)<br/>
因此取\(S_W^{-1}S_B\)的最大特征值即为\(\lambda\)，对应的特征向量即为\(W\)</p>

<p>当然除了判别分析之外，还有SVM等方法，这个后续会具体介绍</p>

<h3 id="toc_1">2.软输出</h3>

<p>利用似然度区分回归结果，根据回归值和似然性的关系输出样本属于某个类别的<strong>概率</strong>。即通过一个激活函数，架起了回归和分类问题的通道。<br/>
\[y(x) = g^{-1}(w^Tx+b)\]</p>

<p>逻辑回归就是一个典型的例子。传统的回归模型的假定已经不成立，因为预测变量y是服从二项分布，逻辑回归估计的是样本属于某个类别的后验概率。即</p>

<p>\[p(c_1|x)=\frac{p(x|c_1)p(c_1)}{p(x|c_1)p(c_1) + p(x|c_2)p(c_2)}\]</p>

<p>从这个角度看，对上式稍加变形就有</p>

<p>\[p(c_1|x)=\frac{1}{1+exp(-z)}=\pi(z)\]<br/>
其中\(z=ln \frac{p(x|c_1)p(c_1)}{p(x|c_2)p(c_2)}=w^Tx + b\)</p>

<p>参数估计用MLE方法：最终分类结果只有两个，所以是服从二项分布<br/>
\[p(w,b|x) = \prod \pi(x_i)^{y_i}[1-\pi(x_i)]^{1-y_i}\]</p>

<p>对数似然函数<br/>
\[J(w)=\sum_1^n y_i ln(\pi(z_i)) + (1-y_i)ln(1-\pi(z_i))\]</p>

<p>最大化这个目标函数，可以用梯度下降的方法。注意到sigmoid函数有一个比较好的性质\(\pi&#39;(z)=\pi(z)(1-\pi(z))\)</p>

<p>推导：</p>

<p>\[\frac{\partial J(W)}{\partial w_j}=\sum (y_i\frac{1}{pi(z_i)}-(1-y_i)\frac{1}{1-\pi(z_i)})\pi(z_i)(1-\pi(z_i))x_j\]<br/>
\[=\sum [y_i(1-\pi(z_i)) - (1-y_i)\pi(z_i)]x_j\]</p>

<p>\[=\sum(y_i -\pi(z_i))x_j\]</p>

<p>因此在利用梯度下降方法更新权重时候，只需要按照\(w_j:=w_j +\eta\sum(y_i -\pi(z_i))x_j\)即可</p>

<p>梯度下降的python版本实现 <a href="https://github.com/tjzzz/data_science/blob/master/statistical%20learning/logistic_regression.py">github</a></p>

<p><strong>sklearn实现</strong>： 逻辑回归是在<code>sklearn.linear_model</code></p>

<pre><code>from sklearn.linear_model import LogisticRegression
model = LogisticRegression(multi_class=&#39;multinomial&#39;, solver=&#39;sag&#39;)
model.fit(X_train,y_train)
y_pred = model.predict(X_test)
</code></pre>

<blockquote>
<p>OR值(odds ratio), 本来是在医学实验中的词，值实验组中暴露人数与非暴露人数的比值，与对照组中暴露人数与非暴露人数的比值的比值，所以也叫<strong>比值比</strong><br/>
逻辑回归的更新公式与一般的线性回归的极为相似。\(\sum(y_i-x_iw)x_j\)</p>
</blockquote>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2019/7/21</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='5%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html'>5 机器学习</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15637037678245.html">
                
                  <h1>4.5 树模型</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	
                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2019/7/21</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='5%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html'>5 机器学习</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15637037679781.html">
                
                  <h1>t-sne</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<pre><code>from sklearn.manifold import TSNE
from sklearn.datasets import load_iris
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
 
 
 
data=pd.read_csv(&#39;test.data&#39;, sep=&#39;,&#39;,header=None)
dd= data[range(200)]

X_tsne = TSNE().fit_transform(dd)
X_pca = PCA().fit_transform(dd)

out = DataFrame(np.hstack((X_tsne, X_pca)))

out2=data[200])

out.to_csv(&#39;save_data.csv&#39;)


plt.figure(figsize=(10, 5))
plt.subplot(121)
plt.scatter(X_tsne[:, 0], X_tsne[:, 1],c=data[200])
plt.subplot(122)
#plt.scatter(X_pca[:, 0], X_pca[:, 1], c=iris.target)
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=data[200])
</code></pre>

<p>R<br/>
```</p>

<pre><code>
</code></pre>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2019/7/21</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='5%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html'>5 机器学习</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
              


			<div class="row">
			  <div class="large-6 columns">
			  <p class="text-left" style="padding-top:25px;">
			   <a href="5 机器学习_2.html">&laquo; Prev Page</a>  
			  </p>
			  </div>
			  <div class="large-6 columns">
			<p class="text-right" style="padding-top:25px;">
			 <a href="5 机器学习_4.html">&raquo; Next Page</a> 
			</p>
			  </div>
			</div>
		</div>
	</div><!-- large 8 -->

 <div class="large-4 medium-4 columns">
  <div class="hide-for-small">
    <div id="sidebar" class="sidebar">
          <div id="site-info" class="site-info">
            
                <h1>zhenzhen学习笔记</h1>
                <div class="site-des"></div>
                <div class="social">









<a target="_blank" class="github" target="_blank" href="tjzzz.github.io" title="GitHub">GitHub</a>

  <a target="_blank" class="rss" href="atom.xml" title="RSS">RSS</a>
                
              	 </div>
          	</div>

             

              <div id="site-categories" class="side-item ">
                <div class="side-header">
                  <h2>Categories</h2>
                </div>
                <div class="side-content">

      	<p class="cat-list">
        
            <a href="1%20Tools.html"><strong>1 Tools</strong></a>
        
            <a href="2%20Get%20Data.html"><strong>2 Get Data</strong></a>
        
            <a href="3%20%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96.html"><strong>3 数据可视化</strong></a>
        
            <a href="4%20%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95.html"><strong>4 统计方法</strong></a>
        
            <a href="5%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html"><strong>5 机器学习</strong></a>
        
            <a href="6%20%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F.html"><strong>6 推荐系统</strong></a>
        
            <a href="6%20%E6%96%87%E6%9C%AC&%E8%A7%86%E9%A2%91.html"><strong>6 文本&视频</strong></a>
        
            <a href="7%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html"><strong>7 深度学习</strong></a>
        
            <a href="8%20%E6%AF%94%E8%B5%9B%E5%AD%A6%E4%B9%A0.html"><strong>8 比赛学习</strong></a>
        
            <a href="%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6-%E6%B8%85%E5%8D%95.html"><strong>数据科学-清单</strong></a>
        
            <a href="%E8%BD%A8%E8%BF%B9%E6%95%B0%E6%8D%AE.html"><strong>轨迹数据</strong></a>
         
        </p>


                </div>
              </div>

              <div id="site-categories" class="side-item">
                <div class="side-header">
                  <h2>Recent Posts</h2>
                </div>
                <div class="side-content">
                <ul class="posts-list">
	      
		      
			      <li class="post">
			        <a href="15686309605233.html">matplotlib</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15687050894061.html">综述</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15686368904229.html">基于dtw进行聚类</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15636947700701.html">4.7 聚类1</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15637037683461.html">Jupyter notebook</a>
			      </li>
		     
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		   
		  		</ul>
                </div>
              </div>
        </div><!-- sidebar -->
      </div><!-- hide for small -->
</div><!-- large 4 -->

</div><!-- row -->

 <div class="page-bottom clearfix">
  <div class="row">
   <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
</div>

        </section>
      </div>
    </div>

  
    

    <script src="asset/js/foundation.min.js"></script>
    <script>
      $(document).foundation();
      function fixSidebarHeight(){
        var w1 = $('.markdown-body').height();
          var w2 = $('#sidebar').height();
          if (w1 > w2) { $('#sidebar').height(w1); };
      }
      $(function(){
        fixSidebarHeight();
      })
      $(window).load(function(){
          fixSidebarHeight();
      });
     
    </script>

    
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>


  </body>
</html>
