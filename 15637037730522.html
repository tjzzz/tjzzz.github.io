<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  关于长点击阈值划分方法 - zhenzhen学习笔记
  
  </title>
 <meta name="description" content="">
 <link href="atom.xml" rel="alternate" title="zhenzhen学习笔记" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />

    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
    <script src="asset/highlightjs/highlight.pack.js"></script>
    <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
    <script>hljs.initHighlightingOnLoad();</script>
    
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>

<div id="header">
    <h1><a href="index.html">zhenzhen学习笔记</a></h1>
</div>

</nav>
        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; zhenzhen学习笔记</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
      <li><a href="index.html">Home</a></li>
      
        <li class="divider"></li>
        <li><label>1 Tools</label></li>

          
            <li><a title="1 安装-mac" href="15637025344954.html">1 安装-mac</a></li>
          
            <li><a title="git" href="15637037678160.html">git</a></li>
          
            <li><a title="jupyterLab" href="15637037680349.html">jupyterLab</a></li>
          
            <li><a title="markdown" href="15637037679256.html">markdown</a></li>
          
            <li><a title="sublime" href="15637037680741.html">sublime</a></li>
          
            <li><a title="工欲善其事必先利其器——Jupyter notebook" href="15637037683461.html">工欲善其事必先利其器——Jupyter notebook</a></li>
          
            <li><a title="工欲善其事必先利其器——conda" href="15637025346412.html">工欲善其事必先利其器——conda</a></li>
          

      
        <li class="divider"></li>
        <li><label>2 Get Data</label></li>

          
            <li><a title="公开微观数据库 1.0" href="15637025347227.html">公开微观数据库 1.0</a></li>
          

      
        <li class="divider"></li>
        <li><label>3 数据可视化</label></li>

          
            <li><a title="Data product" href="15637037683065.html">Data product</a></li>
          
            <li><a title="rCharts" href="15637037678380.html">rCharts</a></li>
          
            <li><a title="数据可视化(seaborn)" href="15637037713554.html">数据可视化(seaborn)</a></li>
          

      
        <li class="divider"></li>
        <li><label>4 统计方法</label></li>

          
            <li><a title="1 估计的置信度" href="15637036455584.html">1 估计的置信度</a></li>
          
            <li><a title="2 不同设计之间有统计学差异吗" href="15637025346225.html">2 不同设计之间有统计学差异吗</a></li>
          
            <li><a title="3 样本量的确定" href="15637036605080.html">3 样本量的确定</a></li>
          
            <li><a title="关于长点击阈值划分方法" href="15637037730522.html">关于长点击阈值划分方法</a></li>
          
            <li><a title="卡方检验" href="15637025346262.html">卡方检验</a></li>
          
            <li><a title="统计阈值" href="15637037730576.html">统计阈值</a></li>
          

      
        <li class="divider"></li>
        <li><label>5 机器学习</label></li>

          
            <li><a title="3.1 特征处理—— 特征选择" href="15637037691936.html">3.1 特征处理—— 特征选择</a></li>
          
            <li><a title="3.2 特征处理——降维" href="15637037731313.html">3.2 特征处理——降维</a></li>
          
            <li><a title="4.1 回归模型" href="15637037691075.html">4.1 回归模型</a></li>
          
            <li><a title="4.2 回归与分类" href="15637037677393.html">4.2 回归与分类</a></li>
          
            <li><a title="4.3 支持向量机" href="15637037728199.html">4.3 支持向量机</a></li>
          
            <li><a title="4.4 k近邻 —— 非参模型" href="15637037731266.html">4.4 k近邻 —— 非参模型</a></li>
          
            <li><a title="4.5 树模型" href="15637037678245.html">4.5 树模型</a></li>
          
            <li><a title="4.6 集成" href="15637037692016.html">4.6 集成</a></li>
          
            <li><a title="4.7 聚类1" href="15636947700701.html">4.7 聚类1</a></li>
          
            <li><a title="4.7 聚类2——-效果评价" href="15637037683688.html">4.7 聚类2——-效果评价</a></li>
          
            <li><a title="4.8 自适应的基函数——神经网络" href="15637025348085.html">4.8 自适应的基函数——神经网络</a></li>
          
            <li><a title="4.9 深度学习综述" href="15637037686386.html">4.9 深度学习综述</a></li>
          
            <li><a title="FM" href="15637037720747.html">FM</a></li>
          
            <li><a title="FM 模型" href="15637037680228.html">FM 模型</a></li>
          
            <li><a title="query文本聚类" href="15637025345613.html">query文本聚类</a></li>
          
            <li><a title="t-sne" href="15637037679781.html">t-sne</a></li>
          
            <li><a title="xgboost" href="15637025344879.html">xgboost</a></li>
          
            <li><a title="【聚类】-效果评价" href="15637037699016.html">【聚类】-效果评价</a></li>
          
            <li><a title="一、基础篇" href="15637037677178.html">一、基础篇</a></li>
          
            <li><a title="二、起步篇—— 数据预处理[python]" href="15637025346988.html">二、起步篇—— 数据预处理[python]</a></li>
          
            <li><a title="二、起步篇——数据预处理[方法论]" href="15636947700356.html">二、起步篇——数据预处理[方法论]</a></li>
          
            <li><a title="二、起步篇——数据预处理[方法论]" href="15637025346040.html">二、起步篇——数据预处理[方法论]</a></li>
          
            <li><a title="聚类Tools篇" href="15637025345910.html">聚类Tools篇</a></li>
          
            <li><a title="聚类Tools篇" href="15637037682671.html">聚类Tools篇</a></li>
          
            <li><a title="聚类方法-spark的bisecting和streaming" href="15637037731727.html">聚类方法-spark的bisecting和streaming</a></li>
          
            <li><a title="聚类方法Mini Batch KMeans" href="15637025344831.html">聚类方法Mini Batch KMeans</a></li>
          
            <li><a title="视频广告" href="15637025347693.html">视频广告</a></li>
          

      
        <li class="divider"></li>
        <li><label>6 推荐系统</label></li>

          
            <li><a title="章1 基本介绍" href="15637025348511.html">章1 基本介绍</a></li>
          
            <li><a title="章2 利用用户行为数据" href="15637025347286.html">章2 利用用户行为数据</a></li>
          

      
        <li class="divider"></li>
        <li><label>6 文本&视频</label></li>

          
            <li><a title="Face综述" href="15637037688620.html">Face综述</a></li>
          
            <li><a title="face_recgnization" href="15637037690385.html">face_recgnization</a></li>
          
            <li><a title="图像识别模型—— 1.利用已有的进行微调" href="15637037708871.html">图像识别模型—— 1.利用已有的进行微调</a></li>
          

      
        <li class="divider"></li>
        <li><label>7 深度学习</label></li>

          
            <li><a title="3.【解释性】LIME" href="15637037677008.html">3.【解释性】LIME</a></li>
          
            <li><a title="TensorFlow" href="15637037730028.html">TensorFlow</a></li>
          
            <li><a title="[2018-06-25]学习1" href="15637037693934.html">[2018-06-25]学习1</a></li>
          
            <li><a title="【NG-DL】course2_week1 优化网络参数" href="15637025344767.html">【NG-DL】course2_week1 优化网络参数</a></li>
          
            <li><a title="【Tensorflow】week2 Introduction to Computer Vision" href="15637025345757.html">【Tensorflow】week2 Introduction to Computer Vision</a></li>
          
            <li><a title="神经网络解释性问题" href="15637037679634.html">神经网络解释性问题</a></li>
          
            <li><a title="第一章 引言" href="15637025345079.html">第一章 引言</a></li>
          
            <li><a title="第七章 正则化" href="15637025346077.html">第七章 正则化</a></li>
          
            <li><a title="第三章 概率与信息论" href="15637025345792.html">第三章 概率与信息论</a></li>
          
            <li><a title="第二章 线性代数" href="15637025345723.html">第二章 线性代数</a></li>
          
            <li><a title="第五章 机器学习" href="15637025346737.html">第五章 机器学习</a></li>
          
            <li><a title="第八章 深度模型中的优化" href="15637037731128.html">第八章 深度模型中的优化</a></li>
          
            <li><a title="第六章 深度前馈网络" href="15637025345687.html">第六章 深度前馈网络</a></li>
          
            <li><a title="第四章 数值计算" href="15637037679680.html">第四章 数值计算</a></li>
          

      
        <li class="divider"></li>
        <li><label>10 比赛学习</label></li>

          
            <li><a title="比赛学习" href="15637037730631.html">比赛学习</a></li>
          

      
        <li class="divider"></li>
        <li><label>数据科学-清单</label></li>

          
            <li><a title="推荐资源" href="15637037694950.html">推荐资源</a></li>
          
            <li><a title="目录" href="15637025347820.html">目录</a></li>
          
            <li><a title="资源List" href="15637025346338.html">资源List</a></li>
          

      
      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>

        <section id="main-content" role="main" class="scroll-container">

          <div class="row">
            <div class="large-3 medium-3 columns">
              <div class="hide-for-small">
                <div class="sidebar">
                <nav>
                  <ul id="side-nav" class="side-nav">

                    
                      <li class="side-title"><span>1 Tools</span></li>
                        
                          <li><a title="1 安装-mac" href="15637025344954.html">1 安装-mac</a></li>
                        
                          <li><a title="git" href="15637037678160.html">git</a></li>
                        
                          <li><a title="jupyterLab" href="15637037680349.html">jupyterLab</a></li>
                        
                          <li><a title="markdown" href="15637037679256.html">markdown</a></li>
                        
                          <li><a title="sublime" href="15637037680741.html">sublime</a></li>
                        
                          <li><a title="工欲善其事必先利其器——Jupyter notebook" href="15637037683461.html">工欲善其事必先利其器——Jupyter notebook</a></li>
                        
                          <li><a title="工欲善其事必先利其器——conda" href="15637025346412.html">工欲善其事必先利其器——conda</a></li>
                        

                    
                      <li class="side-title"><span>2 Get Data</span></li>
                        
                          <li><a title="公开微观数据库 1.0" href="15637025347227.html">公开微观数据库 1.0</a></li>
                        

                    
                      <li class="side-title"><span>3 数据可视化</span></li>
                        
                          <li><a title="Data product" href="15637037683065.html">Data product</a></li>
                        
                          <li><a title="rCharts" href="15637037678380.html">rCharts</a></li>
                        
                          <li><a title="数据可视化(seaborn)" href="15637037713554.html">数据可视化(seaborn)</a></li>
                        

                    
                      <li class="side-title"><span>4 统计方法</span></li>
                        
                          <li><a title="1 估计的置信度" href="15637036455584.html">1 估计的置信度</a></li>
                        
                          <li><a title="2 不同设计之间有统计学差异吗" href="15637025346225.html">2 不同设计之间有统计学差异吗</a></li>
                        
                          <li><a title="3 样本量的确定" href="15637036605080.html">3 样本量的确定</a></li>
                        
                          <li><a title="关于长点击阈值划分方法" href="15637037730522.html">关于长点击阈值划分方法</a></li>
                        
                          <li><a title="卡方检验" href="15637025346262.html">卡方检验</a></li>
                        
                          <li><a title="统计阈值" href="15637037730576.html">统计阈值</a></li>
                        

                    
                      <li class="side-title"><span>5 机器学习</span></li>
                        
                          <li><a title="3.1 特征处理—— 特征选择" href="15637037691936.html">3.1 特征处理—— 特征选择</a></li>
                        
                          <li><a title="3.2 特征处理——降维" href="15637037731313.html">3.2 特征处理——降维</a></li>
                        
                          <li><a title="4.1 回归模型" href="15637037691075.html">4.1 回归模型</a></li>
                        
                          <li><a title="4.2 回归与分类" href="15637037677393.html">4.2 回归与分类</a></li>
                        
                          <li><a title="4.3 支持向量机" href="15637037728199.html">4.3 支持向量机</a></li>
                        
                          <li><a title="4.4 k近邻 —— 非参模型" href="15637037731266.html">4.4 k近邻 —— 非参模型</a></li>
                        
                          <li><a title="4.5 树模型" href="15637037678245.html">4.5 树模型</a></li>
                        
                          <li><a title="4.6 集成" href="15637037692016.html">4.6 集成</a></li>
                        
                          <li><a title="4.7 聚类1" href="15636947700701.html">4.7 聚类1</a></li>
                        
                          <li><a title="4.7 聚类2——-效果评价" href="15637037683688.html">4.7 聚类2——-效果评价</a></li>
                        
                          <li><a title="4.8 自适应的基函数——神经网络" href="15637025348085.html">4.8 自适应的基函数——神经网络</a></li>
                        
                          <li><a title="4.9 深度学习综述" href="15637037686386.html">4.9 深度学习综述</a></li>
                        
                          <li><a title="FM" href="15637037720747.html">FM</a></li>
                        
                          <li><a title="FM 模型" href="15637037680228.html">FM 模型</a></li>
                        
                          <li><a title="query文本聚类" href="15637025345613.html">query文本聚类</a></li>
                        
                          <li><a title="t-sne" href="15637037679781.html">t-sne</a></li>
                        
                          <li><a title="xgboost" href="15637025344879.html">xgboost</a></li>
                        
                          <li><a title="【聚类】-效果评价" href="15637037699016.html">【聚类】-效果评价</a></li>
                        
                          <li><a title="一、基础篇" href="15637037677178.html">一、基础篇</a></li>
                        
                          <li><a title="二、起步篇—— 数据预处理[python]" href="15637025346988.html">二、起步篇—— 数据预处理[python]</a></li>
                        
                          <li><a title="二、起步篇——数据预处理[方法论]" href="15636947700356.html">二、起步篇——数据预处理[方法论]</a></li>
                        
                          <li><a title="二、起步篇——数据预处理[方法论]" href="15637025346040.html">二、起步篇——数据预处理[方法论]</a></li>
                        
                          <li><a title="聚类Tools篇" href="15637025345910.html">聚类Tools篇</a></li>
                        
                          <li><a title="聚类Tools篇" href="15637037682671.html">聚类Tools篇</a></li>
                        
                          <li><a title="聚类方法-spark的bisecting和streaming" href="15637037731727.html">聚类方法-spark的bisecting和streaming</a></li>
                        
                          <li><a title="聚类方法Mini Batch KMeans" href="15637025344831.html">聚类方法Mini Batch KMeans</a></li>
                        
                          <li><a title="视频广告" href="15637025347693.html">视频广告</a></li>
                        

                    
                      <li class="side-title"><span>6 推荐系统</span></li>
                        
                          <li><a title="章1 基本介绍" href="15637025348511.html">章1 基本介绍</a></li>
                        
                          <li><a title="章2 利用用户行为数据" href="15637025347286.html">章2 利用用户行为数据</a></li>
                        

                    
                      <li class="side-title"><span>6 文本&视频</span></li>
                        
                          <li><a title="Face综述" href="15637037688620.html">Face综述</a></li>
                        
                          <li><a title="face_recgnization" href="15637037690385.html">face_recgnization</a></li>
                        
                          <li><a title="图像识别模型—— 1.利用已有的进行微调" href="15637037708871.html">图像识别模型—— 1.利用已有的进行微调</a></li>
                        

                    
                      <li class="side-title"><span>7 深度学习</span></li>
                        
                          <li><a title="3.【解释性】LIME" href="15637037677008.html">3.【解释性】LIME</a></li>
                        
                          <li><a title="TensorFlow" href="15637037730028.html">TensorFlow</a></li>
                        
                          <li><a title="[2018-06-25]学习1" href="15637037693934.html">[2018-06-25]学习1</a></li>
                        
                          <li><a title="【NG-DL】course2_week1 优化网络参数" href="15637025344767.html">【NG-DL】course2_week1 优化网络参数</a></li>
                        
                          <li><a title="【Tensorflow】week2 Introduction to Computer Vision" href="15637025345757.html">【Tensorflow】week2 Introduction to Computer Vision</a></li>
                        
                          <li><a title="神经网络解释性问题" href="15637037679634.html">神经网络解释性问题</a></li>
                        
                          <li><a title="第一章 引言" href="15637025345079.html">第一章 引言</a></li>
                        
                          <li><a title="第七章 正则化" href="15637025346077.html">第七章 正则化</a></li>
                        
                          <li><a title="第三章 概率与信息论" href="15637025345792.html">第三章 概率与信息论</a></li>
                        
                          <li><a title="第二章 线性代数" href="15637025345723.html">第二章 线性代数</a></li>
                        
                          <li><a title="第五章 机器学习" href="15637025346737.html">第五章 机器学习</a></li>
                        
                          <li><a title="第八章 深度模型中的优化" href="15637037731128.html">第八章 深度模型中的优化</a></li>
                        
                          <li><a title="第六章 深度前馈网络" href="15637025345687.html">第六章 深度前馈网络</a></li>
                        
                          <li><a title="第四章 数值计算" href="15637037679680.html">第四章 数值计算</a></li>
                        

                    
                      <li class="side-title"><span>10 比赛学习</span></li>
                        
                          <li><a title="比赛学习" href="15637037730631.html">比赛学习</a></li>
                        

                    
                      <li class="side-title"><span>数据科学-清单</span></li>
                        
                          <li><a title="推荐资源" href="15637037694950.html">推荐资源</a></li>
                        
                          <li><a title="目录" href="15637025347820.html">目录</a></li>
                        
                          <li><a title="资源List" href="15637025346338.html">资源List</a></li>
                        

                    
                  </ul>
                </nav>
                </div>
              </div>
            </div>
            <div class="large-9 medium-9 columns">

 <div class="markdown-body">
<h1>关于长点击阈值划分方法</h1>

<p>用户停留时长一直是衡量用户在落地页满意度的一个重要度量指标。在具体业务设计的时候，可以去看时长分布的中位数、平均时长等统计级指标，亦有类似于衡量时长好坏的长点击率，长点击占比等指标。</p>

<p>首先来说下长点击，简单来说长点击即停留时长比较长的一个点击时间。</p>

<h3 id="toc_0">1. 长点击，满意点击，人工打分</h3>

<p>我们说停留时间“比较长”，其实是一个相对概念，不同的资源类型可能划分的标准会不同。但是他们的出发点是一样的: 我们认为在特定资源类型下落地页时长越长，用户越倾向于满意。所以长点击本质上是用来刻画满意点击的。</p>

<p><strong>(1) 无监督的划分</strong><br/>
即我们不知道groundtruth，这个时候可以根据本身时长的分布，按照经验值比如60%，70%作为其长点击的分界点。这种划分方式 xxxx</p>

<p><strong>(2) 有监督的</strong><br/>
通过人工评估（比如qu相关性，qu的页面质量等维度），可以对qu结果进行人工打分，一般是0-4档。0，1代表不太好，2代表一般，3-4代表比较好。可以根据业务需求比如3-4认为是满意点击，2认为是一般点击，0-1认为是不满意点击。<br/>
以此人工标注来决定如何选择长点击划分阈值。</p>

<h3 id="toc_1">2. 如何划分长点击</h3>

<p>长点击阈值划分的目标，即寻找如下决策函数的参数x</p>

<p>\[<br/>
F(t) = \left\{<br/>
             \begin{array}{lr}<br/>
            1，长点击 t \ge x &amp;  \\<br/>
            0，非长点击 t&lt; x\\  <br/>
             \end{array}<br/>
\right.<br/>
\]</p>

<p>从统计分布的角度看，即使是时长比较长的结果，人工打分也可能很低，时长很短的结果人工打分也可能是满意的。所以不管寻找到的最优参数\(x\)是多少，它都有可能会误分。而我们的目的是让这种因为误分而犯错的可能性尽可能的小。<br/>
<img src="media/15542962343188/15543644977641.jpg" alt=""/></p>

<p>从以上的分布图来说更直观一些，我们的误判损失即是图中阴影部分，很容易证明，移动阈值划分x时候，损失最小的是当两个分布曲线相交的点的时候。这指导我们可以按照如下的方法进行长点击划分：</p>

<p>执行步骤<br/>
<strong>Step0： 摸底时长分布</strong></p>

<p>首先需要了解清楚数据本身的时长分布，根据时长的分布情况，大概划分不同的区间段。比如0-5，5-10，10-15，15-20，20-25，25-30，30-35，35-40， 40-50，50-60，60-100，&gt;100这样进行划分。<br/>
同于频次分布较高的部分可以划分的细致一些，频次分布较低的部分可以划分的宽度较宽一些。</p>

<p><strong>Step1： 抽样送评qu数据</strong></p>

<p>确定送评样本，因为人工评估是需要成本的，我们不可能得到整体的good或者bad的分布曲线，我们所有的只是抽取的送评样本的标注数据。这就要求我们送评的数据对于总体一定要有好的代表性：</p>

<ul>
<li>抽样分布应该和总体分布尽量一致</li>
<li>抽样量不能太小，否则样本估计总体的误差会比较大</li>
</ul>

<blockquote>
<p>如何确定最优送评样本量？（这个回来再写）<br/>
统计学的研究方法是要找到我们所关注变量的统计分布，我们最终是希望通过抽取得到的good和not_good的时长分布与整体差不多。</p>
</blockquote>

<p>数据抽取：</p>

<ul>
<li>考虑到数据抽取是基于qu粒度，一个qu其实会有多次用户点击行为，也就会有多个时长，可能波动较大。所以一般是取count(qu)&gt;5的，并且时长取的是其中位数</li>
<li><p>预送评，一般先进行少量的预送评，比如送评1000个样本。返回会用来检验数据质量和划分的精细度</p>

<ul>
<li>check自己送评的数据中是否有一些异常数据。比如sf的url路径不完成</li>
<li>check人工打分的质量程度</li>
<li>初步看下good和not_good的分布情况，大概确定长点的分布区间，从而看下送评的样本的时间段间隔精度是否需要调整</li>
</ul></li>
<li><p>正式送评</p></li>
</ul>

<p><strong>Step2： 返回分析</strong></p>

<p>根据good和not_good的频数分布，找到曲线的交点，即满足good(x) = not_good(x)的点，即可认为是长点击的分界点。短点击的划分类似，可以认为0-1的是短点击，或者更严格的0分的是短点击。 绘制bad和not_bad的频数分布，找到曲线交点。即满足bood(x) = not_bood(x)的点</p>

<ul>
<li>实际操作：实际数据的分布图可能不如示意图那么明显，甚至有多个交点的情况。这时候可以计算图中b+c的面积，绘制(x,g(x))的曲线图，找到g(x)=0.5的点即可。 如果有多个可能是因为样本量不足够，或者本身指标数据不可信(前提假定是要研究的指标与人工打分是存在单调关系的)</li>
</ul>

<h3 id="toc_2">3 应用-关于sigmoid函数的理解</h3>

<ul>
<li><p>AB实验<br/>
对于AB实验来说，有了长短点击时间阈值之后，可以直接计算长点击和短点击，更新指标评估即可。</p></li>
<li><p>interleaving实验<br/>
对于interleaving来说，实际中是将dt经过一个映射(一般是sigmoid函数)将其转化为一个0-1的打分。</p></li>
</ul>

<p>这里我们从另外一个角度来看这件事。LR或者说sigmoid函数能将一个负无穷到正无穷的数映射到0-1的一个概率值。是否是长点其实也是一个概率，当然这里时长t是取的(0, 正无穷)</p>

<p>假设<br/>
\[g(x) = \frac{good(x)}{good(x) + not\_good(x)}\]<br/>
其中 \(good(x)= \#good(t=x)\), \(not\_good(x)=\#not\_good(t= x)\)。 <br/>
所以\(g(x)\)其实表示的是在\(t=x\)时候是长点击的概率。为了书写方便，</p>

<p>\[g(x) = \frac{1}{1+ not\_good(x)/good(x)}= \frac{1}{1+ e^{ln\frac{p}{1-p}}}\]</p>

<p>这里\(p(x)\)是表示当时间等于x时是长点击的概率。</p>

<p>从这个角度说，之前的sigmoid映射函数中\(\frac{1}{1+ e^{-a(x-b)}}\) 系数项即是log odds ratio。</p>

<p>因此只需对送评数据中\(ln\frac{p}{1-p}\)的分布数据去拟合一条曲线 \(\hat f(t)\)即可，最终的sigmoid映射函数就是</p>

<p>\[g(t) = \frac{1}{1+ e^{\hat f(t)}}\]</p>

<p>并且其中\(\hat f(t)=0\)的点恰巧就是长点击的分界点。</p>

<p>注意：实际送评的时候因为样本量的限制，不可能每一个分界点(在这里是每个停留时间dt)都会去送评，</p>

<h3 id="toc_3">4.其他:从模型准召的角度</h3>

<p>其实从分类评估角度来看，</p>

<table>
<thead>
<tr>
<th></th>
<th>not_good</th>
<th>Good</th>
</tr>
</thead>

<tbody>
<tr>
<td>F=0</td>
<td>a</td>
<td>b</td>
</tr>
<tr>
<td>F=1</td>
<td>c</td>
<td>d</td>
</tr>
</tbody>
</table>

<p>上面说的损失即阴影部分的面积=b+c, 所以其实从分类模型评估的角度，就是不一致率最小的时候的最优解,即<br/>
\[min b+c\]</p>

<ul>
<li>准确&amp;召回</li>
</ul>

<p>分类模型中其实用的更多的是准确和召回指标，\(accurate=\frac{d}{c+d}\),\(recall = \frac{d}{b+d}\)<br/>
\[Max F\_score = 1-\frac{b+c}{b+c+2d}\]</p>

<p>这个标准下，和之前还是略微有些不同的</p>

<h3 id="toc_4">5.如何泛化</h3>

<p>泛化问题主要是指：</p>

<ul>
<li>业务层面</li>
</ul>

<p>搜索，视频，以后其他的大小业务都可能面临这种问题。对于新的业务类型，人工送评应该是避免不了了。</p>

<ul>
<li>时间层面变更</li>
</ul>

<p>随着线上效果变更，当前调研的结果可能已经不再试用后续的结果。需要不断进行更新，比如视频铺量后，整体的时长分布和之前的可能变化很大。或者是需要拆解不同的维度类别</p>

<p>方案1：再次人工送评一遍，<br/>
方案2：进行时长分布映射<br/>
这种方案有个问题，相当于是按照top百分比进行划分的，认为top百分比所代表的满意度保持一致。可能整体时长都变长了，映射完后阈值也变长了，相对的满意度并没变。</p>


</div>

<br /><br />
<hr />

<div class="row clearfix">
  <div class="large-6 columns">
	<div class="text-left" style="padding:15px 0px;">
		
	        <a href="15637025347227.html"  title="Previous Post: 公开微观数据库 1.0">&laquo; 公开微观数据库 1.0</a>
	    
	</div>
  </div>
  <div class="large-6 columns">
	<div class="text-right" style="padding:15px 0px;">
		
	        <a href="15637025346262.html" 
	        title="Next Post: 卡方检验">卡方检验 &raquo;</a>
	    
	</div>
  </div>
</div>

<div class="row">
<div style="padding:0px 0.93em;" class="share-comments">

</div>
</div>
<script type="text/javascript">
	$(function(){
		var currentURL = '15637037730522.html';
		$('#side-nav a').each(function(){
			if($(this).attr('href') == currentURL){
				$(this).parent().addClass('active');
			}
		});
	});
</script>  
</div></div>


<div class="page-bottom">
  <div class="row">
  <hr />
  <div class="small-9 columns">
  <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
  <div class="small-3 columns">
  <p class="copyright text-right"><a href="#header">TOP</a></p>
  </div>
   
  </div>
</div>

        </section>
      </div>
    </div>
    
    
    <script src="asset/js/foundation.min.js"></script>
    <script src="asset/js/foundation/foundation.offcanvas.js"></script>
    <script>
      $(document).foundation();

     
    </script>
    
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>

  </body>
</html>
