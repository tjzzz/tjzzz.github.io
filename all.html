<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  zhenzhen学习笔记
  
  </title>
 <meta name="description" content="">
 <link href="atom.xml" rel="alternate" title="zhenzhen学习笔记" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />

    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
    <script src="asset/highlightjs/highlight.pack.js"></script>
    <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
    <script>hljs.initHighlightingOnLoad();</script>
    
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>

<div id="header">
    <h1><a href="index.html">zhenzhen学习笔记</a></h1>
</div>

</nav>
        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; zhenzhen学习笔记</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
      <li><a href="index.html">Home</a></li>
      
        <li class="divider"></li>
        <li><label>1 Tools</label></li>

          
            <li><a title="1 安装-mac" href="15637025344954.html">1 安装-mac</a></li>
          
            <li><a title="git" href="15637037678160.html">git</a></li>
          
            <li><a title="jupyterLab" href="15637037680349.html">jupyterLab</a></li>
          
            <li><a title="markdown" href="15637037679256.html">markdown</a></li>
          
            <li><a title="sublime" href="15637037680741.html">sublime</a></li>
          
            <li><a title="工欲善其事必先利其器——Jupyter notebook" href="15637037683461.html">工欲善其事必先利其器——Jupyter notebook</a></li>
          
            <li><a title="工欲善其事必先利其器——conda" href="15637025346412.html">工欲善其事必先利其器——conda</a></li>
          

      
        <li class="divider"></li>
        <li><label>2 Get Data</label></li>

          
            <li><a title="公开微观数据库 1.0" href="15637025347227.html">公开微观数据库 1.0</a></li>
          

      
        <li class="divider"></li>
        <li><label>3 数据可视化</label></li>

          
            <li><a title="Data product" href="15637037683065.html">Data product</a></li>
          
            <li><a title="rCharts" href="15637037678380.html">rCharts</a></li>
          
            <li><a title="数据可视化(seaborn)" href="15637037713554.html">数据可视化(seaborn)</a></li>
          

      
        <li class="divider"></li>
        <li><label>4 统计方法</label></li>

          
            <li><a title="1 估计的置信度" href="15637036455584.html">1 估计的置信度</a></li>
          
            <li><a title="2 不同设计之间有统计学差异吗" href="15637025346225.html">2 不同设计之间有统计学差异吗</a></li>
          
            <li><a title="3 样本量的确定" href="15637036605080.html">3 样本量的确定</a></li>
          
            <li><a title="关于长点击阈值划分方法" href="15637037730522.html">关于长点击阈值划分方法</a></li>
          
            <li><a title="卡方检验" href="15637025346262.html">卡方检验</a></li>
          
            <li><a title="统计阈值" href="15637037730576.html">统计阈值</a></li>
          

      
        <li class="divider"></li>
        <li><label>5 机器学习</label></li>

          
            <li><a title="3.1 特征处理—— 特征选择" href="15637037691936.html">3.1 特征处理—— 特征选择</a></li>
          
            <li><a title="3.2 特征处理——降维" href="15637037731313.html">3.2 特征处理——降维</a></li>
          
            <li><a title="4.1 回归模型" href="15637037691075.html">4.1 回归模型</a></li>
          
            <li><a title="4.2 回归与分类" href="15637037677393.html">4.2 回归与分类</a></li>
          
            <li><a title="4.3 支持向量机" href="15637037728199.html">4.3 支持向量机</a></li>
          
            <li><a title="4.4 k近邻 —— 非参模型" href="15637037731266.html">4.4 k近邻 —— 非参模型</a></li>
          
            <li><a title="4.5 树模型" href="15637037678245.html">4.5 树模型</a></li>
          
            <li><a title="4.6 集成" href="15637037692016.html">4.6 集成</a></li>
          
            <li><a title="4.7 聚类1" href="15636947700701.html">4.7 聚类1</a></li>
          
            <li><a title="4.7 聚类2——-效果评价" href="15637037683688.html">4.7 聚类2——-效果评价</a></li>
          
            <li><a title="4.8 自适应的基函数——神经网络" href="15637025348085.html">4.8 自适应的基函数——神经网络</a></li>
          
            <li><a title="4.9 深度学习综述" href="15637037686386.html">4.9 深度学习综述</a></li>
          
            <li><a title="FM" href="15637037720747.html">FM</a></li>
          
            <li><a title="FM 模型" href="15637037680228.html">FM 模型</a></li>
          
            <li><a title="query文本聚类" href="15637025345613.html">query文本聚类</a></li>
          
            <li><a title="t-sne" href="15637037679781.html">t-sne</a></li>
          
            <li><a title="xgboost" href="15637025344879.html">xgboost</a></li>
          
            <li><a title="【聚类】-效果评价" href="15637037699016.html">【聚类】-效果评价</a></li>
          
            <li><a title="一、基础篇" href="15637037677178.html">一、基础篇</a></li>
          
            <li><a title="二、起步篇—— 数据预处理[python]" href="15637025346988.html">二、起步篇—— 数据预处理[python]</a></li>
          
            <li><a title="二、起步篇——数据预处理[方法论]" href="15636947700356.html">二、起步篇——数据预处理[方法论]</a></li>
          
            <li><a title="二、起步篇——数据预处理[方法论]" href="15637025346040.html">二、起步篇——数据预处理[方法论]</a></li>
          
            <li><a title="聚类Tools篇" href="15637025345910.html">聚类Tools篇</a></li>
          
            <li><a title="聚类Tools篇" href="15637037682671.html">聚类Tools篇</a></li>
          
            <li><a title="聚类方法-spark的bisecting和streaming" href="15637037731727.html">聚类方法-spark的bisecting和streaming</a></li>
          
            <li><a title="聚类方法Mini Batch KMeans" href="15637025344831.html">聚类方法Mini Batch KMeans</a></li>
          
            <li><a title="视频广告" href="15637025347693.html">视频广告</a></li>
          

      
        <li class="divider"></li>
        <li><label>6 推荐系统</label></li>

          
            <li><a title="章1 基本介绍" href="15637025348511.html">章1 基本介绍</a></li>
          
            <li><a title="章2 利用用户行为数据" href="15637025347286.html">章2 利用用户行为数据</a></li>
          

      
        <li class="divider"></li>
        <li><label>6 文本&视频</label></li>

          
            <li><a title="Face综述" href="15637037688620.html">Face综述</a></li>
          
            <li><a title="face_recgnization" href="15637037690385.html">face_recgnization</a></li>
          
            <li><a title="图像识别模型—— 1.利用已有的进行微调" href="15637037708871.html">图像识别模型—— 1.利用已有的进行微调</a></li>
          

      
        <li class="divider"></li>
        <li><label>7 深度学习</label></li>

          
            <li><a title="3.【解释性】LIME" href="15637037677008.html">3.【解释性】LIME</a></li>
          
            <li><a title="TensorFlow" href="15637037730028.html">TensorFlow</a></li>
          
            <li><a title="[2018-06-25]学习1" href="15637037693934.html">[2018-06-25]学习1</a></li>
          
            <li><a title="【NG-DL】course2_week1 优化网络参数" href="15637025344767.html">【NG-DL】course2_week1 优化网络参数</a></li>
          
            <li><a title="【Tensorflow】week2 Introduction to Computer Vision" href="15637025345757.html">【Tensorflow】week2 Introduction to Computer Vision</a></li>
          
            <li><a title="神经网络解释性问题" href="15637037679634.html">神经网络解释性问题</a></li>
          
            <li><a title="第一章 引言" href="15637025345079.html">第一章 引言</a></li>
          
            <li><a title="第七章 正则化" href="15637025346077.html">第七章 正则化</a></li>
          
            <li><a title="第三章 概率与信息论" href="15637025345792.html">第三章 概率与信息论</a></li>
          
            <li><a title="第二章 线性代数" href="15637025345723.html">第二章 线性代数</a></li>
          
            <li><a title="第五章 机器学习" href="15637025346737.html">第五章 机器学习</a></li>
          
            <li><a title="第八章 深度模型中的优化" href="15637037731128.html">第八章 深度模型中的优化</a></li>
          
            <li><a title="第六章 深度前馈网络" href="15637025345687.html">第六章 深度前馈网络</a></li>
          
            <li><a title="第四章 数值计算" href="15637037679680.html">第四章 数值计算</a></li>
          

      
        <li class="divider"></li>
        <li><label>10 比赛学习</label></li>

          
            <li><a title="比赛学习" href="15637037730631.html">比赛学习</a></li>
          

      
        <li class="divider"></li>
        <li><label>数据科学-清单</label></li>

          
            <li><a title="推荐资源" href="15637037694950.html">推荐资源</a></li>
          
            <li><a title="目录" href="15637025347820.html">目录</a></li>
          
            <li><a title="资源List" href="15637025346338.html">资源List</a></li>
          

      
      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>

        <section id="main-content" role="main" class="scroll-container">

          <div class="row">
            <div class="large-3 medium-3 columns">
              <div class="hide-for-small">
                <div class="sidebar">
                <nav>
                  <ul id="side-nav" class="side-nav">

                    
                      <li class="side-title"><span>1 Tools</span></li>
                        
                          <li><a title="1 安装-mac" href="15637025344954.html">1 安装-mac</a></li>
                        
                          <li><a title="git" href="15637037678160.html">git</a></li>
                        
                          <li><a title="jupyterLab" href="15637037680349.html">jupyterLab</a></li>
                        
                          <li><a title="markdown" href="15637037679256.html">markdown</a></li>
                        
                          <li><a title="sublime" href="15637037680741.html">sublime</a></li>
                        
                          <li><a title="工欲善其事必先利其器——Jupyter notebook" href="15637037683461.html">工欲善其事必先利其器——Jupyter notebook</a></li>
                        
                          <li><a title="工欲善其事必先利其器——conda" href="15637025346412.html">工欲善其事必先利其器——conda</a></li>
                        

                    
                      <li class="side-title"><span>2 Get Data</span></li>
                        
                          <li><a title="公开微观数据库 1.0" href="15637025347227.html">公开微观数据库 1.0</a></li>
                        

                    
                      <li class="side-title"><span>3 数据可视化</span></li>
                        
                          <li><a title="Data product" href="15637037683065.html">Data product</a></li>
                        
                          <li><a title="rCharts" href="15637037678380.html">rCharts</a></li>
                        
                          <li><a title="数据可视化(seaborn)" href="15637037713554.html">数据可视化(seaborn)</a></li>
                        

                    
                      <li class="side-title"><span>4 统计方法</span></li>
                        
                          <li><a title="1 估计的置信度" href="15637036455584.html">1 估计的置信度</a></li>
                        
                          <li><a title="2 不同设计之间有统计学差异吗" href="15637025346225.html">2 不同设计之间有统计学差异吗</a></li>
                        
                          <li><a title="3 样本量的确定" href="15637036605080.html">3 样本量的确定</a></li>
                        
                          <li><a title="关于长点击阈值划分方法" href="15637037730522.html">关于长点击阈值划分方法</a></li>
                        
                          <li><a title="卡方检验" href="15637025346262.html">卡方检验</a></li>
                        
                          <li><a title="统计阈值" href="15637037730576.html">统计阈值</a></li>
                        

                    
                      <li class="side-title"><span>5 机器学习</span></li>
                        
                          <li><a title="3.1 特征处理—— 特征选择" href="15637037691936.html">3.1 特征处理—— 特征选择</a></li>
                        
                          <li><a title="3.2 特征处理——降维" href="15637037731313.html">3.2 特征处理——降维</a></li>
                        
                          <li><a title="4.1 回归模型" href="15637037691075.html">4.1 回归模型</a></li>
                        
                          <li><a title="4.2 回归与分类" href="15637037677393.html">4.2 回归与分类</a></li>
                        
                          <li><a title="4.3 支持向量机" href="15637037728199.html">4.3 支持向量机</a></li>
                        
                          <li><a title="4.4 k近邻 —— 非参模型" href="15637037731266.html">4.4 k近邻 —— 非参模型</a></li>
                        
                          <li><a title="4.5 树模型" href="15637037678245.html">4.5 树模型</a></li>
                        
                          <li><a title="4.6 集成" href="15637037692016.html">4.6 集成</a></li>
                        
                          <li><a title="4.7 聚类1" href="15636947700701.html">4.7 聚类1</a></li>
                        
                          <li><a title="4.7 聚类2——-效果评价" href="15637037683688.html">4.7 聚类2——-效果评价</a></li>
                        
                          <li><a title="4.8 自适应的基函数——神经网络" href="15637025348085.html">4.8 自适应的基函数——神经网络</a></li>
                        
                          <li><a title="4.9 深度学习综述" href="15637037686386.html">4.9 深度学习综述</a></li>
                        
                          <li><a title="FM" href="15637037720747.html">FM</a></li>
                        
                          <li><a title="FM 模型" href="15637037680228.html">FM 模型</a></li>
                        
                          <li><a title="query文本聚类" href="15637025345613.html">query文本聚类</a></li>
                        
                          <li><a title="t-sne" href="15637037679781.html">t-sne</a></li>
                        
                          <li><a title="xgboost" href="15637025344879.html">xgboost</a></li>
                        
                          <li><a title="【聚类】-效果评价" href="15637037699016.html">【聚类】-效果评价</a></li>
                        
                          <li><a title="一、基础篇" href="15637037677178.html">一、基础篇</a></li>
                        
                          <li><a title="二、起步篇—— 数据预处理[python]" href="15637025346988.html">二、起步篇—— 数据预处理[python]</a></li>
                        
                          <li><a title="二、起步篇——数据预处理[方法论]" href="15636947700356.html">二、起步篇——数据预处理[方法论]</a></li>
                        
                          <li><a title="二、起步篇——数据预处理[方法论]" href="15637025346040.html">二、起步篇——数据预处理[方法论]</a></li>
                        
                          <li><a title="聚类Tools篇" href="15637025345910.html">聚类Tools篇</a></li>
                        
                          <li><a title="聚类Tools篇" href="15637037682671.html">聚类Tools篇</a></li>
                        
                          <li><a title="聚类方法-spark的bisecting和streaming" href="15637037731727.html">聚类方法-spark的bisecting和streaming</a></li>
                        
                          <li><a title="聚类方法Mini Batch KMeans" href="15637025344831.html">聚类方法Mini Batch KMeans</a></li>
                        
                          <li><a title="视频广告" href="15637025347693.html">视频广告</a></li>
                        

                    
                      <li class="side-title"><span>6 推荐系统</span></li>
                        
                          <li><a title="章1 基本介绍" href="15637025348511.html">章1 基本介绍</a></li>
                        
                          <li><a title="章2 利用用户行为数据" href="15637025347286.html">章2 利用用户行为数据</a></li>
                        

                    
                      <li class="side-title"><span>6 文本&视频</span></li>
                        
                          <li><a title="Face综述" href="15637037688620.html">Face综述</a></li>
                        
                          <li><a title="face_recgnization" href="15637037690385.html">face_recgnization</a></li>
                        
                          <li><a title="图像识别模型—— 1.利用已有的进行微调" href="15637037708871.html">图像识别模型—— 1.利用已有的进行微调</a></li>
                        

                    
                      <li class="side-title"><span>7 深度学习</span></li>
                        
                          <li><a title="3.【解释性】LIME" href="15637037677008.html">3.【解释性】LIME</a></li>
                        
                          <li><a title="TensorFlow" href="15637037730028.html">TensorFlow</a></li>
                        
                          <li><a title="[2018-06-25]学习1" href="15637037693934.html">[2018-06-25]学习1</a></li>
                        
                          <li><a title="【NG-DL】course2_week1 优化网络参数" href="15637025344767.html">【NG-DL】course2_week1 优化网络参数</a></li>
                        
                          <li><a title="【Tensorflow】week2 Introduction to Computer Vision" href="15637025345757.html">【Tensorflow】week2 Introduction to Computer Vision</a></li>
                        
                          <li><a title="神经网络解释性问题" href="15637037679634.html">神经网络解释性问题</a></li>
                        
                          <li><a title="第一章 引言" href="15637025345079.html">第一章 引言</a></li>
                        
                          <li><a title="第七章 正则化" href="15637025346077.html">第七章 正则化</a></li>
                        
                          <li><a title="第三章 概率与信息论" href="15637025345792.html">第三章 概率与信息论</a></li>
                        
                          <li><a title="第二章 线性代数" href="15637025345723.html">第二章 线性代数</a></li>
                        
                          <li><a title="第五章 机器学习" href="15637025346737.html">第五章 机器学习</a></li>
                        
                          <li><a title="第八章 深度模型中的优化" href="15637037731128.html">第八章 深度模型中的优化</a></li>
                        
                          <li><a title="第六章 深度前馈网络" href="15637025345687.html">第六章 深度前馈网络</a></li>
                        
                          <li><a title="第四章 数值计算" href="15637037679680.html">第四章 数值计算</a></li>
                        

                    
                      <li class="side-title"><span>10 比赛学习</span></li>
                        
                          <li><a title="比赛学习" href="15637037730631.html">比赛学习</a></li>
                        

                    
                      <li class="side-title"><span>数据科学-清单</span></li>
                        
                          <li><a title="推荐资源" href="15637037694950.html">推荐资源</a></li>
                        
                          <li><a title="目录" href="15637025347820.html">目录</a></li>
                        
                          <li><a title="资源List" href="15637025346338.html">资源List</a></li>
                        

                    
                  </ul>
                </nav>
                </div>
              </div>
            </div>
            <div class="large-9 medium-9 columns">

 


	
		<div class="markdown-body">
		<h1>1 估计的置信度</h1>

		<p>在大多数的研究中，我们无法获取研究对象的总体数据，或者能获取但是成本非常大。实际情况中，我们往往是通过抽样的方法，在总体中进行随机抽样。根据获取的这部分样本数据去推动总体的一些属性。比如通过抽样人群的平均身高去估计所有人群的平均身高，通过抽样人群中的男女比例，去估计我国当前的男女比例状况。<br/>
抽样样本量是直接影响到最终的估计准确度，所以这一章节，先来介绍下如何判断一种估计方法准确与否。</p>

<span id="more"></span><!-- more -->

<p><strong>统计估计</strong></p>

<p>统计中估计的方法有两类：点估计，区间估计。 比如问男性平均身高是多少，167cm就是一个点估计，160-170就是区间估计。</p>

<p><strong>置信区间</strong></p>

<p>根据前面介绍的常用的三种估计类型，其置信区间的计算方式也有所不同。</p>

<h3 id="toc_0">1. 比例的置信区间</h3>

<p>例：假设抛掷一枚不均匀的硬币，其正面朝上的真实概率P位置，每次实验结果只有X=1表示正面，X=0表示反面两种结果。现在实验了n次，其中正面向上个数是k次，想估计下这个硬币正面朝上的概率是多少。</p>

<p>如果用点估计，自然的会用频率\(\hat p=\frac{k}{n}\)去估计真实的频率。而区间估计的主要步骤如下：</p>

<p>\[E(\hat p)=p, V(\hat p)=p(1-p)/n\]<br/>
所以有\[\hat p - N(p, p(1-p)/n)\]<br/>
\[\frac{\hat p -p}{\sqrt\frac{p(1-p)}{n}} - N(0,1)\]</p>

<p><strong>经典的Wald区间</strong></p>

<p>Wald估计是用样本比例替代整体比例，比例估计的置信区间是 \(\hat p \pm z_{1-\alpha/2} \sqrt\frac{\hat p(1-\hat p)}{n} \)</p>

<p>以上的置信区间是有个前提的：样本量比较大的时候，np&gt;5且n(1-p)&gt;5，二项分布才会近似是正态分布。</p>

<p>在样本量比较小，或者是真实的p值接近0或者1的时候，估计的就不是很准确了。</p>

<p><strong>小样本的比例估计</strong></p>

<p>在实际的问题中，这种情况也是经常存在的。以搜索为例，一个具体的搜索策略上线前，通常都会对实验组和对照组进行一些人工评估。因为人力成本问题，一般是评估100或200qu。可能里面的good或者bad的case占比非常少，那么在估计good或badcase的比例的时候置信度就不是很高。</p>

<p>下面介绍几种常用的修正的区间估计</p>

<p>(0) 精确区间<br/>
所谓精确区间，其实就是不对齐分布进行近似，而是直接使用原始的真实分布。我们知道正面朝上的个数k其真实分布是二项分布。这个一开始是Clopper和Pearson在1934年研究出来的，所以也叫做C-P 置信区间</p>

<p>\[P(x=s) =C_n^s p^s(1-p)^{n-s}\]<br/>
<img src="https://upload-images.jianshu.io/upload_images/127231-339c6e5a9a1ad861.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"/></p>

<p>最终可以反解出来这个置信下限和置信上限，这里就不在列出具体公式了。</p>

<p>(1)Wilson区间/Wald矫正区间</p>

<p>注意Wilson和wald两种方法上的区别，wald在设置置信区间的时候是简化了问题，用样本比例近似了真实的比例。wilson认为\(\frac{\hat p -p}{\sqrt\frac{p(1-p)}{n}} - N(0,1)\)</p>

<p>简单的推理过程如下<br/>
<img src="https://upload-images.jianshu.io/upload_images/127231-d8b9a92bf8252c39.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"/></p>

<p>最终推导出来的置信区间是<br/>
<img src="https://upload-images.jianshu.io/upload_images/127231-f921c3e3535fdb79.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"/></p>

<p>（2）wald矫正区间</p>

<p>上述的置信区间有一个简单的计算方式-加2法，即在数据中增加2个成功案例和2个失败案例,然后再用传统的wald区间估计方法</p>

<p>这是因为<br/>
<img src="https://upload-images.jianshu.io/upload_images/127231-1f8783243845ea27.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"/></p>

<h3 id="toc_1">2.等级量表和连续性数据的置信区间</h3>

<p>我们做置信区间或者参数估计，最终目的是希望通过样本的数据去获得总体的信息。常见的就是对总体集中趋势的估计，而这种”集中趋势“根据数据本身的分布情况，可能会采取均值、中位数、众数做为其估计</p>

<p>（1）基于均值的</p>

<p>基于均值的估计，一般是在假设其分布比较对称的时候，均值是很好的对”集中趋势“的度量。根据样本量的大小，均值的置信区间可以用t分布或者z分布。</p>

<p>（2）基于中位数的</p>

<p>很多时候，数据本身的分布是不对称的，比如用户的网页结果的停留时长、用户点击的位置分布等。这个时候均值就不是一个很好的对总体集中趋势的估计了。实际中用的较多的是中位数。</p>

<p>但是中位数本身也存在一些问题。</p>

<ul>
<li>变异性。中位数可以抵挡异常值对整体分布的影响，但是当从一个连续分布中抽样样本时候，中位数要比均值的变异性更大。均值可能相对比较稳定的，但是中位数可能跳动会很大。</li>
<li>偏倚性。平均值的一个好的性质就是估计的无偏性，</li>
</ul>

<p>(3) 基于几何均值的</p>

<p>可以参考<a href="http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=4E0303CA43F91C5E4E68160A9DFB6152?doi=10.1.1.365.603&amp;rep=rep1&amp;type=pdf">Sauro and Lewis</a>2010年的一篇论文。</p>

<p>这里简单说下论文的主要结论吧：</p>

<ul>
<li>样本中位数是总体中位数的有偏估计</li>
<li><p>作者主要比较了，均值，中位数，几何均值，调和平均值，截断均值(去掉最高和最低的topN)。 通过蒙特卡洛模拟的方法，对于n&gt;25时候，样本中位数是个比较好的估计，对于n&lt;25的时候，几何均值是一个比较好的估计</p></li>
<li><p>中位数的置信区间</p></li>
</ul>

<p>特定类型的数据(比如任务时长，用户在搜索结果的停留时间)，要找到中位数的置信区间，中位数即p=0.5的那个分界点。其实相当于要找到p的置信区间。<br/>
\[\hat p \pm z_{1-\alpha/2} \sqrt\frac{\hat p(1-\hat p)}{n} \]</p>

<p>得到置信区间[p1, p2]之后，去找到数据中位于[p1,p2]分界点的数据点即为中位数的置信区间了。</p>

<h2 id="toc_2">参考资料</h2>

<p>维基百科 <a href="https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval#Wilson_score_interval">https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval#Wilson_score_interval</a></p>

<p><a href="https://indico.ihep.ac.cn/event/6182/contribution/4/material/slides/0.pdf">https://indico.ihep.ac.cn/event/6182/contribution/4/material/slides/0.pdf</a></p>


		</div>
	

 
	

 
	

 
	

 
	

  
  
</div></div>


<div class="page-bottom">
  <div class="row">
  <hr />
  <div class="small-9 columns">
  <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
  <div class="small-3 columns">
  <p class="copyright text-right"><a href="#header">TOP</a></p>
  </div>
   
  </div>
</div>

        </section>
      </div>
    </div>
    
    
    <script src="asset/js/foundation.min.js"></script>
    <script src="asset/js/foundation/foundation.offcanvas.js"></script>
    <script>
      $(document).foundation();

     
    </script>
    
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>

  </body>
</html>
