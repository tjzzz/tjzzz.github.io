
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>
    
  镇镇的笔记
  

  </title>
  <meta name="author" content="">
  <meta name="description" content="">

  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link href="asset/css/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="atom.xml" rel="alternate" title="镇镇的笔记" type="application/atom+xml">
  <script src="asset/js/modernizr-2.0.js"></script>
  <script src="asset/js/jquery.min.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/solarized_light.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>

  <style type="text/css">
  .cat-children-p{ padding: 6px 0px;}
  .hljs{background: none;}
  </style>
  <script type="text/javascript">
  var isAddSildbar = true;
  </script>
  <script src="asset/js/octopress.js" type="text/javascript"></script>
</head>
<script type="text/javascript">
//链接新开窗口
function addBlankTargetForLinks () {
  $('a[href^="http"]').each(function(){
      $(this).attr('target', '_blank');
  });
}
$(document).ready(function(event) {
  addBlankTargetForLinks();
});
</script>
<body   >
  <header role="banner"><hgroup>
  <h1><a href="index.html">镇镇的笔记</a></h1>
  
    <h2></h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">

  <li id=""><a target="self" href="index.html">Home</a></li>

  <li id=""><a target="_self" href="archives.html">Archives</a></li>

</ul>

</nav>
  <div id="main">
    <div id="content"> 
<div class="blog-index">

	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15080580137304.html">第四章 数值计算</a></h1>
			<p class="meta"><time datetime="2017-10-15T17:00:13+08:00" 
			pubdate data-updated="true">2017/10/15</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<h2 id="toc_0">1.数值精度</h2>

<p>这部分对于了解具体的算法并没影响，但是在进行底层库开发时候经常会遇到，可能会出现<strong>上溢</strong>或者<strong>下溢</strong></p>

<p>（1）病态条件</p>

<p>条件数：表示函数相对于输入的微小变化而变化的快慢程度。<br/>
比如矩阵求逆运算的条件数=最大和最小特征值的模的比</p>

<h2 id="toc_1">2.优化算法</h2>

<ul>
<li>梯度下降</li>
<li>牛顿法</li>
</ul>

<p>一般把需要最优化的函数称为<strong>目标函数</strong></p>

<p><strong>梯度下降</strong></p>

<p>对于一个多维输入函数f，梯度\(\triangledown_x f(x)\),其在u方向上的<strong>方向导数</strong>，相当于f在u方向上的斜率<br/>
\(f(x+\alpha u)\)关于\(\alpha\)的导数(在\(\alpha =0\)时取得)</p>

<p>\[\frac{\partial}{\partial \alpha}f(x+\alpha u)=u^T\triangledown_x f(x)\]</p>

<p>为了是f最小，希望找到f下降最快的方向，因此有<br/>
\[min u^T\triangledown_x f(x)\]<br/>
u取为单位向量，很明显是在u和f夹角180时候，也就是两个完全相反的时候，下降最快。<br/>
梯度下降： \(x&#39;=x-\epsilon \triangledown_x f(x)\)</p>

<p><strong>牛顿法</strong></p>

<p>Hessian矩阵，二阶导数<br/>
<img src="media/15080580137304/15082408605128.jpg" alt=""/></p>

<h2 id="toc_2">3.有限制的约束</h2>

<p>对于有限制的优化，有时候可以将约束条件转化到原始的优化函数中，这里主要介绍一下通用的方法：<strong>KKT方法</strong>(拉格朗日方法的推广，可以非等式约束)</p>

<pre><code>@@@
http://blog.csdn.net/mr_kktian/article/details/53750424
</code></pre>

<h2 id="toc_3">参考资料</h2>

<p>梯度下降法 扩展阅读： <a href="https://www.jiqizhixin.com/articles/2016-11-21-4">https://www.jiqizhixin.com/articles/2016-11-21-4</a><br/>
<a href="http://www.cnblogs.com/maybe2030/p/4751804.html">http://www.cnblogs.com/maybe2030/p/4751804.html</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15080561019055.html">第三章 概率与信息论</a></h1>
			<p class="meta"><time datetime="2017-10-15T16:28:21+08:00" 
			pubdate data-updated="true">2017/10/15</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>本章主要是介绍了一些概率论的基础以及常见的分布</p>

<h2 id="toc_0">1.常用函数的有用性质</h2>

<ul>
<li>sigmoid 函数</li>
</ul>

<p>\[\delta(x) = \frac{1}{1+exp(-x)}\]</p>

<ul>
<li>softplus函数
\[log(1+exp(x))\]
<img src="media/15080561019055/15080571562017.jpg" alt=""/></li>
</ul>

<p>是\(y=max(0,x)\)的平滑版本</p>

<h2 id="toc_1">2.信息论</h2>

<p>信息论是应用数学的一个分支，主要研究的是对一个信号包含信息的多少进行量化。<br/>
<img src="media/15080561019055/15080594230903.jpg" alt=""/></p>

<p>自信息：定义一个时间X=x的自信息<br/>
\[I(x) = -log P(x)\]</p>

<p>熵：<br/>
\[-\sum P(x_i) logP(x_i)\]</p>

<h3 id="toc_2">KL散度/相对熵</h3>

<p>\[KL(P||Q) = -\sum P_i ln(\frac{P_i}{Q_i})=-\sum P_i(ln(P_i)- ln(Q_i))\]</p>

<p>注意：</p>

<ul>
<li>KL距离其实并不是严格的距离，不满足对称性以及三角不等式。</li>
</ul>

<p>JS距离：<br/>
\[JS(P1||P2) = \frac{1}{2}KL(P1||(P1+P2)/2)+ \frac{1}{2}KL(P2||(P1+P2)/2)\]</p>

<h3 id="toc_3">交叉熵</h3>

<p>相对熵的第一部分<br/>
\[KL(P||Q) = -\sum P_i ln(Q_i)\]</p>

<h2 id="toc_4">3.结构化概率模型——图模型(graphical model)</h2>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15080506207071.html">第二章 线性代数</a></h1>
			<p class="meta"><time datetime="2017-10-15T14:57:00+08:00" 
			pubdate data-updated="true">2017/10/15</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>第二章主要是介绍了线性代数的一些基础知识</p>

<p>这里补充几点吧</p>

<h2 id="toc_0">特征分解</h2>

<p>每个矩阵可以视为多个列向量组成的一个向量空间/或者是一个线性变化(一个矩阵乘以一个向量后相当于是对向量做了一个线性变换)。而矩阵的分解，相当于去提取这个向量空间最重要的特征。</p>

<p>(1)首先是特征值和特征向量<br/>
若<strong>方阵</strong>A满足 \(Av=\lambda v\),则\(v\)称为矩阵A的特征向量，\(\lambda\)称为对应的特征值。</p>

<p><strong>特征分解</strong><br/>
\[A=V \Lambda V^{-1}\]<br/>
V是其特征向量构成的矩阵，\(\Lambda\)是特征值构成的对角矩阵</p>

<p>性质：</p>

<p>(1) 实对称矩阵A都可以分解为\(A=Q\Lambda Q^{-1}\)，Q为正交矩阵</p>

<p>(2)用来计算矩阵的逆。若\(A=Q \Lambda Q^{-1}\)，则\(A^{-1}=Q \Lambda^{-1}Q^{-1}\)</p>

<h2 id="toc_1">奇异值分解</h2>

<p>特征分解对于提取矩阵的特征根是很好的方法，但是他只能针对<strong>方阵</strong>操作。当A不是方阵时候，就需要用到SVD<br/>
\[A_{n*m}=U_{n*n}\Sigma_{n*m} V^{T}_{m*m}\]</p>

<p>其中，U称为左奇异向量，V称为右奇异向量</p>

<p>\(AA^T=UDV^TVDU^T=UD^2U^T\)<br/>
\(A^TA=VDU^T UDV^T=VD^2V^T\)<br/>
即：<br/>
A的左奇异向量是\(AA^T\)的特征向量，A的右奇异向量是\(A^TA\)的特征向量，A的奇异值是\(AA^T\)也是\(A^TA\)的特征之爱的平方根。</p>

<blockquote>
<p>对比：<br/>
特征分解是有限制的，比如矩阵必须是方阵</p>
</blockquote>

<h3 id="toc_2">SVD与PCA的关系</h3>

<ul>
<li class="task-list-item"><input disabled="disabled" type="checkbox" /> 查一下之前多元的变换原理
</li>
</ul>

<p>PCA的全部工作简单点说，就是对原始的空间中顺序地找一组相互正交的坐标轴，第一个轴是使得方差最大的，第二个轴是在与第一个轴正交的平面中使得方差最大的，第三个轴是在与第1、2个轴正交的平面中方差最大的，这样假设在N维空间中，我们可以找到N个这样的坐标轴，我们取前r个去近似这个空间，这样就从一个N维的空间压缩到r维的空间了，但是我们选择的r个坐标轴能够使得空间的压缩使得数据的损失最小。</p>

<h3 id="toc_3">SVD与潜在语义检索LSI</h3>

<h2 id="toc_4">参考资料</h2>

<p><a href="http://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html">http://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15078603543147.html">【聚类】-效果评价</a></h1>
			<p class="meta"><time datetime="2017-10-13T10:05:54+08:00" 
			pubdate data-updated="true">2017/10/13</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>一般分为两类：</p>

<ul>
<li>外部标准：即基于人工的判断，需要有个标注集合</li>
<li>内部标准：基于类内和类间聚类的目标函数的判断</li>
</ul>

<h2 id="toc_0">内部标准clustering-performance-evaluation</h2>

<h2 id="toc_1">外部标准——人工判定</h2>

<p>假设：<br/>
机器判断的类别集合是：\(C=\{C_1,C_2,...C_m\}\)<br/>
人工判断的类别集合是：\(P=\{P_1,P_2,...P_s\}\)</p>

<h3 id="toc_2">1.1混淆矩阵</h3>

<p>基于数据样本点的角度：<br/>
对于任意两个数据pair，\((x_i,x_j)\)按照其在C和P中是否属于同一个簇，可以构造出混淆矩阵</p>

<table>
<thead>
<tr>
<th></th>
<th>P_1</th>
<th>p_0</th>
</tr>
</thead>

<tbody>
<tr>
<td>C_1</td>
<td>a</td>
<td>b</td>
</tr>
<tr>
<td>C_0</td>
<td>c</td>
<td>d</td>
</tr>
</tbody>
</table>

<p><img src="media/15078603543147/15078631739679.jpg" alt=""/></p>

<h3 id="toc_3">1.2簇的准确率/召回率</h3>

<p>基于簇pair的，考虑对任意一个人工与机器的.\(P_j,C_i\)。对于每一个人工标注的\(P_j\),在机器标注中应该都会对应一个&quot;最相关的&quot;。可以遍历C中所有的cluster，分别计算准确率，召回率，F_score。<br/>
<img src="media/15078603543147/15078720767171.jpg" alt=""/></p>

<p>然后对于所有簇的F值做加权平均<br/>
\[ClassF=\sum w_j F(p_j), w_i=n_j/n\]</p>

<p>classF指标，相当于是以人工标注的簇为基准，将聚类的簇尽量逼近这个标注的结果。</p>

<h2 id="toc_4">1.3</h2>

<p>1.2中的方法相当于要求的比较严格，即以人工标注的集合簇为准。</p>

<p>实际中其实只要保证我们聚的每一个类\(C_i\)是有意义的就可以，即以C为主</p>

<p>类似的定义 \(F(C_i)=\max_{1\lt j \lt s}F(P_j, C_i)\)<br/>
\[F=\sum w_i F(C_i), w_i=|C_i|/n\]</p>

<ul>
<li>问题： 这个指标可能变化不是非常明显</li>
</ul>

<h2 id="toc_5">1.4基于数据对象的准召F</h2>

<p><img src="media/15078603543147/15078731022919.jpg" alt=""/></p>

<h2 id="toc_6">思考</h2>

<ol>
<li>基于人工标注的方法中，认为人工标注的是准确的或者说结果是唯一的。实际上一堆sample可以有不同的分类方法，而且每种方法可能都是对的。
<code>
e.g 苹果维修， 冰箱维修，苹果价格，冰箱价格，中国人民大学
</code>
如何进行标注，或者标注结果是非固定时候怎么衡量聚类效果的好坏？？</li>
</ol>

<h2 id="toc_7">参考资料</h2>

<p><a href="http://blog.csdn.net/itplus/article/details/10322361">http://blog.csdn.net/itplus/article/details/10322361</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15075611675547.html">第一章 引言</a></h1>
			<p class="meta"><time datetime="2017-10-09T22:59:27+08:00" 
			pubdate data-updated="true">2017/10/9</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>别人的读后总结，可参考「Deep Learning」读书系列分享（一） | 分享总结</p>

<p><a href="https://www.leiphone.com/news/201708/LEBNjZzvm0Q3Ipp0.html">https://www.leiphone.com/news/201708/LEBNjZzvm0Q3Ipp0.html</a></p>

<h3 id="toc_0">需要明确的几个概念范围</h3>

<p><img src="media/15075611675547/15075613801366.jpg" alt=""/></p>

<p><img src="media/15075611675547/15075614908544.jpg" alt=""/></p>


		</div>

		

	</article>
  
	<div class="pagination">
	 <a class="prev" href="all_10.html">&larr; Older</a> 
<a href="archives.html">Blog Archives</a>
	 <a class="next" href="all_8.html">Newer &rarr;</a>  
	    
	</div>
</div>
 <aside class="sidebar"> 

	<section>
	  <h1>Categories</h1>
	  <ul id="recent_posts">
	  
	      <li class="post">
	        <a href="%E4%BD%A0%E4%B8%8D%E5%BE%97%E4%B8%8D%E7%9F%A5%E7%9A%84%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95.html"><strong>你不得不知的统计方法&nbsp;(3)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3%E7%BA%B3%E7%B1%B3%E5%AD%A6%E4%BD%8D.html"><strong>Udacity.DL&nbsp;(3)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="DL.html"><strong>Ng.DL&nbsp;(3)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="book.DL.html"><strong>book.DL&nbsp;(8)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html"><strong>机器学习&nbsp;(23)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F.html"><strong>推荐系统&nbsp;(3)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="NLP&%E5%9B%BE%E5%83%8F.html"><strong>NLP&图像&nbsp;(4)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96.html"><strong>数据可视化&nbsp;(7)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="0.%20%E8%B5%84%E6%BA%90%E5%AF%BC%E8%88%AA.html"><strong>0. 资源导航&nbsp;(3)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="data.html"><strong>data&nbsp;(1)</strong></a>
	        
	        
	        
	      </li>
	   
	  </ul>
	</section>
	<section>
	  <h1>Recent Posts</h1>
	  <ul id="recent_posts">
	  
	      
		      <li class="post">
		        <a href="15516671779096.html">list</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15479712192030.html">R 数据透视表</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15456330400571.html">统计阈值</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15394437873112.html">4.9 深度学习综述</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15394428762655.html">4.8 自适应的基函数——神经网络</a>
		      </li>
	     
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	   
	  </ul>
	</section>
	
</aside> </div></div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 -  -
  <span class="credit">Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a> &nbsp;&nbsp; Theme by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>

  
    


<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>

</body>
</html>