<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  zhenzhen数据科学笔记
  
  </title>
  
  
  <link href="atom.xml" rel="alternate" title="zhenzhen数据科学笔记" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />
    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript">
  function before_search(){
    var searchVal = 'site: ' + document.getElementById('search_input').value;
    document.getElementById('search_q').value = searchVal;
    return true;
  }
</script>
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>


  <section class="top-bar-section">
  <div class="row">
      <div style="position: relative;width:100%;"><div style="position: absolute; width:100%;">
        <ul id="main-menu" class="left">
        
        <li id=""><a target="_self" href="index.html">Home</a></li>
        
        <li id=""><a target="_self" href="archives.html">Archives</a></li>
        
        <li id=""><a target="_self" href="about_me.html">aboutme</a></li>
        
        </ul>

        <ul class="right" id="search-wrap">
          <li>
<form target="_blank" onsubmit="return before_search();" action="https://google.com/search" method="get">
    <input type="hidden" id="search_q" name="q" value="" />
    <input tabindex="1" type="search" id="search_input"  placeholder="Search"/>
</form>
</li>
          </ul>
      </div></div>
  </div>
  </section>

</nav>

        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; zhenzhen数据科学笔记</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
        
        <li><a target="_self" href="index.html">Home</a></li>
        
        <li><a target="_self" href="archives.html">Archives</a></li>
        
        <li><a target="_self" href="about_me.html">aboutme</a></li>
        

    <li><label>Categories</label></li>

        
            <li><a href="kdd&%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html">kdd&异常检测</a></li>
        
            <li><a href="%E8%BD%A8%E8%BF%B9%E5%88%86%E6%9E%90.html">轨迹分析</a></li>
        
            <li><a href="1%20Tools.html">1 Tools</a></li>
        
            <li><a href="2%20Get%20Data.html">2 Get Data</a></li>
        
            <li><a href="3%20%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96.html">3 数据可视化</a></li>
        
            <li><a href="4%20%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95.html">4 统计方法</a></li>
        
            <li><a href="5%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html">5 机器学习</a></li>
        
            <li><a href="6%20NLP.html">6 NLP</a></li>
        
            <li><a href="7%20CV.html">7 CV</a></li>
        
            <li><a href="8%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html">8 深度学习</a></li>
        
            <li><a href="9%20%E6%AF%94%E8%B5%9B%E5%AD%A6%E4%B9%A0.html">9 比赛学习</a></li>
        
            <li><a href="%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6-%E6%B8%85%E5%8D%95.html">数据科学-清单</a></li>
        
            <li><a href="%E5%85%B6%E4%BB%96.html">其他</a></li>
         

      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>


        <section id="main-content" role="main" class="scroll-container">
        
       

 <script type="text/javascript">
	$(function(){
		$('#menu_item_index').addClass('is_active');
	});
</script>
<div class="row">
	<div class="large-8 medium-8 columns">
		<div class="markdown-body home-categories">
		
			<div class="article">
                <a class="clearlink" href="15686368904229.html">
                
                  <h1>3. 轨迹聚类综述</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>轨迹聚类的方式总的来说有三大类：无监督的、有监督的、半监督的。轨迹聚类能够探知时空数据的潜在信息，并且能有很多的实际应用场景。比如：物体移动预测、交通监控、活动理解、异常检测、三维重建等。</p>

<p>一条轨迹数据的基本构成可以看做是<br/>
\[Trajectory = (Tr_1, Tr_2, ....Tr_n)\]<br/>
其中每个\(Tr_i=(x_i,y_i,t_i, 其他信息)\), 其他信息可能包括速度、方向、加速度等等。<br/>
为了进行聚类，必须要衡量轨迹之间的相似性，而不同轨迹数据面临采样不一致、长短不同等问题。所以在聚类开始之前会有很多的前期预处理工作。</p>

<h2 id="toc_0">3.1 相似性预处理</h2>

<p>对轨迹聚类前期的准备工作主要是对数据进行变换。主要有如下步骤:</p>

<p><strong>要求轨迹长度相同的-轨迹transformation</strong><br/>
对于要求轨迹长度相同的才能计算相似性的方法，比如欧式距离，就需要首先将两条轨迹进行变换，或者是投影到另一个子空间。</p>

<p>(1) transformation 方法</p>

<ul>
<li>linear transformation. 将轨迹表示成basic trajectory的线性组合</li>
<li>curve fitting，转到参数空间， e.g B-spline curve.</li>
<li>vector fields </li>
<li>PCA</li>
<li>DFT 离散傅里叶变换</li>
</ul>

<p>(2)重抽样方法<br/>
但是会有信息损失，需要加稀疏正则</p>

<p>(3)sub-trajectory.<br/>
需要提前对轨迹进行segmentation，比如根据changing point或者是速度、方向等。 这里有一些常用的轨迹切分方法：MDL最小描述长度，DP算法，MBR(minimum bounding rectangles)。 此外还有基于region进行切分的</p>

<p>(4) 根据poi点。 比如  <code>A survey of vision-based trajectory learning and analysis for surveillance</code>。包括进出门、逗留等。还可以对points设置不同的重要性<code>Dense scene reconstruction with points of interest</code></p>

<p>(5) Scale-invariant Features？？<br/>
一些刻画曲线的统计指标信息吧。 HOG(histograms of oriented gradients), HOF(histograms of optical flow)</p>

<p>（6） 其他<br/>
&#39;String-based feature representation for trajectory clustering&#39;中采样了网格化的方法，将轨迹映射到了网格上，将数字字符化。<br/>
首先利用DP算法将每条轨迹都搞成一样长度的</p>

<p><img src="media/15686368904229/15777734932601.jpg" alt=""/></p>

<p>基于字符的距离度量方式有：编辑距离、q-grame based距离、</p>

<h2 id="toc_1">3.2距离/相似性度量</h2>

<p>数据相同长度：</p>

<ul>
<li>欧式距离</li>
</ul>

<p>可以不同长度：</p>

<ul>
<li><p>hausdorff distance 每个点到另一条轨迹的最短距离的最大值<br/>
<img src="media/15686368904229/15772782653996.jpg" alt=""/></p></li>
<li><p>Bhattacharyya distance 是用来衡量两个概率分布是否相同的<br/>
\[D(p,q)=-ln(\sum \sqrt{p_iq_i})\]</p></li>
<li><p>Fréchet distance(弗雷歇距离） 狗绳距离</p></li>
<li><p>DTW</p></li>
<li><p>LCSS 最长公共子序列</p></li>
</ul>

<p>其他：</p>

<ul>
<li>SSPD
<img src="media/15686368904229/15776864958726.jpg" alt=""/></li>
</ul>

<p>T1上的点p到T2 的距离定义为：min(d(p,q)), q属于T2.而\(D_{SPD}(T_1, T2)= mean(D(p, T2))\)</p>

<p>从数据类型上来看主要包括：数值型和string型，数值型的主要是location的(x,y)坐标，string型的主要是根据(x,y)映射后的loc信息，比如poi点等</p>

<p>对距离的汇总比较<br/>
<img src="media/15686368904229/15776769741230.jpg" alt=""/></p>

<h2 id="toc_2">3.3 聚类-无监督</h2>

<table>
<thead>
<tr>
<th>方法</th>
<th>算法举例</th>
<th>参考</th>
</tr>
</thead>

<tbody>
<tr>
<td>partition based</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>

<p>(1) densely based <br/>
DBSCAN ,比如对于sub-trajectory<br/>
KMEANS ,FCM(fuzzy C-MEANS)</p>

<p>(2)层次聚类</p>

<ul>
<li>agglomerative clustering  自下而上，以及在此基础上出现的HITS</li>
<li>divisive clustering  自上而下，以及在此基础上出现的Test-and-Divide (TAD)</li>
</ul>

<p>(3) 谱聚类<br/>
计算效率快，但是只适合同长度的。是一种基于图论的方法。对于一个图G=G(V,E),其中V={v1,v2...vn}即是顶点的集合，E是边的集合，即E={w_ij}表示顶点i与顶点j之前的权重。</p>

<p>谱聚类的基本想法就是把所有的数据看做空间中的点，通过定义边之前的权重，然后进行切图，将距离较近的点切在一起，距离较远的点分开。所以说是一种基于图的聚类。</p>

<p>对于邻接矩阵W的构建，一般是根据相似矩阵𝑆来获得邻接矩阵𝑊。<img src="media/15686368904229/15776815135405.jpg" alt="" style="width:231px;"/></p>

<p>聚类步骤：</p>

<ul>
<li>计算图的Laplacian矩阵L=D-W  （D为度的对角矩阵，W为边的权重矩阵）</li>
<li>对Laplacian矩阵进行特征值分解，取其前个特征值对应的特征向量，构成的特征向量矩阵；</li>
<li>利用K-Means聚类算法对上述的的特征向量矩阵进行聚类，每一行代表一个样本点。</li>
</ul>

<p>（4）神经网络<br/>
基于SOM（自组织映射网络）</p>

<p>(5) Co-Occurrence Decomposition</p>

<p>Trajectories are viewed as a bags of words where similar bags contain similar words。该方法需要提前定义a set of vocabulary。<br/>
<a href="https://iksinc.online/tag/co-occurrence-matrix/">https://iksinc.online/tag/co-occurrence-matrix/</a></p>

<h2 id="toc_3">参考资料</h2>

<p>相关学者 Brendan Tran Morris <a href="https://ieeexplore.ieee.org/author/37391430100">https://ieeexplore.ieee.org/author/37391430100</a></p>

<ol>
<li>A survey on trajectory clustering analysis</li>
<li>Review &amp; Perspective for Distance Based Trajectory Clustering</li>
</ol>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2019/9/16</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='%E8%BD%A8%E8%BF%B9%E5%88%86%E6%9E%90.html'>轨迹分析</a></span>
          				   
                    

                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15637037691936.html">
                
                  <h1>3.1 特征处理—— 特征选择</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<h2 id="toc_0">参考</h2>

<p><a href="https://blog.csdn.net/kebu12345678/article/details/78437118">https://blog.csdn.net/kebu12345678/article/details/78437118</a></p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2019/7/21</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='5%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html'>5 机器学习</a></span>
          				   
                    

                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15637037731313.html">
                
                  <h1>3.2 特征处理——降维</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>关于降维的讨论主要是来源于“维度灾难”, 这个是数学家理查德-贝尔曼提出的。</p>

<blockquote>
<p>当所有参数是已知的时候，维度的增加可以让分类问题的错误率渐近为0.<br/>
当未知参数只能根据有限样本来估计时，维度的增加使错误率先降低后增加，最终收敛到0.5</p>
</blockquote>

<p>维数灾难的本质原因在于<code>数据样本的有限性</code>。而在数据有限的条件下，去解决维度问题，自然的方法就是去降维。降维的方法有很多</p>

<h2 id="toc_0">1. 常用的线性降维方法：</h2>

<ul>
<li>PCA 主成分分析</li>
<li>IDA</li>
<li>LDA</li>
</ul>

<h2 id="toc_1">2.非线性的方法——流形</h2>

<p><strong>流形</strong><br/>
是指嵌入在高维空间中的低维子空间，它的维度是低维数据变化的自由度。（比如地球仪的球面，虽然它是在一个三维空间中，但其实是一个二维的地图卷曲而成，\(x^2+y^2+z^2=1\)，维度是2）</p>

<p><strong>流形学习</strong><br/>
就是通过挖掘数据的内在结构实现向故由维度的转化，找到对应的低维嵌入流形。其大部分是非线性的、非参的。所以相比线性方法有更强的表达能力，但是同时对噪声更加敏感。</p>

<p><strong>流形学习方法</strong></p>

<p>流形学习，首先需要确定低维流形的结构，然后是高维到低维的映射关系。实际中因为都未知，所以需要做一些假设。</p>

<blockquote>
<ul>
<li>多维缩放MDS (multi dimensional scaling)</li>
</ul>
</blockquote>

<p>原则:让高维空间上样本之间的距离在低维空间中尽量保持一致以距离重建的误差最小为优化目标。</p>

<p>具体来说：</p>

<p>(1) 对于原始的数据\(X_{np}\),首先可以计算出任何两个样本之间的距离，从而构造出一个距离矩阵\(D\)，MDS算法的目的就是根据距离矩阵，寻找向量\(Z_1,Z_2...Z_k\),使得\(||Z_i-Z_j||≈\sigma_{ij}\)</p>

<p>假设\(Z\)是经过中心化处理过的，即\(\sum z_i = 0\) , 则有</p>

<p>\[XX^T = D≈ZZ^T\]</p>

<p>看到这个形式，应该就能明白怎么取解了。对D做特征分解\(D=VAV^T\)， V是对应的特征向量，我们选择前k个特征值比较大的作为最终的降维维度即可。</p>

<p><code>问题：高维空间的距离与低维空间距离保持一致这个假设是否合理？</code></p>

<p>以地球仪的球面为例，三维空间中两个点的距离和平面中两个点的距离显然是不一样的。三维空间中如果用欧式距离去度量那么北京与纽约的距离是连接两点的直线，而在平面上他是一条曲线。</p>

<pre><code class="language-text"># MDS
mds = manifold.MDS(n_components, max_iter=100, n_init=1)
Y = mds.fit_transform(X)
</code></pre>

<p>下面再说一些以几何性质作为同构基础的降维方法</p>

<blockquote>
<ul>
<li>等度量映射Isomap</li>
</ul>
</blockquote>

<p>等度量映射，以数据所在的低维流形与欧式空间子集的等距性为基础。描述距离的是<strong>测地距离</strong>，即流形上两点的真实距离。测地距离的近似计算方法：近邻点之间的欧式距离近似为近邻点之间的测地距离。</p>

<p>通过对每一个近邻点建立连接，就可以让所有数据点共同构成一张带权重的近邻连接图。这样在这张图上任意两个点的测地距离就相当于是两点之间的最短路径。可以用图论中的Dijkstra算法求解。</p>

<p>当计算出距离后，剩下的处理方法和MDS一致。所以总的来说包括三步：<br/>
(1) 最近邻搜索<br/>
(2) 最短路径搜索<br/>
(3) 部分特征值分解</p>

<pre><code class="language-text">model = manifold.Isomap(n_neighbors, n_components)
Y = model.fit_transform(X)
</code></pre>

<blockquote>
<ul>
<li>局部线性嵌入LLE(local linear embedding)</li>
</ul>
</blockquote>

<p>想法：待求解的低维流形在局部上是线性的，每个点可以表示成近邻点的线性组合。而局部线性嵌入就是在求解流形的过程中保持每个领域中的线性系数不变的基础上重构原数据点。</p>

<p>详细的推导过程<a href="https://blog.csdn.net/yukgwy60648/article/details/54578141">https://blog.csdn.net/yukgwy60648/article/details/54578141</a></p>

<pre><code class="language-text"># 其中method可选 [&#39;standard&#39;, &#39;ltsa&#39;, &#39;hessian&#39;, &#39;modified&#39;]
model = manifold.LocallyLinearEmbedding(n_neighbors, n_components, eigen_solver=&#39;auto&#39;, method=method)
Y = model.fit_transform(X)
</code></pre>

<p>从概率角度</p>

<blockquote>
<ul>
<li>随机近邻嵌入 SNE</li>
</ul>
</blockquote>

<p>随机近邻嵌入的特点：保持数据降维前后的概率分布不变,他将高维空间中的距离首先映射到了一个服从正态分布的条件概率上。这个概率描述了不同数据点之间的相似性。</p>

<p>\[p_{j|i}=\frac{exp(-||x_j-x_i||^2/2\sigma^2_i)}{\sum_{k\ne i}exp(-||x_k-x_i||^2/2\sigma^2_i)}\]</p>

<p>映射到低维空间后，按照同样方式计算条件概率，希望连个概率分布尽量一致。这里是KL散度最小化<br/>
\[KL(P||Q) = -\sum P_i ln(\frac{P_i}{Q_i})=-\sum P_i(ln(P_i)- ln(Q_i))\]</p>

<p><code>问题</code>：<br/>
KL距离是不对称的，会导致相聚较远的点出现较大的散度差。为了是KL距离最小化，数据就会被压缩到极小的范围，产生拥挤问题。</p>

<p><code>改进</code></p>

<ul>
<li>将KL散度改为对称形式 \(p_{ij}=p_{ji}=(p_{i|j}+p_{j|i})/2\)</li>
<li>令低维空间中的条件概率服从t分布，t分布有长尾效应，从而使高维中分布较远的点降维后也能区分开</li>
</ul>

<pre><code class="language-text">tsne = manifold.TSNE(n_components=n_components, init=&#39;pca&#39;, random_state=0)
Y = tsne.fit_transform(X)
</code></pre>

<p><img src="media/15382821564829/15383222417494.jpg" alt=""/></p>

<h2 id="toc_2">小结</h2>

<ul>
<li><p>本章主要知识结构<br/>
<img src="https://upload-images.jianshu.io/upload_images/127231-bf906252693ca552.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"/></p></li>
<li><p>sklearn中关于流形学习内容都在<code>sklearn.manifold</code>模块。<br/>
官网示例 <a href="http://sklearn.apachecn.org/cn/0.19.0/auto_examples/manifold/plot_compare_methods.html#sphx-glr-auto-examples-manifold-plot-compare-methods-py">http://sklearn.apachecn.org/cn/0.19.0/auto_examples/manifold/plot_compare_methods.html#sphx-glr-auto-examples-manifold-plot-compare-methods-py</a></p></li>
<li><p>参考文档<br/>
<a href="https://blog.csdn.net/yukgwy60648/article/details/54578141">https://blog.csdn.net/yukgwy60648/article/details/54578141</a><br/>
sklearn—文档 <a href="http://scikit-learn.org/stable/modules/manifold.html">http://scikit-learn.org/stable/modules/manifold.html</a><br/>
<a href="http://sklearn.apachecn.org/cn/0.19.0/modules/manifold.html">http://sklearn.apachecn.org/cn/0.19.0/modules/manifold.html</a></p></li>
</ul>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2019/7/21</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='5%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html'>5 机器学习</a></span>
          				   
                    

                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15665275932673.html">
                
                  <h1>3.vim 配置</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p><strong>1 简单版，直接配置好的</strong><br/>
mac vim 配置<br/>
<a href="https://github.com/barretlee/autoconfig-mac-vimrc">https://github.com/barretlee/autoconfig-mac-vimrc</a></p>

<pre><code class="language-text">git clone https://github.com/barretlee/autoconfig-mac-vimrc.git;
cd autoconfig-mac-vimrc;
chmod +x install;
./install;
</code></pre>

<p>调整终端配色： <a href="https://github.com/mitsuhide1992/vim-colors-solarized">https://github.com/mitsuhide1992/vim-colors-solarized</a></p>

<p>macvim:  <a href="https://www.jianshu.com/p/923aec861af3">https://www.jianshu.com/p/923aec861af3</a></p>

<p><strong>2 vimrc配置中一些常用命令说明</strong></p>

<pre><code class="language-text">colorscheme desert  &quot;设置主题 
set number   &quot;显示行号 
set autoindent   &quot;自动缩进 
set cursorcolumn  &quot;光垂直平方向高亮显示
set cursorline  &quot;光标水平方向高亮显示
set mouse=a   &quot;激活鼠标可用 
set tabstop=4  &quot;设置tab和缩进为4个空格
syntax enable   &quot;开启语法 
</code></pre>

<p><strong>3 vim 操作快捷键</strong></p>

<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>

<tbody>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2019/8/23</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='1%20Tools.html'>1 Tools</a></span>
          				   
                    

                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15637037677008.html">
                
                  <h1>3.【解释性】LIME</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>机器学习得到的模型有时候是一个black box不具有解释性，作者提出了一个问题，我们究竟是相信一个predict result，还是相信一个model。</p>

<p>本文作者主要是利用局部近似的方法，来对any classifier进行解释<br/>
一个大概的示意图<br/>
<img src="media/15227606288131/15227612016423.jpg" alt=""/></p>

<h2 id="toc_0">2.可解释性</h2>

<ul>
<li>可解释：首先必须是可解释的易懂的，在特征很多的时候，线性模型、梯度向量、可加模型等都不太适合。</li>
<li>local faithfull：局部忠诚</li>
<li>与模型无关的，可解释any classifier</li>
</ul>

<h2 id="toc_1">3 Local Interpretable Model-agnostic Explanations</h2>

<p>LIME，首先区分两个东西</p>

<ul>
<li>features</li>
<li>interpretable data representations</li>
</ul>

<p>比如文本文类时具体的features是一个vector，而可解释的representation可能是是否出现某个关键词</p>

<p>基本原理示意图：<br/>
<img src="media/15227606288131/15227631412258.jpg" alt=""/></p>

<p>说明：</p>

<p>抽象的数学描述<br/>
<img src="media/15227606288131/15227633252420.jpg" alt=""/></p>

<p>作者在后面主要是讲了候选集是稀疏线性模型的方法</p>

<h3 id="toc_2">稀疏线性解释</h3>

<p>即G为线性模型，一致性的度量\(\pi_x=exp(-D(x,z)^2/\sigma^2)\), 在x局部用一个线性函数去近似</p>

<p><img src="media/15227606288131/15227718128055.jpg" alt=""/><br/>
具体操作，先用lasso选择k个特征，然后用最小二乘学习特征的权重，K-LASSO<br/>
<img src="media/15227606288131/15227724362604.jpg" alt=""/></p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2019/7/21</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='8%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html'>8 深度学习</a></span>
          				   
                    

                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
              


			<div class="row">
			  <div class="large-6 columns">
			  <p class="text-left" style="padding-top:25px;">
			   <a href="all_1.html">&laquo; Prev Page</a>  
			  </p>
			  </div>
			  <div class="large-6 columns">
			<p class="text-right" style="padding-top:25px;">
			 <a href="all_3.html">&raquo; Next Page</a> 
			</p>
			  </div>
			</div>
		</div>
	</div><!-- large 8 -->

 <div class="large-4 medium-4 columns">
  <div class="hide-for-small">
    <div id="sidebar" class="sidebar">
          <div id="site-info" class="site-info">
            
                <h1>zhenzhen数据科学笔记</h1>
                <div class="site-des"></div>
                <div class="social">









<a target="_blank" class="github" target="_blank" href="tjzzz.github.io" title="GitHub">GitHub</a>

  <a target="_blank" class="rss" href="atom.xml" title="RSS">RSS</a>
                
              	 </div>
          	</div>

             

              <div id="site-categories" class="side-item ">
                <div class="side-header">
                  <h2>Categories</h2>
                </div>
                <div class="side-content">

      	<p class="cat-list">
        
            <a href="kdd&%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html"><strong>kdd&异常检测</strong></a>
        
            <a href="%E8%BD%A8%E8%BF%B9%E5%88%86%E6%9E%90.html"><strong>轨迹分析</strong></a>
        
            <a href="1%20Tools.html"><strong>1 Tools</strong></a>
        
            <a href="2%20Get%20Data.html"><strong>2 Get Data</strong></a>
        
            <a href="3%20%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96.html"><strong>3 数据可视化</strong></a>
        
            <a href="4%20%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95.html"><strong>4 统计方法</strong></a>
        
            <a href="5%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html"><strong>5 机器学习</strong></a>
        
            <a href="6%20NLP.html"><strong>6 NLP</strong></a>
        
            <a href="7%20CV.html"><strong>7 CV</strong></a>
        
            <a href="8%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html"><strong>8 深度学习</strong></a>
        
            <a href="9%20%E6%AF%94%E8%B5%9B%E5%AD%A6%E4%B9%A0.html"><strong>9 比赛学习</strong></a>
        
            <a href="%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6-%E6%B8%85%E5%8D%95.html"><strong>数据科学-清单</strong></a>
        
            <a href="%E5%85%B6%E4%BB%96.html"><strong>其他</strong></a>
         
        </p>


                </div>
              </div>

              <div id="site-categories" class="side-item">
                <div class="side-header">
                  <h2>Recent Posts</h2>
                </div>
                <div class="side-content">
                <ul class="posts-list">
	      
		      
			      <li class="post">
			        <a href="15687050894061.html">0.综述</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15637036455584.html">1 估计的置信度</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15637037681646.html">1 基础工具包安装pip</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15637025346412.html">1. conda 环境管理</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15637037713554.html">1. 数据可视化概述</a>
			      </li>
		     
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		   
		  		</ul>
                </div>
              </div>
        </div><!-- sidebar -->
      </div><!-- hide for small -->
</div><!-- large 4 -->

</div><!-- row -->

 <div class="page-bottom clearfix">
  <div class="row">
   <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
</div>

        </section>
      </div>
    </div>

  
    

    <script src="asset/js/foundation.min.js"></script>
    <script>
      $(document).foundation();
      function fixSidebarHeight(){
        var w1 = $('.markdown-body').height();
          var w2 = $('#sidebar').height();
          if (w1 > w2) { $('#sidebar').height(w1); };
      }
      $(function(){
        fixSidebarHeight();
      })
      $(window).load(function(){
          fixSidebarHeight();
      });
     
    </script>

    
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>


  </body>
</html>
